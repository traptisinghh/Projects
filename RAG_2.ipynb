{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDRdg99vU+oDAwqgNEKPKm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/traptisinghh/Projects/blob/main/RAG_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhV8tkd0i2kJ",
        "outputId": "ae3f30a4-9e4e-4857-db66-3949d6c7fb25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53sthl1qi5jD",
        "outputId": "6beef309-9703-40ad-c04b-e933aabc5e3e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.78 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.78)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.33)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.78->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rag with Langchain and FIASS to read external text and PDF\n",
        "\n",
        "!pip install faiss-cpu\n",
        "!pip install langchain_community\n",
        "\n",
        "import os\n",
        "import faiss\n",
        "from google.colab import files\n",
        "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Upload files\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "documents = []\n",
        "for filename in uploaded_files.keys():\n",
        "    if filename.endswith(\".txt\"):\n",
        "        text_loader = TextLoader(filename)\n",
        "        docs = text_loader.load()\n",
        "        documents.extend(docs)\n",
        "    elif filename.endswith(\".pdf\"):\n",
        "        pdf_loader = PyPDFLoader(filename)\n",
        "        docs = pdf_loader.load()\n",
        "        documents.extend(docs)\n",
        "\n",
        "# Print original text content\n",
        "print(\"\\nUploaded Document Contents:\\n\")\n",
        "for i, doc in enumerate(documents):\n",
        "    print(f\"Document {i+1}:\")\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)  # Separator for readability\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QiDxuUGzjC-1",
        "outputId": "2ef59701-e764-4afa-b313-c2e431e17e52"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.78 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.78)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.33)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.78->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f3be3451-6632-430c-b428-bc9354bd8493\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f3be3451-6632-430c-b428-bc9354bd8493\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving agenticAI_contextEngineering.pdf to agenticAI_contextEngineering (2).pdf\n",
            "\n",
            "Uploaded Document Contents:\n",
            "\n",
            "Document 1:\n",
            "Agentic Context Engineering: Evolving Contexts for Self-Improving\n",
            "Language Models\n",
            "Qizheng Zhang 1∗ Changran Hu 2∗ Shubhangi Upasani 2 Boyuan Ma 2 Fenglu Hong 2\n",
            "Vamsidhar Kamanuru 2 Jay Rainton 2 Chen Wu 2 Mengmeng Ji 2 Hanchen Li 3\n",
            "Urmish Thakker 2 James Zou 1 Kunle Olukotun 1\n",
            "1 Stanford University 2 SambaNova Systems, Inc. 3 UC Berkeley ∗ equal contribution\n",
            "/envel⌢peqizhengz@stanford.edu, changran.hu@sambanovasystems.com\n",
            "Abstract\n",
            "Large language model (LLM) applications such as agents and domain-specific reasoning increasingly rely on\n",
            "context adaptation—modifying inputs with instructions, strategies, or evidence, rather than weight updates.\n",
            "Prior approaches improve usability but often suffer from brevity bias, which drops domain insights for\n",
            "concise summaries, and from context collapse, where iterative rewriting erodes details over time. Building on\n",
            "the adaptive memory introduced by Dynamic Cheatsheet, we introduce ACE (AgenticContextEngineering),\n",
            "a framework that treats contexts as evolving playbooks that accumulate, refine, and organize strategies\n",
            "through a modular process of generation, reflection, and curation. ACE prevents collapse with structured,\n",
            "incremental updates that preserve detailed knowledge and scale with long-context models. Across agent\n",
            "and domain-specific benchmarks, ACE optimizes contexts both offline (e.g.,system prompts) and online (e.g.,\n",
            "agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while\n",
            "significantly reducing adaptation latency and rollout cost. Notably, ACE could adapt effectively without\n",
            "labeled supervision and instead by leveraging natural execution feedback. On the AppWorld leaderboard,\n",
            "ACE matches the top-ranked production-level agent on the overall average and surpasses it on the harder\n",
            "test-challenge split, despite using a smaller open-source model. These results show that comprehensive,\n",
            "evolving contexts enable scalable, efficient, and self-improving LLM systems with low overhead.\n",
            "1 Introduction\n",
            "Base LLM\n",
            "ICL GEPA DC ACE\n",
            "40.0\n",
            "42.5\n",
            "45.0\n",
            "47.5\n",
            "50.0\n",
            "52.5\n",
            "55.0\n",
            "57.5\n",
            "60.0Accuracy (%)\n",
            "42.4%\n",
            "46.0% 46.4%\n",
            "51.9%\n",
            "59.5%\n",
            "Agent: AppWorld\n",
            "Base LLM\n",
            "ICL GEPA DC ACE\n",
            "68\n",
            "70\n",
            "72\n",
            "74\n",
            "76\n",
            "78\n",
            "80\n",
            "82\n",
            "70.7%\n",
            "72.3%\n",
            "73.5%\n",
            "74.2%\n",
            "78.3%\n",
            "Domain Knowledge: FiNER\n",
            "Base LLM\n",
            "ICL GEPA DC ACE\n",
            "66\n",
            "68\n",
            "70\n",
            "72\n",
            "74\n",
            "76\n",
            "78\n",
            "80\n",
            "67.5% 67.0%\n",
            "71.5%\n",
            "69.5%\n",
            "76.5%\n",
            "Numerical Reasoning: Formula\n",
            "Figure 1:Overall Performance Results.Our proposed framework, ACE, consistently outperforms strong\n",
            "baselines across agent and domain-specific reasoning tasks.\n",
            "Modern AI applications based on large language models (LLMs), such as LLM agents [49, 52] and compound\n",
            "AI systems [55], increasingly depend oncontext adaptation. Instead of modifying model weights, context\n",
            "arXiv:2510.04618v1  [cs.LG]  6 Oct 2025\n",
            "--------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "adaptation improves performance after model training by incorporating clarified instructions, structured\n",
            "reasoning steps, or domain-specific input formats directly into the model’s inputs. Contexts underpin\n",
            "many AI system components, including system prompts that guide downstream tasks [4, 36], memory that\n",
            "carries past facts and experiences [41, 48], and factual evidence that reduces hallucination and supplements\n",
            "knowledge [6].\n",
            "Adapting throughcontextsrather thanweightsoffers several key advantages. Contexts are interpretable and\n",
            "explainable for users and developers [45, 47], allow rapid integration of new knowledge at runtime [7, 27],\n",
            "and can be shared across models or modules in a compound system [ 23]. Meanwhile, advances in long-\n",
            "context LLMs [39] and context-efficient inference such as KV cache reuse [17, 51] are making context-based\n",
            "approaches increasingly practical for deployment. As a result, context adaptation is emerging as a central\n",
            "paradigm for building capable, scalable, and self-improving AI systems.\n",
            "Despite this progress, existing approaches to context adaptation face two key limitations. First, abrevity\n",
            "bias: many prompt optimizers prioritize concise, broadly applicable instructions over comprehensive\n",
            "accumulation. For example, GEPA [ 4] highlights brevity as a strength, but such abstraction can omit\n",
            "domain-specific heuristics, tool-use guidelines, or common failure modes that matter in practice [16]. This\n",
            "objective aligns with validation metrics in some settings, but often fails to capture the detailed strategies\n",
            "required by agents and knowledge-intensive applications. Second,context collapse: methods that rely on\n",
            "monolithic rewriting by an LLM often degrade into shorter, less informative summaries over time, causing\n",
            "sharp performance declines (Figure 2). In domains such as interactive agents [38, 43, 57], domain-specific\n",
            "programming [53, 56], and financial or legal analysis [18, 33, 44], strong performance depends on retaining\n",
            "detailed, task-specific knowledge rather than compressing it away.\n",
            "As applications such as agents and knowledge-intensive reasoning demand greater reliability, recent work\n",
            "has shifted toward saturating contexts with abundant, potentially useful information [11, 12, 22], enabled by\n",
            "advances in long-context LLMs [34, 39].We argue that contexts should function not as concise summaries,\n",
            "but as comprehensive, evolving playbooks—detailed, inclusive, and rich with domain insights.Unlike\n",
            "humans, who often benefit from concise generalization, LLMs are more effective when provided with long,\n",
            "detailed contexts and can distill relevance autonomously [22, 31, 41]. Thus, instead of compressing away\n",
            "domain-specific heuristics and tactics, contexts should preserve them, allowing the model to decide what\n",
            "matters at inference time.\n",
            "To address these limitations, we introduce ACE (AgenticContextEngineering), a framework for compre-\n",
            "hensive context adaptation in both offline settings (e.g.,system prompt optimization) and online settings\n",
            "(e.g.,test-time memory adaptation). Rather than compressing contexts into distilled summaries, ACE treats\n",
            "them as evolving playbooks that accumulate and organize strategies over time. Building on the agentic\n",
            "architecture of Dynamic Cheatsheet [41], ACE incorporates a modular workflow of generation, reflection,\n",
            "and curation, while adding structured, incremental updates guided by a grow-and-refine principle. This\n",
            "design preserves detailed, domain-specific knowledge, prevents context collapse, and yields contexts that\n",
            "remain comprehensive and scalable throughout adaptation.\n",
            "We evaluate ACE on two categories of LLM applications that most benefit from comprehensive, evolving\n",
            "contexts: (1)agents[ 43], which require multi-turn reasoning, tool use, and environment interaction, where\n",
            "accumulated strategies can be reused across episodes; and (2)domain-specific benchmarks, which demand\n",
            "specialized tactics and knowledge, where we focus on financial analysis [33, 44]. Our key findings are:\n",
            "• ACE consistently outperforms strong baselines, yielding average gains of 10.6% onagentsand 8.6% on\n",
            "domain-specific benchmarks, across both offline and online adaptation settings.\n",
            "• ACE is able to construct effective contextswithoutlabeled supervision, instead leveraging execution\n",
            "feedback and environment signals—key ingredients for self-improving LLMs and agents.\n",
            "• On the AppWorld benchmark leaderboard [5], ACE matches the top-ranked production-level agent IBM-\n",
            "CUGA [35] (powered by GPT-4.1) on average and surpasses it on the harder test-challenge split, while\n",
            "using a smaller open-source model (DeepSeek-V3.1).\n",
            "2\n",
            "--------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "• ACE requires significantly fewer rollouts and lower dollar costs, and achieves 86.9% lower adaptation\n",
            "latency (on average) than existing adaptive methods, demonstrating that scalable self-improvement can be\n",
            "achieved with both higher accuracy and lower overhead.\n",
            "2 Background and Motivation\n",
            "2.1 Context Adaptation\n",
            "Context adaptation (or context engineering) refers to methods that improve model behavior by constructing\n",
            "or modifying inputs to an LLM, rather than altering its weights. The current state of the art leveragesnatural\n",
            "language feedback[ 4, 40, 54]. In this paradigm, a language model inspects the current context along with\n",
            "signals such as execution traces, reasoning steps, or validation results, and generates natural language\n",
            "feedback on how the context should be revised. This feedback is then incorporated into the context, enabling\n",
            "iterative adaptation. Representative methods include Reflexion [40], which reflects on failures to improve\n",
            "agent planning; TextGrad [54], which optimizes prompts via gradient-like textual feedback; GEPA [4], which\n",
            "refines prompts iteratively based on execution traces and achieves strong performance, even surpassing\n",
            "reinforcement learning approaches in some settings; and Dynamic Cheatsheet [ 41], which constructs an\n",
            "external memory that accumulates strategies and lessons from past successes and failures during inference.\n",
            "These natural language feedback methods represent a major advance, offering flexible and interpretable\n",
            "signals for improving LLM systems beyond weight updates.\n",
            "2.2 Limitations of Existing Context Adaptation Methods\n",
            "The Brevity Bias.A recurring limitation of context adaptation methods isbrevity bias: the tendency of\n",
            "optimization to collapse toward short, generic prompts. Gao et al. [ 16] document this effect in prompt\n",
            "optimization for test generation, where iterative methods repeatedly produced near-identical instructions\n",
            "(e.g.,\"Create unit tests to ensure methods behave as expected\"), sacrificing diversity and omitting domain-\n",
            "specific detail. This convergence not only narrows the search space but also propagates recurring errors\n",
            "across iterations, since optimized prompts often inherit the same faults as their seeds. More broadly, such\n",
            "bias undermines performance in domains that demand detailed, context-rich guidance—such as multi-step\n",
            "agents, program synthesis, or knowledge-intensive reasoning—where success hinges on accumulating rather\n",
            "than compressing task-specific insights.\n",
            "# Tokens: 18,282Accuracy: 66.7 \n",
            "# Tokens: 122Accuracy: 57.1 Accuracy w/o context: 63.7\n",
            "Figure 2:Context Collapse.Monolithic rewriting of context by an LLM can collapse it into shorter, less\n",
            "informative summaries, leading to sharp performance drops.\n",
            "Context Collapse.In a case study on the AppWorld benchmark [ 43], we observe a phenomenon we\n",
            "callcontext collapse, which arises when an LLM is tasked with fully rewriting the accumulated context at\n",
            "each adaptation step. As the context grows large, the model tends to compress it into much shorter, less\n",
            "informative summaries, causing a dramatic loss of information. For instance, at step 60 the context contained\n",
            "3\n",
            "--------------------------------------------------------------------------------\n",
            "Document 4:\n",
            "18,282 tokens and achieved an accuracy of 66.7, but at the very next step it collapsed to just 122 tokens,\n",
            "with accuracy dropping to 57.1—worse than the baseline accuracy of 63.7 without adaptation. While we\n",
            "highlight this through Dynamic Cheatsheet [41], the issue is not specific to that method; rather, it reflects a\n",
            "fundamental risk of end-to-end context rewriting with LLMs, where accumulated knowledge can be abruptly\n",
            "erased instead of preserved.\n",
            "Figure 3:Example ACE-Generated Context on the AppWorld Benchmark(partially shown). ACE-generated\n",
            "contexts contain detailed, domain-specific insights along with tools and code that are readily usable, serving\n",
            "as a comprehensive playbook for LLM applications.\n",
            "3 Agentic Context Engineering (ACE)\n",
            "We present ACE (AgenticContextEngineering), a framework for scalable and efficient context adaptation\n",
            "in both offline (e.g.,system prompt optimization) and online (e.g.,test-time memory adaptation) scenarios.\n",
            "Instead of condensing knowledge into terse summaries or static instructions, ACE treats contexts as evolving\n",
            "playbooks that continuously accumulate, refine, and organize strategies over time. Building on the agentic\n",
            "design of Dynamic Cheatsheet [41], ACE introduces a structured division of labor across three roles (Figure\n",
            "4): theGenerator, which produces reasoning trajectories; theReflector, which distills concrete insights from\n",
            "successes and errors; and theCurator, which integrates these insights into structured context updates. This\n",
            "mirrors how humans learn—experimenting, reflecting, and consolidating—while avoiding the bottleneck of\n",
            "overloading a single model with all responsibilities.\n",
            "To address the limitations of prior methods discussed in §2.2—notablybrevity biasandcontext collapse—ACE\n",
            "introduces three key innovations: (1) a dedicatedReflectorthat separates evaluation and insight extraction\n",
            "from curation, improving context quality and downstream performance (§4.5); (2) incrementaldelta updates\n",
            "(§3.1) that replace costly monolithic rewrites with localized edits, reducing both latency and compute cost\n",
            "(§4.6); and (3) agrow-and-refinemechanism (§3.2) that balances steady context expansion with redundancy\n",
            "control.\n",
            "4\n",
            "--------------------------------------------------------------------------------\n",
            "Document 5:\n",
            "Generator\n",
            "Context Playbook\n",
            "Query\n",
            "Trajectory\n",
            " Insights\n",
            "Delta Context Items\n",
            "Iterative Refinement\n",
            "Update\n",
            "Reflector Curator\n",
            "Figure 4:The ACE Framework.Inspired by Dynamic Cheatsheet, ACE adopts an agentic architecture with\n",
            "three specialized components: a Generator, a Reflector, and a Curator.\n",
            "As shown in Figure 4, the workflow begins with the Generator producing reasoning trajectories for new\n",
            "queries, which surface both effective strategies and recurring pitfalls. The Reflector critiques these traces\n",
            "to extract lessons, optionally refining them across multiple iterations. The Curator then synthesizes these\n",
            "lessons into compactdelta entries, which are merged deterministically into the existing context by lightweight,\n",
            "non-LLM logic. Because updates are itemized and localized, multiple deltas can be merged in parallel,\n",
            "enabling batched adaptation at scale. ACE further supports multi-epoch adaptation, where the same queries\n",
            "are revisited to progressively strengthen the context.\n",
            "3.1 Incremental Delta Updates\n",
            "A core design principle of ACE is to represent context as a collection ofstructured, itemized bullets, rather\n",
            "than a single monolithic prompt. The concept of a bullet is similar to the concept of a memory entry in LLM\n",
            "memory frameworks like Dynamic Cheatsheet [41] and A-MEM [48], but builds on top of that and consists\n",
            "of (1)metadata, including a unique identifier and counters tracking how often it was marked helpful or\n",
            "harmful; and (2)content, capturing a small unit such as a reusable strategy, domain concept, or common\n",
            "failure mode. When solving new problems, the Generator highlights which bullets were useful or misleading,\n",
            "providing feedback that guides the Reflector in proposing corrective updates.\n",
            "This itemized design enables three key properties: (1)localization, so only the relevant bullets are updated;\n",
            "(2)fine-grained retrieval, so the Generator can focus on the most pertinent knowledge; and (3)incremental\n",
            "adaptation, allowing efficient merging, pruning, and de-duplication during inference.\n",
            "Rather than regenerating contexts in full, ACE incrementally produces compactdelta contexts: small sets of\n",
            "candidate bullets distilled by the Reflector and integrated by the Curator. This avoids the computational\n",
            "cost and latency of full rewrites, while ensuring that past knowledge is preserved and new insights are\n",
            "steadily appended. As contexts grow, this approach provides the scalability needed for long-horizon or\n",
            "domain-intensive applications.\n",
            "3.2 Grow-and-Refine\n",
            "Beyond incremental growth, ACE ensures that contexts remain compact and relevant through periodic or\n",
            "lazy refinement. In grow-and-refine, bullets with new identifiers are appended, while existing bullets are\n",
            "updated in place (e.g.,incrementing counters). A de-duplication step then prunes redundancy by comparing\n",
            "bullets via semantic embeddings. This refinement can be performed proactively (after each delta) or lazily\n",
            "(only when the context window is exceeded), depending on application requirements for latency and\n",
            "accuracy.\n",
            "5\n",
            "--------------------------------------------------------------------------------\n",
            "Document 6:\n",
            "Together, incremental updates and grow-and-refine maintain contexts that expand adaptively, remain\n",
            "interpretable, and avoid the potential variance introduced by monolithic context rewriting.\n",
            "4 Results\n",
            "Our evaluation of ACE shows that:\n",
            "• Enabling High-Performance, Self-Improving Agents.ACE enables agents to self-improve by dynamically\n",
            "refining their input context. It boosts accuracy on the AppWorld benchmark by up to 17.1% by learning to\n",
            "engineer better contexts from execution feedback alone, without needing ground-truth labels. This context-\n",
            "driven improvement allows a smaller, open-source model to match the performance of the top-ranked\n",
            "proprietary agent on the leaderboard. (§4.3)\n",
            "• Large Gains on Domain-Specific Benchmarks.On complex financial reasoning benchmarks, ACE delivers\n",
            "an average performance gain of 8.6% over strong baselines by constructing comprehensive playbooks\n",
            "with domain-specific concepts and insights. (§4.4)\n",
            "• Effective by Design.Ablation studies confirm our design choices are key to success, with components\n",
            "like the Reflector and multi-epoch refinement each contributing substantial performance gains. (§4.5)\n",
            "• Lower Cost and Adaptation Latency.ACE achieves these gains efficiently, reducing adaptation latency by\n",
            "86.9% on average, while requiring fewer rollouts and lower token dollar costs. (§4.6)\n",
            "4.1 Tasks and Datasets\n",
            "We evaluate ACE on two categories of LLM applications that benefit most from a comprehensive and\n",
            "evolving context: (1)agent benchmarks, which require multi-turn reasoning, tool use, and environment\n",
            "interaction, where agents can accumulate and reuse strategies across episodes and environments; and (2)\n",
            "domain-specific benchmarks, which demand mastery of specialized concepts and tactics, where we focus on\n",
            "financial analysis as a case study.\n",
            "• LLM Agent: AppWorld [ 43]is a suite of autonomous agent tasks involving API understanding, code\n",
            "generation, and environment interaction. It provides a realistic execution environment with common\n",
            "applications and APIs (e.g.,email, file system) and tasks of two difficulty levels (normal and challenge). A\n",
            "public leaderboard [5] tracks performance, where, at the time of submission, the best system achieved only\n",
            "60.3% average accuracy, highlighting the benchmark’s difficulty and realism.\n",
            "• Financial Analysis: FiNER [ 33] and Formula [ 44]test LLMs on financial reasoning tasks that rely on\n",
            "the eXtensible Business Reporting Language (XBRL).FiNERrequires labeling tokens in XBRL financial\n",
            "documents with one of 139 fine-grained entity types, a key step for financial information extraction in\n",
            "regulated domains.Formulafocuses on extracting values from structured XBRL filings and performing\n",
            "computations to answer financial queries,i.e.,numerical reasoning.\n",
            "Evaluation Metrics.For AppWorld, we follow the official benchmark protocol and reportTask Goal\n",
            "Completion(TGC) andScenario Goal Completion(SGC) on both the test-normal and test-challenge splits. For\n",
            "FiNER and Formula, we follow the original setup and report accuracy, measured as the proportion of\n",
            "predicted answers that exactly match the ground truth.\n",
            "All datasets follow the original train/validation/test splits. Forofflinecontext adaptation, methods are\n",
            "optimized on the training split and evaluated on the test split with pass@1 accuracy. Foronlinecontext\n",
            "adaptation, methods are evaluated sequentially on the test split: for each sample, the model first predicts\n",
            "with the current context, then updates its context based on that sample. The same shuffled test split is used\n",
            "across all methods.\n",
            "4.2 Baselines and Methods\n",
            "Base LLM.The base model is evaluated directly on each benchmark without any context engineering,\n",
            "using the default prompts provided by dataset authors. For AppWorld, we follow the official ReAct [52]\n",
            "6\n",
            "--------------------------------------------------------------------------------\n",
            "Document 7:\n",
            "implementation released by the benchmark authors, and build all other baselines and methods on top of this\n",
            "framework.\n",
            "In-Context Learning (ICL) [3].ICL provides the model with task demonstrations in the input prompt\n",
            "(few-shot or many-shot). This allows the model to infer the task format and desired output without weight\n",
            "updates. We supply all training samples when they fit within the model’s context window; otherwise, we fill\n",
            "the window with as many demonstrations as possible.\n",
            "MIPROv2 [36].MIPROv2 is a popular prompt optimizer for LLM applications that works by jointly\n",
            "optimizing system instructions and in-context demonstrations via bayesian optimization. We use the official\n",
            "DSPy implementation [15], settingauto=\"heavy\"to maximize optimization performance.\n",
            "GEPA [4].GEPA (Genetic-Pareto) is a sample-efficient prompt optimizer based on reflective prompt\n",
            "evolution. It collects execution traces (reasoning, tool calls, intermediate outputs) and applies natural-\n",
            "language reflection to diagnose errors, assign credit, and propose prompt updates. A genetic Pareto search\n",
            "maintains a frontier of high-performing prompts, mitigating local optima. Empirically, GEPA outperforms\n",
            "reinforcement learning methods such as GRPO and prompt optimizers like MIPROv2, achieving up to\n",
            "10–20% higher accuracy with as much as 35× fewer rollouts. We use the official DSPy implementation [14],\n",
            "settingauto=\"heavy\"to maximize optimization performance.\n",
            "Dynamic Cheatsheet (DC) [41].DC is a test-time learning approach that introduces an adaptive external\n",
            "memory of reusable strategies and code snippets. By continuously updating this memory with newly\n",
            "encountered inputs and outputs, DC enables models to accumulate knowledge and reuse it across tasks,\n",
            "often leading to substantial improvements over static prompting methods. A key advantage of DC is that it\n",
            "does not require ground-truth labels: the model can curate its own memory from its generations, making\n",
            "the method highly flexible and broadly applicable. We use the official implementation released by the\n",
            "authors [42] and set it to use thecumulativemode (DC-CU).\n",
            "ACE (ours).ACE optimizes LLM contexts for both offline and online adaptation through an agentic context\n",
            "engineering framework. To ensure fairness, we use the same LLM for the Generator, Reflector, and Curator\n",
            "(non-thinking mode of DeepSeek-V3.1 [13]), preventing knowledge transfer from a stronger Reflector or\n",
            "Curator to a weaker Generator. This isolates the benefit of context construction itself. We adopt a batch size\n",
            "of 1 (constructing a delta context from each sample). We set the maximum number of Reflector refinement\n",
            "rounds and the maximum number of epochs in offline adaptation to 5.\n",
            "4.3 Results on Agent Benchmark\n",
            "Analysis.As shown in Table 1, ACE consistently improves over strong baselines on the AppWorld\n",
            "benchmark. In the offline setting, ReAct + ACE outperforms both ReAct + ICL and ReAct + GEPA by\n",
            "significant margins (12.3% and 11.9%, respectively), demonstrating that structured, evolving, and detailed\n",
            "contexts enable more effective agent learning than fixed demonstrations or single optimized instruction\n",
            "prompts. These gains extend to the online setting, where ACE continues to outperform prior adaptive\n",
            "methods such as Dynamic Cheatsheet by an average of 7.6%.\n",
            "In the agent use case, ACE remains effective evenwithoutaccess to ground-truth labels during adaptation:\n",
            "ReAct + ACE achieves an average improvement of 14.8% over the ReAct baseline in this setting. This\n",
            "robustness arises because ACE leverages signals naturally available during execution (e.g.,code execution\n",
            "success or failure) to guide the Reflector and Curator in forming structured lessons of successes and failures.\n",
            "Together, these results establish ACE as a strong and versatile framework for building self-improving agents\n",
            "that adapt reliably both with and without labeled supervision.\n",
            "Notably, on the latest AppWorld leaderboard (as of September 20, 2025; Figure 5), on average, ReAct +\n",
            "ACE (59.4%) matches the top-ranked IBM CUGA (60.3%), a production-level GPT-4.1–based agent [ 35],\n",
            "despite using the smaller open-source model DeepSeek-V3.1. With online adaptation, ReAct + ACE even\n",
            "7\n",
            "--------------------------------------------------------------------------------\n",
            "Document 8:\n",
            "Method GT Labels Test-Normal Test-Challenge Average\n",
            "TGC↑SGC↑ TGC↑SGC↑\n",
            "DeepSeek-V3.1 as Base LLM\n",
            "ReAct 63.7 42.9 41.5 21.6 42.4\n",
            "Offline Adaptation\n",
            "ReAct+ ICL✓ 64.3+0.6 46.4+3.5 46.0+4.5 27.3+5.7 46.0+3.6\n",
            "ReAct+ GEPA✓ 64.9+1.2 44.6+1.7 46.0+4.5 30.2+8.6 46.4+4.0\n",
            "ReAct+ ACE✓ 76.2+12.5 64.3+21.4 57.3+15.8 39.6+18.0 59.4+17.0\n",
            "ReAct+ ACE✗ 75.0+11.3 64.3+21.4 54.4+12.9 35.2+13.6 57.2+14.8\n",
            "Online Adaptation\n",
            "ReAct+ DC (CU)✗ 65.5+1.8 58.9+16.0 52.3+10.8 30.8+9.2 51.9+9.5\n",
            "ReAct+ ACE✗ 69.6+5.9 53.6+10.7 66.0+24.5 48.9+27.3 59.5+17.1\n",
            "Table 1:Results on the AppWorld Agent Benchmark.\"GT labels\" indicates whether ground-truth labels are\n",
            "available to the Reflector during adaptation. We evaluate the ACE framework against multiple baselines\n",
            "on top of the official ReAct implementation, both for offline and online context adaptation. ReAct + ACE\n",
            "outperforms selected baselines by an average of 10.6%, and could achieve good performance even without\n",
            "access to GT labels.\n",
            "Method GT Labels FINER (Acc↑) Formula (Acc↑) Average\n",
            "DeepSeek-V3.1 as Base LLM\n",
            "Base LLM 70.7 67.5 69.1\n",
            "Offline Adaptation\n",
            "ICL✓ 72.3+1.6 67.0−0.5 69.6+0.5\n",
            "MIPROv2✓ 72.4+1.7 69.5+2.0 70.9+1.8\n",
            "GEPA✓ 73.5+2.8 71.5+4.0 72.5+3.4\n",
            "ACE✓ 78.3+7.6 85.5+18.0 81.9+12.8\n",
            "ACE✗ 71.1+0.4 83.0+15.5 77.1+8.0\n",
            "Online Adaptation\n",
            "DC (CU)✓ 74.2+3.5 69.5+2.0 71.8+2.7\n",
            "DC (CU)✗ 68.3−2.4 62.5−5.0 65.4−3.7\n",
            "ACE✓ 76.7+6.0 76.5+9.0 76.6+7.5\n",
            "ACE✗ 67.3−3.4 78.5+11.0 72.9+3.8\n",
            "Table 2:Results on Financial Analysis Benchmark.\"GT labels\" indicates whether ground-truth labels\n",
            "are available to the Reflector during adaptation. With GT labels, ACE outperforms selected baselines by\n",
            "an average of 8.6%, highlighting the advantage of structured and evolving contexts for domain-specific\n",
            "reasoning. However, we also observe that in the absence of reliable feedback signals (e.g.,ground-truth\n",
            "labels or execution outcomes), both ACE and other adaptive methods such as Dynamic Cheatsheet may\n",
            "degrade, suggesting that context adaptation depends critically on feedback quality.\n",
            "surpasses IBM CUGA by 8.4% in TGC and 0.7% in SGC on the harder test-challenge split, underscoring the\n",
            "effectiveness of ACE in building comprehensive and self-evolving contexts for agents.\n",
            "4.4 Results on Domain-Specific Benchmark\n",
            "Analysis.As shown in Table 2, ACE delivers strong improvements on financial analysis benchmarks.\n",
            "In the offline setting, when provided with ground-truth answers from the training split, ACE surpasses\n",
            "ICL, MIPROv2, and GEPA by clear margins (an average of 10.9%), showing that structured and evolving\n",
            "contexts are particularly effective when tasks require precise domain knowledge (e.g.,financial concepts,\n",
            "8\n",
            "--------------------------------------------------------------------------------\n",
            "Document 9:\n",
            "Method GT Labels Test-Normal Test-Challenge Average\n",
            "TGC↑SGC↑ TGC↑SGC↑\n",
            "DeepSeek-V3.1 as Base LLM\n",
            "ReAct 63.7 42.9 41.5 21.6 42.4\n",
            "Offline Adaptation\n",
            "ReAct+ ACE w/o Reflector or multi-epoch✓ 70.8+7.1 55.4+12.5 55.9+14.4 38.1+17.5 55.1+12.7\n",
            "ReAct+ ACE w/o multi-epoch✓ 72.0+8.3 60.7+17.8 54.9+13.4 39.6+18.0 56.8+14.4\n",
            "ReAct+ ACE✓ 76.2+12.5 64.3+21.4 57.3+15.8 39.6+18.0 59.4+17.0\n",
            "Online Adaptation\n",
            "ReAct+ ACE✗ 67.9+4.2 51.8+8.9 61.4+19.9 43.2+21.6 56.1+13.7\n",
            "ReAct+ ACE + offline warmup✗ 69.6+5.9 53.6+10.7 66.0+24.5 48.9+27.3 59.5+17.1\n",
            "Table 3:Ablation Studies on AppWorld.We study how particular design choices of ACE (iterative\n",
            "refinement, multi-epoch adaptation, and offline warmup) could help high-quality context adaptation.\n",
            "Method Latency (s)↓# Rollouts↓\n",
            "ReAct + GEPA 53898 1434\n",
            "ReAct + ACE 9517 (-82.3%) 357(-75.1%)\n",
            "(a)Offline(AppWorld).\n",
            "Method Latency (s)↓Token Cost ($)↓\n",
            "DC (CU) 65104 17.7\n",
            "ACE 5503 (-91.5%) 2.9(-83.6%)\n",
            "(b)Online(FiNER).\n",
            "Table 4:Cost and Speed Analysis.We measure the context adaptation latency, number of rollouts, and\n",
            "dollar costs of ACE against GEPA (offline) and DC (online).\n",
            "XBRL rules) that goes beyond fixed demonstrations or monolithic optimized prompts. In the online setting,\n",
            "ACE continues to exceed prior adaptive methods such as DC by an average of 6.2%, further confirming the\n",
            "benefit of agentic context engineering for accumulating reusable insights across specialized domains.\n",
            "Moreover, we also observe that when ground-truth supervision or reliable execution signals are absent,\n",
            "both ACE and DC may degrade in performance. In such cases, the constructed context can be polluted by\n",
            "spurious or misleading signals, highlighting a potential limitation of inference-time adaptation without\n",
            "reliable feedback. This suggests that while ACE is robust under rich feedback (e.g.,code execution results or\n",
            "formula correctness in agent tasks), its effectiveness depends on the availability of signals that allow the\n",
            "Reflector and Curator to make sound judgments. We return to this limitation in Appendix B.\n",
            "4.5 Ablation Study\n",
            "Table 3 reports ablation studies on the AppWorld benchmark, analyzing how individual design choices\n",
            "of ACE contribute to effective context adaptation. We examine three factors: (1)the Reflector with iterative\n",
            "refinement, our addition to the agentic framework beyond Dynamic Cheatsheet, (2)multi-epoch adaptation,\n",
            "which refines contexts over training samples multiple times, and (3)offline warmup, which initializes the\n",
            "context through offline adaptation before online adaptation begins.\n",
            "4.6 Cost and Speed Analysis\n",
            "Due to its support for incremental, “delta\" context updates and non-LLM-based context merging and de-\n",
            "duplication, ACE demonstrates particular advantages in reducing the cost (in terms of the number of rollouts\n",
            "or the amount of dollar cost for token ingestion/generation) and latency of adaptation.\n",
            "As examples, on the offline adaptation of AppWorld, ACE achieves 82.3% reduction in adaptation latency\n",
            "and 75.1% reduction in the number of rollouts as compared to GEPA (Table 4(a)). On the online adaptation\n",
            "9\n",
            "--------------------------------------------------------------------------------\n",
            "Document 10:\n",
            "of FiNER, ACE achieves 91.5% reduction in adaptation latency and 83.6% reduction in token dollar cost for\n",
            "token ingestion and generation as compared to DC (Table 4(b)).\n",
            "5 Discussion\n",
            "Longer Context ̸= Higher Serving Cost.Although ACE produces longer contexts than methods such\n",
            "as GEPA, this does not translate to linearly higher inference cost or GPU memory usage. Modern serving\n",
            "infrastructures are increasingly optimized for long-context workloads through techniques such as the\n",
            "reuse [17, 51], compression [30, 32], and offload [25] of KV cache. These mechanisms allow frequently reused\n",
            "context segments to be cached locally or remotely, avoiding repetitive and expensive prefill operations.\n",
            "Ongoing advances in ML systems suggest that the amortized cost of handling long contexts will continue to\n",
            "decrease, making context-rich approaches like ACE increasingly practical in deployment.\n",
            "Implications for Online and Continuous Learning.Online and continuous learning are key research\n",
            "directions in machine learning for addressing issues like distribution shifts [ 19, 24] and limited training\n",
            "data [21, 37, 60]. ACE offers a flexible and efficient alternative to conventional model fine-tuning, as\n",
            "adapting contexts is generally cheaper than updating model weights [ 9, 20, 26, 28]. Moreover, because\n",
            "contexts are human-interpretable, ACE enablesselective unlearning[ 8, 10, 29]—whether due to privacy or\n",
            "legal constraints [1, 2], or when outdated or incorrect information is identified by domain experts. These are\n",
            "promising directions for future work, where ACE could play a central role in advancing continuous and\n",
            "responsible learning.\n",
            "References\n",
            "[1] General Data Protection Regulation article 17: Right to erasure. EU Regulation 2016/679, 2016. Official\n",
            "consolidated text.\n",
            "[2] California consumer privacy act, civil code §1798.105: Right to delete. State of California Civil Code,\n",
            "2018.\n",
            "[3] Rishabh Agarwal, Avi Singh, Lei Zhang, Bernd Bohnet, Luis Rosias, Stephanie Chan, Biao Zhang,\n",
            "Ankesh Anand, Zaheer Abbas, Azade Nova, et al. Many-shot in-context learning.Advances in Neural\n",
            "Information Processing Systems, 37:76930–76966, 2024.\n",
            "[4] Lakshya A Agrawal, Shangyin Tan, Dilara Soylu, Noah Ziems, Rishi Khare, Krista Opsahl-Ong, Arnav\n",
            "Singhvi, Herumb Shandilya, Michael J Ryan, Meng Jiang, et al. Gepa: Reflective prompt evolution can\n",
            "outperform reinforcement learning.arXiv preprint arXiv:2507.19457, 2025.\n",
            "[5] AppWorld. Leaderboard.https://appworld.dev/leaderboard, 2025. Accessed: 2025-09-20.\n",
            "[6] Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. Self-rag: Learning to\n",
            "retrieve, generate, and critique through self-reflection. 2024.\n",
            "[7] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican,\n",
            "George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. Improving\n",
            "language models by retrieving from trillions of tokens. InInternational conference on machine learning,\n",
            "pages 2206–2240. PMLR, 2022.\n",
            "[8] Lucas Bourtoule, Varun Chandrasekaran, Christopher Choquette-Choo, Hengrui Jia, Adelin Travers,\n",
            "Baiwu Zhang, David Lie, and Nicolas Papernot. Machine unlearning.IEEE Symposium on Security and\n",
            "Privacy, pages 141–159, 2021.\n",
            "[9] Tom Brown et al. Language models are few-shot learners. InNeurIPS, 2020.\n",
            "[10] Yinzhi Cao and Junfeng Yang. Towards making systems forget with machine unlearning. InIEEE\n",
            "Symposium on Security and Privacy, 2015.\n",
            "10\n",
            "--------------------------------------------------------------------------------\n",
            "Document 11:\n",
            "[11] Tianxiang Chen, Zhentao Tan, Xiaofan Bo, Yue Wu, Tao Gong, Qi Chu, Jieping Ye, and Nenghai Yu.\n",
            "Flora: Effortless context construction to arbitrary length and scale.arXiv preprint arXiv:2507.19786, 2025.\n",
            "[12] Yeounoh Chung, Gaurav T Kakkar, Yu Gan, Brenton Milne, and Fatma Ozcan. Is long context all you\n",
            "need? leveraging llm’s extended context for nl2sql.arXiv preprint arXiv:2501.12372, 2025.\n",
            "[13] DeepSeek-AI. Deepseek-v3 technical report, 2024.\n",
            "[14] DSPy. dspy.gepa: Reflective prompt optimizer. https://dspy.ai/api/optimizers/GEPA/overview/,\n",
            "2025. Accessed: 2025-09-24.\n",
            "[15] DSPy. dspy.miprov2.https://dspy.ai/api/optimizers/MIPROv2/, 2025. Accessed: 2025-09-24.\n",
            "[16] Shuzheng Gao, Chaozheng Wang, Cuiyun Gao, Xiaoqian Jiao, Chun Yong Chong, Shan Gao, and\n",
            "Michael Lyu. The prompt alchemist: Automated llm-tailored prompt optimization for test case genera-\n",
            "tion.arXiv preprint arXiv:2501.01329, 2025.\n",
            "[17] In Gim, Guojun Chen, Seung-seob Lee, Nikhil Sarda, Anurag Khandelwal, and Lin Zhong. Prompt\n",
            "cache: Modular attention reuse for low-latency inference.Proceedings of Machine Learning and Systems,\n",
            "6:325–338, 2024.\n",
            "[18] Neel Guha, Julian Nyarko, Daniel Ho, Christopher Ré, Adam Chilton, Alex Chohlas-Wood, Austin\n",
            "Peters, Brandon Waldon, Daniel Rockmore, Diego Zambrano, et al. Legalbench: A collaboratively built\n",
            "benchmark for measuring legal reasoning in large language models.Advances in neural information\n",
            "processing systems, 36:44123–44279, 2023.\n",
            "[19] Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. InICLR, 2021.\n",
            "[20] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and\n",
            "Weizhu Chen. LoRA: Low-rank adaptation of large language models.arXiv:2106.09685, 2021.\n",
            "[21] Maxwell L Hutchinson, Erin Antono, Brenna M Gibbons, Sean Paradiso, Julia Ling, and Bryce Meredig.\n",
            "Overcoming data scarcity with transfer learning.arXiv preprint arXiv:1711.05099, 2017.\n",
            "[22] Mingjian Jiang, Yangjun Ruan, Luis Lastras, Pavan Kapanipathi, and Tatsunori Hashimoto. Putting it\n",
            "all into context: Simplifying agents with lclms.arXiv preprint arXiv:2505.08120, 2025.\n",
            "[23] Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish\n",
            "Sabharwal. Decomposed prompting: A modular approach for solving complex tasks.arXiv preprint\n",
            "arXiv:2210.02406, 2022.\n",
            "[24] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubra-\n",
            "mani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A benchmark of\n",
            "in-the-wild distribution shifts. InInternational conference on machine learning, pages 5637–5664. PMLR,\n",
            "2021.\n",
            "[25] Wonbeom Lee, Jungi Lee, Junghwan Seo, and Jaewoong Sim.{InfiniGen}: Efficient generative inference\n",
            "of large language models with dynamic {KV} cache management. In18th USENIX Symposium on\n",
            "Operating Systems Design and Implementation (OSDI 24), pages 155–172, 2024.\n",
            "[26] Brian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efficient prompt\n",
            "tuning. InEMNLP, 2021.\n",
            "[27] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,\n",
            "Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented generation for\n",
            "knowledge-intensive nlp tasks.Advances in neural information processing systems, 33:9459–9474, 2020.\n",
            "[28] Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation.ACL,\n",
            "2021.\n",
            "11\n",
            "--------------------------------------------------------------------------------\n",
            "Document 12:\n",
            "[29] Shiyang Liu et al. Rethinking machine unlearning for large language models.arXiv:2402.08787, 2024.\n",
            "[30] Yuhan Liu, Hanchen Li, Yihua Cheng, Siddhant Ray, Yuyang Huang, Qizheng Zhang, Kuntai Du, Jiayi\n",
            "Yao, Shan Lu, Ganesh Ananthanarayanan, et al. Cachegen: Kv cache compression and streaming for\n",
            "fast large language model serving. InProceedings of the ACM SIGCOMM 2024 Conference, pages 38–56,\n",
            "2024.\n",
            "[31] Zhining Liu, Rana Ali Amjad, Ravinarayana Adkathimar, Tianxin Wei, and Hanghang Tong. Selfelicit:\n",
            "Your language model secretly knows where is the relevant evidence.arXiv preprint arXiv:2502.08767,\n",
            "2025.\n",
            "[32] Zirui Liu, Jiayi Yuan, Hongye Jin, Shaochen Zhong, Zhaozhuo Xu, Vladimir Braverman, Beidi Chen, and\n",
            "Xia Hu. Kivi: A tuning-free asymmetric 2bit quantization for kv cache.arXiv preprint arXiv:2402.02750,\n",
            "2024.\n",
            "[33] Lefteris Loukas, Manos Fergadiotis, Ilias Chalkidis, Eirini Spyropoulou, Prodromos Malakasiotis, Ion\n",
            "Androutsopoulos, and Georgios Paliouras. Finer: Financial numeric entity recognition for xbrl tagging.\n",
            "arXiv preprint arXiv:2203.06482, 2022.\n",
            "[34] Yansheng Mao, Jiaqi Li, Fanxu Meng, Jing Xiong, Zilong Zheng, and Muhan Zhang. Lift: Improving\n",
            "long context understanding through long input fine-tuning.arXiv preprint arXiv:2412.13626, 2024.\n",
            "[35] Sami Marreed, Alon Oved, Avi Yaeli, Segev Shlomov, Ido Levy, Offer Akrabi, Aviad Sela, Asaf Adi, and\n",
            "Nir Mashkif. Towards enterprise-ready computer using generalist agent.arXiv preprint arXiv:2503.01861,\n",
            "2025.\n",
            "[36] Krista Opsahl-Ong, Michael J Ryan, Josh Purtell, David Broman, Christopher Potts, Matei Zaharia, and\n",
            "Omar Khattab. Optimizing instructions and demonstrations for multi-stage language model programs.\n",
            "arXiv preprint arXiv:2406.11695, 2024.\n",
            "[37] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning.IEEE Transactions on Knowledge and\n",
            "Data Engineering, 22(10):1345–1359, 2010.\n",
            "[38] Shishir G Patil, Tianjun Zhang, Xin Wang, and Joseph E Gonzalez. Gorilla: Large language model\n",
            "connected with massive apis.Advances in Neural Information Processing Systems, 37:126544–126565, 2024.\n",
            "[39] Bowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole. Yarn: Efficient context window\n",
            "extension of large language models.arXiv preprint arXiv:2309.00071, 2023.\n",
            "[40] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion:\n",
            "Language agents with verbal reinforcement learning.Advances in Neural Information Processing Systems,\n",
            "36:8634–8652, 2023.\n",
            "[41] Mirac Suzgun, Mert Yuksekgonul, Federico Bianchi, Dan Jurafsky, and James Zou. Dynamic cheatsheet:\n",
            "Test-time learning with adaptive memory.arXiv preprint arXiv:2504.07952, 2025.\n",
            "[42] Mirac Suzgun, Mert Yuksekgonul, Federico Bianchi, Dan Jurafsky, and James Zou. Dynamic cheatsheet:\n",
            "Test-time learning with adaptive memory. https://github.com/suzgunmirac/dynamic-cheatsheet,\n",
            "2025. Accessed: 2025-09-24.\n",
            "[43] Harsh Trivedi, Tushar Khot, Mareike Hartmann, Ruskin Manku, Vinty Dong, Edward Li, Shashank\n",
            "Gupta, Ashish Sabharwal, and Niranjan Balasubramanian. Appworld: A controllable world of apps\n",
            "and people for benchmarking interactive coding agents.arXiv preprint arXiv:2407.18901, 2024.\n",
            "[44] Dannong Wang, Jaisal Patel, Daochen Zha, Steve Y Yang, and Xiao-Yang Liu. Finlora: Benchmarking\n",
            "lora methods for fine-tuning llms on financial datasets.arXiv preprint arXiv:2505.19819, 2025.\n",
            "[45] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery,\n",
            "and Denny Zhou. Self-consistency improves chain of thought reasoning in language models.arXiv\n",
            "preprint arXiv:2203.11171, 2022.\n",
            "12\n",
            "--------------------------------------------------------------------------------\n",
            "Document 13:\n",
            "[46] Zora Zhiruo Wang, Jiayuan Mao, Daniel Fried, and Graham Neubig. Agent workflow memory.arXiv\n",
            "preprint arXiv:2409.07429, 2024.\n",
            "[47] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,\n",
            "et al. Chain-of-thought prompting elicits reasoning in large language models.Advances in neural\n",
            "information processing systems, 35:24824–24837, 2022.\n",
            "[48] Wujiang Xu, Kai Mei, Hang Gao, Juntao Tan, Zujie Liang, and Yongfeng Zhang. A-mem: Agentic\n",
            "memory for llm agents.arXiv preprint arXiv:2502.12110, 2025.\n",
            "[49] John Yang, Carlos E Jimenez, Alexander Wettig, Kilian Lieret, Shunyu Yao, Karthik Narasimhan, and\n",
            "Ofir Press. Swe-agent: Agent-computer interfaces enable automated software engineering.Advances in\n",
            "Neural Information Processing Systems, 37:50528–50652, 2024.\n",
            "[50] Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov, and\n",
            "Christopher D Manning. Hotpotqa: A dataset for diverse, explainable multi-hop question answering.\n",
            "arXiv preprint arXiv:1809.09600, 2018.\n",
            "[51] Jiayi Yao, Hanchen Li, Yuhan Liu, Siddhant Ray, Yihua Cheng, Qizheng Zhang, Kuntai Du, Shan Lu,\n",
            "and Junchen Jiang. Cacheblend: Fast large language model serving for rag with cached knowledge\n",
            "fusion. InProceedings of the Twentieth European Conference on Computer Systems, pages 94–109, 2025.\n",
            "[52] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\n",
            "React: Synergizing reasoning and acting in language models. InInternational Conference on Learning\n",
            "Representations (ICLR), 2023.\n",
            "[53] Jiacheng Ye, Chengzu Li, Lingpeng Kong, and Tao Yu. Generating data for symbolic language with\n",
            "large language models.arXiv preprint arXiv:2305.13917, 2023.\n",
            "[54] Mert Yuksekgonul, Federico Bianchi, Joseph Boen, Sheng Liu, Zhi Huang, Carlos Guestrin, and James\n",
            "Zou. Textgrad: Automatic\" differentiation\" via text.arXiv preprint arXiv:2406.07496, 2024.\n",
            "[55] Matei Zaharia, Omar Khattab, Lingjiao Chen, Jared Quincy Davis, Heather Miller, Chris Potts, James\n",
            "Zou, Michael Carbin, Jonathan Frankle, Naveen Rao, and Ali Ghodsi. The shift from models to\n",
            "compound ai systems.https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/, 2024.\n",
            "[56] Genghan Zhang, Weixin Liang, Olivia Hsu, and Kunle Olukotun. Adaptive self-improvement llm\n",
            "agentic system for ml library development.arXiv preprint arXiv:2502.02534, 2025.\n",
            "[57] Qizheng Zhang, Ali Imran, Enkeleda Bardhi, Tushar Swamy, Nathan Zhang, Muhammad Shahbaz,\n",
            "and Kunle Olukotun. Caravan: Practical online learning of {In-Network}{ML} models with labeling\n",
            "agents. In18th USENIX Symposium on Operating Systems Design and Implementation (OSDI 24), pages\n",
            "325–345, 2024.\n",
            "[58] Qizheng Zhang, Michael Wornow, and Kunle Olukotun. Cost-efficient serving of llm agents via test-time\n",
            "plan caching.arXiv preprint arXiv:2506.14852, 2025.\n",
            "[59] Huichi Zhou, Yihang Chen, Siyuan Guo, Xue Yan, Kin Hei Lee, Zihan Wang, Ka Yiu Lee, Guchun\n",
            "Zhang, Kun Shao, Linyi Yang, et al. Agentfly: Fine-tuning llm agents without fine-tuning llms.arXiv\n",
            "preprint arXiv:2508.16153, 2025.\n",
            "[60] Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong, and\n",
            "Qing He. A comprehensive survey on transfer learning.arXiv:1911.02685, 2019.\n",
            "13\n",
            "--------------------------------------------------------------------------------\n",
            "Document 14:\n",
            "A Related Work on Agent Memory\n",
            "A growing body of work explores how agents can accumulate experience from past trajectories and leverage\n",
            "external (often non-parametric) memory to guide future actions. AgentFly [59] presents an extensible frame-\n",
            "work where memory evolves continuously as agents solve tasks, enabling scalable reinforcement learning\n",
            "and long-horizon reasoning across diverse environments. AWM (Agent Workflow Memory) [46] induces\n",
            "reusableworkflows—structured routines distilled from past trajectories—and selectively injects them into\n",
            "memory to improve efficiency and generalization in web navigation benchmarks. A-MEM [48] introduces\n",
            "a dynamically organized memory system inspired by the Zettelkasten method: each stored memory is\n",
            "annotated with structured attributes (e.g.,tags, keywords, contextual descriptions) and automatically linked\n",
            "to relevant past entries, while existing entries are updated to integrate new knowledge, yielding adaptive\n",
            "and context-aware retrieval. Agentic Plan Caching [ 58] instead focuses on cost efficiency by extracting\n",
            "reusable plan templates from agent trajectories and caching them for fast execution at test time.\n",
            "Together, these works demonstrate the value of external memory for improving adaptability, efficiency, and\n",
            "generalization in LLM agents. Our work differs by tackling the broader challenge ofcontext adaptation, which\n",
            "spans not only agent memory but also system prompts, factual evidence, and other inputs underpinning AI\n",
            "systems. We further highlight two fundamental limitations of existing adaptation methods—brevity biasand\n",
            "context collapse—and show that addressing them is essential for robustness, reliability, and scalability beyond\n",
            "raw task performance. Accordingly, our evaluation considers not only accuracy but also cost, latency, and\n",
            "scalability.\n",
            "B Limitations and Challenges\n",
            "A potential limitation of ACE is its reliance on a reasonably strong Reflector: if the Reflector fails to extract\n",
            "meaningful insights from generated traces or outcomes, the constructed context may become noisy or even\n",
            "harmful. In domain-specific tasks where no model can extract useful insights, the resulting context will\n",
            "naturally lack them. This dependency is similar to Dynamic Cheatsheet [41], where the quality of adaptation\n",
            "hinges on the underlying model’s ability to curate memory. We also note that not all applications require\n",
            "rich or detailed contexts. Tasks like HotPotQA [50] often benefit more from concise, high-level instructions\n",
            "(e.g.,how to retrieve and synthesize evidence) than from long contexts. Similarly, games with fixed strategies\n",
            "such as Game of 24 [ 41] may only need a single reusable rule, rendering additional context redundant.\n",
            "Overall, ACE is most beneficial in settings that demand detailed domain knowledge, complex tool use,\n",
            "or environment-specific strategies that go beyond what is already embedded in model weights or simple\n",
            "system instructions.\n",
            "C AppWorld Leaderboard Snapshot (09/2025)\n",
            "Figure 5: The AppWorld leaderboard as accessed on 09/20/2025.\n",
            "14\n",
            "--------------------------------------------------------------------------------\n",
            "Document 15:\n",
            "D Prompts\n",
            "We release the language model prompts used in our agentic context engineering framework as well as the\n",
            "baselines to support research transparency and reproducibility.\n",
            "I\tam\tyour\tsupervisor\tand\tyou\tare\ta\tsuper\tintelligent\tAI\tAssistant\twhose\tjob\tis\tto\tachieve\tmy\tday-to-day\ttasks\tcompletely\tautonomously.\n",
            "To\tdo\tthis,\tyou\twill\tneed\tto\tinteract\twith\tapp/s\t(e.g.,\tspotify,\tvenmo\tetc)\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\tFor\tthis\tyou\twill\n",
            "undertake\ta\t\n",
            "multi-step\tconversation\n",
            "\tusing\ta\tpython\tREPL\tenvironment.\tThat\tis,\tyou\twill\twrite\tthe\tpython\tcode\tand\tthe\tenvironment\twill\n",
            "execute\tit\tand\tshow\tyou\tthe\tresult,\tbased\ton\twhich,\tyou\twill\twrite\tpython\tcode\tfor\tthe\tnext\tstep\tand\tso\ton,\tuntil\tyou’ve\tachieved\tthe\tgoal.\n",
            "This\tenvironment\twill\tlet\tyou\tinteract\twith\tapp/s\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\n",
            "Here\tare\tthree\tkey\tAPIs\tthat\tyou\tneed\tto\tknow\tto\tget\tmore\tinformation\n",
            "Each\tcode\texecution\twill\tproduce\tan\toutput\tthat\tyou\tcan\tuse\tin\tsubsequent\tcalls.\tUsing\tthese\tAPIs,\tyou\tcan\tnow\tgenerate\tcode,\tthat\tI\twill\n",
            "execute,\tto\tsolve\tthe\ttask.\n",
            "Let’s\tstart\twith\tthe\ttask\n",
            "[3\tshot\texample]\n",
            "Key\tinstructions\n",
            ":\n",
            "1.\t\n",
            "Make\tsure\tto\tend\tcode\tblocks\twith\t```\tfollowed\tby\ta\tnewline().\n",
            "2.\t\n",
            "Remember\tyou\tcan\tuse\tthe\tvariables\tin\tyour\tcode\tin\tsubsequent\tcode\tblocks.\n",
            "3.\t\n",
            "Remember\tthat\tthe\temail\taddresses,\taccess\ttokens\tand\tvariables\t(e.g.\tspotify_password)\tin\tthe\texample\tabove\tare\tnot\tvalid\n",
            "anymore.\n",
            "4.\t\n",
            "You\tcan\tuse\tthe\t“supervisor”\tapp\tto\tget\tinformation\tabout\tmy\taccounts\tand\tuse\tthe\t“phone”\tapp\tto\tget\tinformation\tabout\tfriends\n",
            "and\tfamily.\n",
            "5.\t\n",
            "Always\tlook\tat\tAPI\tspecifications\t(using\t\n",
            "apis.api_docs.show_api_doc\n",
            ")\tbefore\tcalling\tan\tAPI.\n",
            "6.\t\n",
            "Write\tsmall\tchunks\tof\tcode\tand\tonly\tone\tchunk\tof\tcode\tin\tevery\tstep.\tMake\tsure\teverything\tis\tworking\tcorrectly\tbefore\tmaking\tany\n",
            "irreversible\tchange.\n",
            "7.\t\n",
            "Many\tAPIs\treturn\titems\tin\t“pages”.\tMake\tsure\tto\trun\tthrough\tall\tthe\tpages\tby\tlooping\tover\t\n",
            "page_index\n",
            ".\n",
            "8.\t\n",
            "Once\tyou\thave\tcompleted\tthe\ttask,\tmake\tsure\tto\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            ".\tIf\tthe\ttask\tasked\tfor\tsome\tinformation,\n",
            "return\tit\tas\tthe\tanswer\targument,\ti.e.\tcall\t\n",
            "apis.supervisor.complete_task(answer=<answer>)\n",
            ".\tMany\ttasks\tdo\tnot\trequire\tan\n",
            "answer,\tso\tin\tthose\tcases,\tjust\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            "\ti.e.\tdo\tnot\tpass\tany\targument.\n",
            "Using\tthese\tAPIs,\tgenerate\tcode\tto\tsolve\tthe\tactual\ttask:\n",
            "My\tname\tis:\t{{\tmain_user.first_name\t}}\t{{\tmain_user.last_name\t}}.\tMy\tpersonal\temail\tis\t{{\tmain_user.email\t}}\tand\tphone\tnumber\tis\t{{\n",
            "main_user.phone_number\t}}.\n",
            "Task:\t{{\tinput_str\t}}\n",
            "#\tTo\tget\ta\tlist\tof\tapps\tthat\tare\tavailable\tto\tyou.\n",
            "print\n",
            "(apis.api_docs.show_app_descriptions())\n",
            "#\tTo\tget\tthe\tlist\tof\tapis\tunder\tany\tapp\tlisted\tabove,\te.g.\tspotify\n",
            "print\n",
            "(apis.api_docs.show_api_descriptions(app_name\n",
            "=\n",
            "'spotify'\n",
            "))\n",
            "#\tTo\tget\tthe\tspecification\tof\ta\tparticular\tapi,\te.g.\tspotify\tapp's\tlogin\tapi\n",
            "print\n",
            "(apis.api_docs.show_api_doc(app_name\n",
            "=\n",
            "'spotify'\n",
            ",\tapi_name\n",
            "=\n",
            "'login'\n",
            "))\n",
            "Figure 6: ICL-baseline Generator prompt on AppWorld\n",
            "15\n",
            "--------------------------------------------------------------------------------\n",
            "Document 16:\n",
            "I\tam\tyour\tsupervisor\tand\tyou\tare\ta\tsuper\tintelligent\tAI\tAssistant\twhose\tjob\tis\tto\tachieve\tmy\tday-to-day\ttasks\tcompletely\tautonomously.\n",
            "You\twill\tbe\tgiven\ta\tcheatsheet\tcontaining\trelevant\tstrategies,\tpatterns,\tand\texamples\tfrom\tsimilar\tproblems\tto\tapply\tand\tsolve\tthe\n",
            "current\ttask.\n",
            "To\tdo\tthis,\tyou\twill\tneed\tto\tinteract\twith\tapp/s\t(e.g.,\tspotify,\tvenmo\tetc)\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\tFor\tthis\tyou\twill\n",
            "undertake\ta\t\n",
            "multi-step\tconversation\n",
            "\tusing\ta\tpython\tREPL\tenvironment.\tThat\tis,\tyou\twill\twrite\tthe\tpython\tcode\tand\tthe\tenvironment\twill\n",
            "execute\tit\tand\tshow\tyou\tthe\tresult,\tbased\ton\twhich,\tyou\twill\twrite\tpython\tcode\tfor\tthe\tnext\tstep\tand\tso\ton,\tuntil\tyou’ve\tachieved\tthe\tgoal.\n",
            "This\tenvironment\twill\tlet\tyou\tinteract\twith\tapp/s\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\n",
            "Here\tare\tthree\tkey\tAPIs\tthat\tyou\tneed\tto\tknow\tto\tget\tmore\tinformation\n",
            "Each\tcode\texecution\twill\tproduce\tan\toutput\tthat\tyou\tcan\tuse\tin\tsubsequent\tcalls.\tUsing\tthese\tAPIs,\tyou\tcan\tnow\tgenerate\tcode,\tthat\tI\twill\n",
            "execute,\tto\tsolve\tthe\ttask.\n",
            "CHEATSHEET:\t’’’\t{{\tcheat_sheet\t}}\t’’’\n",
            "1.\tANALYSIS\t&\tSTRATEGY\n",
            "Carefully\tanalyze\tboth\tthe\tquestion\tand\tcheatsheet\tbefore\tstarting\n",
            "Search\tfor\tand\tidentify\tany\tapplicable\tpatterns,\tstrategies,\tor\texamples\twithin\tthe\tcheatsheet\n",
            "Create\ta\tstructured\tapproach\tto\tsolving\tthe\tproblem\tat\thand\n",
            "Review\tand\tdocument\tany\tlimitations\tin\tthe\tprovided\treference\tmaterials\n",
            "2.\tSOLUTION\tDEVELOPMENT\n",
            "Present\tyour\tsolution\tusing\tclear,\tlogical\tsteps\tthat\tothers\tcan\tfollow\tand\treview\n",
            "Explain\tyour\treasoning\tand\tmethodology\tbefore\tpresenting\tfinal\tconclusions\n",
            "Provide\tdetailed\texplanations\tfor\teach\tstep\tof\tthe\tprocess\n",
            "Check\tand\tverify\tall\tassumptions\tand\tintermediate\tcalculations\n",
            "3.\tPROGRAMMING\tTASKS\n",
            "When\tcoding\tis\trequired:\t-\tWrite\tclean,\tefficient\tPython\tcode\t-\tFollow\tthe\tstrict\tcode\tformatting\tand\texecution\tprotocol\t(always\tuse\tthe\n",
            "Python\tcode\tformatting\tblock;\tfurthermore,\tafter\tthe\tcode\tblock,\talways\texplicitly\trequest\texecution\tby\tappending:\t“EXECUTE\tCODE!”):\t\n",
            "python\t\t\t#\tYour\tcode\there\n",
            "\tEXECUTE\tCODE!\n",
            "All\trequired\timports\tand\tdependencies\tshould\tbe\tclearly\tdeclared\tat\tthe\ttop\tof\tyour\tcode\n",
            "Include\tclear\tinline\tcomments\tto\texplain\tany\tcomplex\tprogramming\tlogic\n",
            "Perform\tresult\tvalidation\tafter\texecuting\tyour\tcode\n",
            "Apply\toptimization\ttechniques\tfrom\tthe\tcheatsheet\twhen\tapplicable\n",
            "The\tcode\tshould\tbe\tcompletely\tself-contained\twithout\texternal\tfile\tdependencies–it\tshould\tbe\tready\tto\tbe\texecuted\tright\taway\n",
            "Do\tnot\tinclude\tany\tplaceholders,\tsystem-specific\tpaths,\tor\thard-coded\tlocal\tpaths\n",
            "Feel\tfree\tto\tuse\tstandard\tand\twidely-used\tpip\tpackages\n",
            "Opt\tfor\talternative\tmethods\tif\terrors\tpersist\tduring\texecution\n",
            "Exclude\tlocal\tpaths\tand\tengine-specific\tsettings\t(e.g.,\tavoid\tconfigurations\tlike\n",
            "chess.engine.SimpleEngine.popen_uci(“/usr/bin/stockfish”))\n",
            "Let’s\tstart\twith\tthe\ttask\n",
            "[3\tshot\texample]\n",
            "Key\tinstructions\n",
            ":\t(1)\tMake\tsure\tto\tend\tcode\tblocks\twith\t```\tfollowed\tby\ta\tnewline().\n",
            "2.\t\n",
            "Remember\tyou\tcan\tuse\tthe\tvariables\tin\tyour\tcode\tin\tsubsequent\tcode\tblocks.\n",
            "3.\t\n",
            "Remember\tthat\tthe\temail\taddresses,\taccess\ttokens\tand\tvariables\t(e.g.\tspotify_password)\tin\tthe\texample\tabove\tare\tnot\tvalid\n",
            "anymore.\n",
            "4.\t\n",
            "You\tcan\tuse\tthe\t“supervisor”\tapp\tto\tget\tinformation\tabout\tmy\taccounts\tand\tuse\tthe\t“phone”\tapp\tto\tget\tinformation\tabout\tfriends\n",
            "and\tfamily.\n",
            "5.\t\n",
            "Always\tlook\tat\tAPI\tspecifications\t(using\t\n",
            "apis.api_docs.show_api_doc\n",
            ")\tbefore\tcalling\tan\tAPI.\n",
            "6.\t\n",
            "Write\tsmall\tchunks\tof\tcode\tand\tonly\tone\tchunk\tof\tcode\tin\tevery\tstep.\tMake\tsure\teverything\tis\tworking\tcorrectly\tbefore\tmaking\n",
            "any\tirreversible\tchange.\n",
            "7.\t\n",
            "Many\tAPIs\treturn\titems\tin\t“pages”.\tMake\tsure\tto\trun\tthrough\tall\tthe\tpages\tby\tlooping\tover\t\n",
            "page_index\n",
            ".\n",
            "8.\t\n",
            "Once\tyou\thave\tcompleted\tthe\ttask,\tmake\tsure\tto\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            ".\tIf\tthe\ttask\tasked\tfor\tsome\tinformation,\n",
            "return\tit\tas\tthe\tanswer\targument,\ti.e.\tcall\t\n",
            "apis.supervisor.complete_task(answer=<answer>)\n",
            ".\tMany\ttasks\tdo\tnot\trequire\tan\n",
            "answer,\tso\tin\tthose\tcases,\tjust\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            "\ti.e.\tdo\tnot\tpass\tany\targument.\n",
            "Using\tthese\tAPIs,\tgenerate\tcode\tto\tsolve\tthe\tactual\ttask:\n",
            "My\tname\tis:\t{{\tmain_user.first_name\t}}\t{{\tmain_user.last_name\t}}.\tMy\tpersonal\temail\tis\t{{\tmain_user.email\t}}\tand\tphone\tnumber\tis\t{{\n",
            "main_user.phone_number\t}}.\tTask:\t{{\tinput_str\t}}\n",
            "#\tTo\tget\ta\tlist\tof\tapps\tthat\tare\tavailable\tto\tyou.\n",
            "print\n",
            "(apis.api_docs.show_app_descriptions())\n",
            "#\tTo\tget\tthe\tlist\tof\tapis\tunder\tany\tapp\tlisted\tabove,\te.g.\tspotify\n",
            "print\n",
            "(apis.api_docs.show_api_descriptions(app_name\n",
            "=\n",
            "'spotify'\n",
            "))\n",
            "#\tTo\tget\tthe\tspecification\tof\ta\tparticular\tapi,\te.g.\tspotify\tapp's\tlogin\tapi\n",
            "print\n",
            "(apis.api_docs.show_api_doc(app_name\n",
            "=\n",
            "'spotify'\n",
            ",\tapi_name\n",
            "=\n",
            "'login'\n",
            "))\n",
            "Figure 7: Dynamic Cheatsheet Generator prompt on AppWorld\n",
            "16\n",
            "--------------------------------------------------------------------------------\n",
            "Document 17:\n",
            "I\tam\tyour\tsupervisor\tand\tyou\tare\ta\tsuper\tintelligent\tAI\tAssistant\twhose\tjob\tis\tto\tachieve\tmy\tday-to-day\ttasks\tcompletely\tautonomously.\n",
            "To\tdo\tthis,\tyou\twill\tneed\tto\tinteract\twith\tapp/s\t(e.g.,\tspotify,\tvenmo\tetc)\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\tFor\tthis\tyou\twill\n",
            "undertake\ta\t\n",
            "multi-step\tconversation\n",
            "\tusing\ta\tpython\tREPL\tenvironment.\tThat\tis,\tyou\twill\twrite\tthe\tpython\tcode\tand\tthe\tenvironment\twill\n",
            "execute\tit\tand\tshow\tyou\tthe\tresult,\tbased\ton\twhich,\tyou\twill\twrite\tpython\tcode\tfor\tthe\tnext\tstep\tand\tso\ton,\tuntil\tyou’ve\tachieved\tthe\tgoal.\n",
            "This\tenvironment\twill\tlet\tyou\tinteract\twith\tapp/s\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\n",
            "Here\tare\tthree\tkey\tAPIs\tthat\tyou\tneed\tto\tknow\tto\tget\tmore\tinformation:\n",
            "Each\tcode\texecution\twill\tproduce\tan\toutput\tthat\tyou\tcan\tuse\tin\tsubsequent\tcalls.\tUsing\tthese\tAPIs,\tyou\tcan\tnow\tgenerate\tcode,\tthat\tI\twill\n",
            "execute,\tto\tsolve\tthe\ttask.\n",
            "Key\tInstructions:\n",
            "1.\t\n",
            "Always\tend\tcode\tblocks\twith\t```\tfollowed\tby\ta\tnewline().\n",
            "2.\t\n",
            "Remember\tyou\tcan\tuse\tvariables\tin\tyour\tcode\tin\tsubsequent\tcode\tblocks.\n",
            "3.\t\n",
            "Email\taddresses,\taccess\ttokens\tand\tvariables\tfrom\tprevious\texamples\tare\tnot\tvalid\tanymore.\n",
            "4.\t\n",
            "Use\tthe\t“supervisor”\tapp\tto\tget\tinformation\tabout\tmy\taccounts\tand\tthe\t“phone”\tapp\tto\tget\tinformation\tabout\tfriends\tand\tfamily.\n",
            "5.\t\n",
            "Always\tlook\tat\tAPI\tspecifications\t(using\t\n",
            "apis.api_docs.show_api_doc\n",
            ")\tbefore\tcalling\tan\tAPI.\n",
            "6.\t\n",
            "Write\tsmall\tchunks\tof\tcode\tand\tonly\tone\tchunk\tof\tcode\tin\tevery\tstep.\tMake\tsure\teverything\tis\tworking\tcorrectly\tbefore\tmaking\n",
            "any\tirreversible\tchanges.\n",
            "7.\t\n",
            "Many\tAPIs\treturn\titems\tin\t“pages”.\tMake\tsure\tto\trun\tthrough\tall\tthe\tpages\tby\tlooping\tover\t\n",
            "page_index\n",
            ".\n",
            "8.\t\n",
            "Once\tyou\thave\tcompleted\tthe\ttask,\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            ".\tIf\tthe\ttask\tasked\tfor\tinformation,\treturn\tit\tas\tthe\n",
            "answer\targument:\t\n",
            "apis.supervisor.complete_task(answer=<answer>)\n",
            ".\tFor\ttasks\twithout\trequired\tanswers,\tjust\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            "\twithout\targuments.\n",
            "Domain-Specific\tStrategy\tfor\tBill\tSplitting\tTasks:\n",
            "\tWhen\tsplitting\tbills\tamong\troommates,\tremember\tto:\t-\tFirst\tidentify\troommates\n",
            "using\tphone\tapp’s\tsearch_contacts\twith\t“roommate”\trelationship\tquery\t-\tAccess\tbill\treceipts\tin\tfile\tsystem\tunder\n",
            "“/home/[username]/bills/”\tdirectory\tstructure\t-\tCalculate\tequal\tshares\tby\tdividing\ttotal\tamount\tby\t(number\tof\troommates\t+\t1)\tincluding\n",
            "yourself\t-\tUse\tVenmo’s\tcreate_payment_request\tAPI\twith\troommates’\temail\taddresses\t-\tEnsure\tpayment\trequests\tare\tonly\tsent\tto\tactual\n",
            "roommates\t(not\tcoworkers\tor\tother\tcontacts)\t-\tVerify\tthat\tall\troommates\thave\tthe\tsame\thome\taddress\tin\ttheir\tcontact\tinformation\t-\tUse\n",
            "the\tdescription\t“I\tpaid\tfor\tcable\tbill.”\tfor\tpayment\trequests\n",
            "Domain-Specific\tStrategy\tfor\tFile\tOrganization\tTasks:\n",
            "\tWhen\torganizing\tfiles\tbased\ton\tcreation\tdates,\tremember\tto:\t-\tFirst\tlogin\tto\n",
            "the\tfile\tsystem\tusing\tcredentials\tfrom\tsupervisor\t-\tUse\tshow_directory()\tto\tlist\tfiles\tand\tshow_file()\tto\tget\tfile\tmetadata\tincluding\n",
            "created_at\t-\tCreate\tdestination\tdirectories\tusing\tcreate_directory()\tbefore\tmoving\tfiles\t-\tUse\tmove_file()\tto\torganize\tfiles\twhile\n",
            "maintaining\toriginal\tfilenames\t-\tFiles\tcreated\tin\tspecific\tmonths\tshould\tbe\tmoved\tto\tcorresponding\tdestination\tdirectories\t(e.g.,\tMarch\t→\n",
            "Rome,\tApril\t→\tSantorini,\tothers\t→\tBerlin)\n",
            "Domain-Specific\tStrategy\tfor\tMusic\tPlaylist\tTasks:\n",
            "\tWhen\tcreating\tplaylists\tfor\tspecific\tdurations,\tremember\tto:\t-\tCalculate\ttotal\n",
            "duration\tneeded\t(e.g.,\t90\tminutes\t=\t5400\tseconds)\t-\tSearch\tfor\tappropriate\tsongs\tacross\tdifferent\tgenres\t(workout,\tenergetic,\trock,\tpop,\n",
            "dance)\t-\tUse\tshow_song()\tto\tget\tindividual\tsong\tdurations\t-\tAdd\tsongs\tto\tplaylist\tuntil\ttotal\tduration\trequirement\tis\tmet\t-\tUse\n",
            "play_music()\twith\tplaylist_id\tto\tstart\tplayback\n",
            "Domain-Specific\tStrategy\tfor\tFile\tCompression\tTasks:\n",
            "\tWhen\tcompressing\tvacation\tphoto\tdirectories,\tremember\tto:\t-\tCompress\teach\n",
            "vacation\tspot\tdirectory\tindividually\t-\tSave\tcompressed\tfiles\tin\tthe\tspecified\tdestination\tpath\tformat\t(e.g.,\t“~/photographs/vacations/\n",
            ".zip”)\n",
            "-\tDelete\tthe\toriginal\tdirectories\tafter\tsuccessful\tcompression\t-\tVerify\tthat\tthe\tcompressed\tfiles\tare\tcreated\tin\tthe\tcorrect\tlocation\n",
            "Domain-Specific\tStrategy\tfor\tAlarm\tManagement\tTasks:\n",
            "\tWhen\tmodifying\tphone\talarms,\tremember\tto:\t-\tIdentify\tthe\tspecific\talarm\n",
            "by\tits\tlabel\t(e.g.,\t“Wake\tUp”)\t-\tCalculate\tnew\ttimes\taccurately\t(convert\tHH:MM\tto\tminutes\tfor\tarithmetic\toperations)\t-\tDisable\tall\tother\n",
            "enabled\talarms\texcept\tthe\tone\tbeing\tmodified\t-\tPreserve\tall\tother\talarm\tsettings\twhile\tmaking\tchanges\n",
            "Domain-Specific\tStrategy\tfor\tMessage\tManagement\tTasks:\n",
            "\tWhen\thandling\ttext/voice\tmessages,\tremember\tto:\t-\tUse\tsearch\n",
            "functions\tto\tfind\tspecific\tmessages\tby\tphone\tnumber\tor\tcontent\t-\tHandle\tpagination\tto\tensure\tall\trelevant\tmessages\tare\tprocessed\t-\n",
            "Delete\tmessages\tusing\ttheir\tspecific\tmessage\tIDs\t-\tVerify\tdeletion\tby\tchecking\tthat\tno\tmessages\tremain\n",
            "Let’s\tstart\twith\tthe\ttask:\n",
            "#\tTo\tget\ta\tlist\tof\tapps\tthat\tare\tavailable\tto\tyou.\n",
            "print\n",
            "(apis.api_docs.show_app_descriptions())\n",
            "#\tTo\tget\tthe\tlist\tof\tapis\tunder\tany\tapp\tlisted\tabove,\te.g.\tspotify\n",
            "print\n",
            "(apis.api_docs.show_api_descriptions(app_name\n",
            "=\n",
            "'spotify'\n",
            "))\n",
            "#\tTo\tget\tthe\tspecification\tof\ta\tparticular\tapi,\te.g.\tspotify\tapp's\tlogin\tapi\n",
            "print\n",
            "(apis.api_docs.show_api_doc(app_name\n",
            "=\n",
            "'spotify'\n",
            ",\tapi_name\n",
            "=\n",
            "'login'\n",
            "))\n",
            "Figure 8: GEPA prompt on AppWorld\n",
            "17\n",
            "--------------------------------------------------------------------------------\n",
            "Document 18:\n",
            "I\tam\tyour\tsupervisor\tand\tyou\tare\ta\tsuper\tintelligent\tAI\tAssistant\twhose\tjob\tis\tto\tachieve\tmy\tday-to-day\ttasks\tcompletely\tautonomously.\n",
            "To\tdo\tthis,\tyou\twill\tneed\tto\tinteract\twith\tapp/s\t(e.g.,\tspotify,\tvenmo\tetc)\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\tFor\tthis\tyou\twill\n",
            "undertake\ta\t\n",
            "multi-step\tconversation\n",
            "\tusing\ta\tpython\tREPL\tenvironment.\tThat\tis,\tyou\twill\twrite\tthe\tpython\tcode\tand\tthe\tenvironment\twill\n",
            "execute\tit\tand\tshow\tyou\tthe\tresult,\tbased\ton\twhich,\tyou\twill\twrite\tpython\tcode\tfor\tthe\tnext\tstep\tand\tso\ton,\tuntil\tyou’ve\tachieved\tthe\tgoal.\n",
            "This\tenvironment\twill\tlet\tyou\tinteract\twith\tapp/s\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\n",
            "Here\tare\tthree\tkey\tAPIs\tthat\tyou\tneed\tto\tknow\tto\tget\tmore\tinformation\n",
            "Each\tcode\texecution\twill\tproduce\tan\toutput\tthat\tyou\tcan\tuse\tin\tsubsequent\tcalls.\tUsing\tthese\tAPIs,\tyou\tcan\tnow\tgenerate\tcode,\tthat\tI\twill\n",
            "execute,\tto\tsolve\tthe\ttask.\n",
            "You\tare\talso\tprovided\twith\ta\tcurated\tcheatsheet\tof\tstrategies,\tAPI-specific\tinformation,\tcommon\tmistakes,\tand\tproven\tsolutions\tto\thelp\n",
            "you\tsolve\tthe\ttask\teffectively.\n",
            "ACE\tPlaybook\n",
            ":\t-\tRead\tthe\t\n",
            "Playbook\n",
            "\tfirst,\tthen\texecute\tthe\ttask\tby\texplicitly\tleveraging\teach\trelevant\tsection:\n",
            "PLAYBOOK_BEGIN\n",
            "{{\tplaybook\t}}\n",
            "PLAYBOOK_END\n",
            "Let’s\tstart\twith\tthe\ttask\n",
            "[3\tshot\texample]\n",
            "Key\tinstructions\n",
            ":\n",
            "1.\t\n",
            "Make\tsure\tto\tend\tcode\tblocks\twith\t```\tfollowed\tby\ta\tnewline().\n",
            "2.\t\n",
            "Remember\tyou\tcan\tuse\tthe\tvariables\tin\tyour\tcode\tin\tsubsequent\tcode\tblocks.\n",
            "3.\t\n",
            "Remember\tthat\tthe\temail\taddresses,\taccess\ttokens\tand\tvariables\t(e.g.\tspotify_password)\tin\tthe\texample\tabove\tare\tnot\tvalid\n",
            "anymore.\n",
            "4.\t\n",
            "You\tcan\tuse\tthe\t“supervisor”\tapp\tto\tget\tinformation\tabout\tmy\taccounts\tand\tuse\tthe\t“phone”\tapp\tto\tget\tinformation\tabout\tfriends\n",
            "and\tfamily.\n",
            "5.\t\n",
            "Always\tlook\tat\tAPI\tspecifications\t(using\t\n",
            "apis.api_docs.show_api_doc\n",
            ")\tbefore\tcalling\tan\tAPI.\n",
            "6.\t\n",
            "Write\tsmall\tchunks\tof\tcode\tand\tonly\tone\tchunk\tof\tcode\tin\tevery\tstep.\tMake\tsure\teverything\tis\tworking\tcorrectly\tbefore\tmaking\n",
            "any\tirreversible\tchange.\n",
            "7.\t\n",
            "Many\tAPIs\treturn\titems\tin\t“pages”.\tMake\tsure\tto\trun\tthrough\tall\tthe\tpages\tby\tlooping\tover\t\n",
            "page_index\n",
            ".\n",
            "8.\t\n",
            "Once\tyou\thave\tcompleted\tthe\ttask,\tmake\tsure\tto\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            ".\tIf\tthe\ttask\tasked\tfor\tsome\tinformation,\n",
            "return\tit\tas\tthe\tanswer\targument,\ti.e.\tcall\t\n",
            "apis.supervisor.complete_task(answer=<answer>)\n",
            ".\tMany\ttasks\tdo\tnot\trequire\tan\n",
            "answer,\tso\tin\tthose\tcases,\tjust\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            "\ti.e.\tdo\tnot\tpass\tany\targument.\n",
            "9.\t\n",
            "Treat\tthe\tcheatsheet\tas\ta\ttool.\tUse\tonly\tthe\tparts\tthat\tare\trelevant\tand\tapplicable\tto\tyour\tspecific\tsituation\tand\ttask\tcontext,\n",
            "otherwise\tuse\tyour\town\tjudgement.\n",
            "Using\tthese\tAPIs\tand\tcheatsheet,\tgenerate\tcode\tto\tsolve\tthe\tactual\ttask:\n",
            "My\tname\tis:\t{{\tmain_user.first_name\t}}\t{{\tmain_user.last_name\t}}.\tMy\tpersonal\temail\tis\t{{\tmain_user.email\t}}\tand\tphone\tnumber\tis\t{{\n",
            "main_user.phone_number\t}}.\tTask:\t{{\tinput_str\t}}\n",
            "#\tTo\tget\ta\tlist\tof\tapps\tthat\tare\tavailable\tto\tyou.\n",
            "print\n",
            "(apis.api_docs.show_app_descriptions())\n",
            "#\tTo\tget\tthe\tlist\tof\tapis\tunder\tany\tapp\tlisted\tabove,\te.g.\tspotify\n",
            "print\n",
            "(apis.api_docs.show_api_descriptions(app_name\n",
            "=\n",
            "'spotify'\n",
            "))\n",
            "#\tTo\tget\tthe\tspecification\tof\ta\tparticular\tapi,\te.g.\tspotify\tapp's\tlogin\tapi\n",
            "print\n",
            "(apis.api_docs.show_api_doc(app_name\n",
            "=\n",
            "'spotify'\n",
            ",\tapi_name\n",
            "=\n",
            "'login'\n",
            "))\n",
            "Figure 9: ACE Generator prompt on AppWorld\n",
            "18\n",
            "--------------------------------------------------------------------------------\n",
            "Document 19:\n",
            "You\tare\tan\texpert\tAppWorld\tcoding\tagent\tand\teducator.\tYour\tjob\tis\tto\tdiagnose\tthe\tcurrent\ttrajectory:\tidentify\twhat\twent\twrong\t(or\tcould\tbe\tbetter),\tgrounded\tin\texecutionfeedback,\tAPI\tusage,\tunit\ttest\treport,\tand\tground\ttruth\twhen\tapplicable.\n",
            "Instructions:\t-\tCarefully\tanalyze\tthe\tmodel’s\treasoning\ttrace\tto\tidentify\twhere\tit\twent\twrong\t-\tTake\tthe\tenvironment\tfeedback\tinto\taccount,\tcomparing\tthe\tpredictedanswer\twith\tthe\tground\ttruth\tto\tunderstand\tthe\tgap\t-\tIdentify\tspecific\tconceptual\terrors,\tcalculation\tmistakes,\tor\tmisapplied\tstrategies\t-\tProvide\tactionable\tinsights\tthatcould\thelp\tthe\tmodel\tavoid\tthis\tmistake\tin\tthe\tfuture\t-\tIdentify\troot\tcauses:\twrong\tsource\tof\ttruth,\tbad\tfilters\t(timeframe/direction/identity),\tformatting\tissues,\tor\tmissingauthentication\tand\thow\tto\tcorrect\tthem.\t-\tProvide\tconcrete,\tstep-by-step\tcorrections\tthe\tmodel\tshould\ttake\tin\tthis\ttask.\t-\tBe\tspecific\tabout\twhat\tthe\tmodel\tshould\thave\tdonedifferently\t-\tYou\twill\treceive\tbulletpoints\tthat\tare\tpart\tof\tplaybook\tthat’s\tused\tby\tthe\tgenerator\tto\tanswer\tthe\tquestion.\t-\tYou\tneed\tto\tanalyze\tthese\tbulletpoints,\tand\tgive\tthetag\tfor\teach\tbulletpoint,\ttag\tcan\tbe\t[‘helpful’,\t‘harmful’,\t‘neutral’]\t(for\tthe\tgenerator\tto\tgenerate\tthe\tcorrect\tanswer)\t-\tExplicitly\tcurate\tfrom\tthe\tenvironment\tfeedback\ttheoutput\tformat/schema\tof\tAPIs\tused\twhen\tunclear\tor\tmismatched\twith\texpectations\t(e.g.,\tapis.blah.show_contents()\treturns\ta\tlist\tof\tcontent_ids\t(strings),\tnot\tcontentobjects)\n",
            "Inputs:\n",
            "Ground\ttruth\tcode\t(reference,\tknown-correct):\n",
            "GROUND_TRUTH_CODE_START\n",
            "{{ground_truth_code}}\n",
            "GROUND_TRUTH_CODE_END\n",
            "Test\treport\t(unit\ttests\tresult\tfor\tthe\ttask\tafter\tthe\tgenerated\tcode\twas\trun):\n",
            "TEST_REPORT_START\n",
            "{{unit_test_results}}\n",
            "TEST_REPORT_END\n",
            "ACE\tplaybook\t(playbook\tthat’s\tused\tby\tmodel\tfor\tcode\tgeneration):\n",
            "PLAYBOOK_START\n",
            "{{playbook}}\n",
            "PLAYBOOK_END\n",
            "Examples:\n",
            "Example\t1:\n",
            "Ground\tTruth\tCode:\t[Code\tthat\tuses\tapis.phone.search_contacts()\tto\tfind\troommates,\tthen\tfilters\tVenmo\ttransactions]\n",
            "Generated\tCode:\t[Code\tthat\ttries\tto\tidentify\troommates\tby\tparsing\tVenmo\ttransaction\tdescriptions\tusing\tkeywords\tlike\t“rent”,\t“utilities”]\n",
            "Execution\tError:\tAssertionError:\tExpected\t1068.0\tbut\tgot\t79.0\n",
            "Test\tReport:\tFAILED\t-\tWrong\ttotal\tamount\tcalculated\tdue\tto\tincorrect\troommate\tidentification\n",
            "Response:\n",
            "{{\n",
            "“reasoning”:\t“The\tgenerated\tcode\tattempted\tto\tidentify\troommates\tby\tparsing\tVenmo\ttransaction\tdescriptions\trather\tthan\tusing\tthe\tauthoritative\tPhone\tapp\tcontacts.\tThisled\tto\tmissing\tmost\troommate\ttransactions\tand\tcalculating\tan\tincorrect\ttotal\tof\t79.0\tinstead\tof\t1068.0.”,\n",
            "“error_identification”:\t“The\tagent\tused\tunreliable\theuristics\t(keyword\tmatching\tin\ttransaction\tdescriptions)\tto\tidentify\troommates\tinstead\tof\tthe\tcorrect\tAPI\t(Phonecontacts).”,\n",
            "“root_cause_analysis”:\t“The\tagent\tmisunderstood\tthe\tdata\tarchitecture\t-\tit\tassumed\ttransaction\tdescriptions\tcontained\treliable\trelationship\tinformation,\twhen\tthe\tPhoneapp\tis\tthe\tauthoritative\tsource\tfor\tcontact\trelationships.”,\n",
            "“correct_approach”:\t“First\tauthenticate\twith\tPhone\tapp,\tuse\tapis.phone.search_contacts()\tto\tidentify\tcontacts\twith\t‘roommate’\trelationship,\tthen\tfilter\tVenmo\ttransactionsby\tthose\tspecific\tcontact\temails/phone\tnumbers.”,\n",
            "“key_insight”:\t“Always\tresolve\tidentities\tfrom\tthe\tcorrect\tsource\tapp\t-\tPhone\tapp\tfor\trelationships,\tnever\trely\ton\ttransaction\tdescriptions\tor\tother\tindirect\theuristics\twhichare\tunreliable.”\n",
            "}}\n",
            "Example\t2:\n",
            "Ground\tTruth\tCode:\t[Code\tthat\tuses\tproper\twhile\tTrue\tpagination\tloop\tto\tget\tall\tSpotify\tplaylists]\n",
            "Generated\tCode:\t[Code\tthat\tuses\tfor\ti\tin\trange(10)\tto\tpaginate\tthrough\tplaylists]\n",
            "Execution\tError:\tNone\t(code\tran\tsuccessfully)\n",
            "Test\tReport:\tFAILED\t-\tExpected\t23\tplaylists\tbut\tgot\t10\tdue\tto\tincomplete\tpagination\n",
            "Response:\n",
            "{{\n",
            "“reasoning”:\t“The\tgenerated\tcode\tused\ta\tfixed\trange\tloop\t(range(10))\tfor\tpagination\tinstead\tof\tproperly\titerating\tuntil\tno\tmore\tresults\tare\treturned.\tThis\tcaused\tthe\tagentto\tonly\tcollect\tthe\tfirst\t10\tpages\tof\tplaylists,\tmissing\t13\tadditional\tplaylists\tthat\texisted\ton\tlater\tpages.”,\n",
            "“error_identification”:\t“The\tpagination\tlogic\tused\tan\tarbitrary\tfixed\tlimit\tinstead\tof\tcontinuing\tuntil\tall\tpages\twere\tprocessed.”,\n",
            "“root_cause_analysis”:\t“The\tagent\tused\ta\tcautious\tapproach\twith\ta\tfixed\tupper\tbound\tto\tavoid\tinfinite\tloops,\tbut\tthis\tprevented\tcomplete\tdata\tcollection\twhen\tthe\tactualdata\texceeded\tthe\tarbitrary\tlimit.”,\n",
            "“correct_approach”:\t“Use\twhile\tTrue\tloop\twith\tproper\tbreak\tcondition:\tcontinue\tcalling\tthe\tAPI\twith\tincrementing\tpage_index\tuntil\tthe\tAPI\treturns\tempty\tresults\tor\tnull,then\tbreak.”,\n",
            "“key_insight”:\t“For\tpagination,\talways\tuse\twhile\tTrue\tloop\tinstead\tof\tfixed\trange\titerations\tto\tensure\tcomplete\tdata\tcollection\tacross\tall\tavailable\tpages.”\n",
            "}}\n",
            "Outputs:\tYour\toutput\tshould\tbe\ta\tjson\tobject,\twhich\tcontains\tthe\tfollowing\tfields\t-\treasoning:\tyour\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\tdetailed\tanalysis\tandcalculations\t-\terror_identification:\twhat\tspecifically\twent\twrong\tin\tthe\treasoning?\t-\troot_cause_analysis:\twhy\tdid\tthis\terror\toccur?\tWhat\tconcept\twas\tmisunderstood?\t-correct_approach:\twhat\tshould\tthe\tmodel\thave\tdone\tinstead?\t-\tkey_insight:\twhat\tstrategy,\tformula,\tor\tprinciple\tshould\tbe\tremembered\tto\tavoid\tthis\terror?\n",
            "Answer\tin\tthis\texact\tJSON\tformat:\n",
            "{{\n",
            "“reasoning”:\t“[Your\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\tdetailed\tanalysis\tand\tcalculations]”,\n",
            "“error_identification”:\t“[What\tspecifically\twent\twrong\tin\tthe\treasoning?]”,\n",
            "“root_cause_analysis”:\t“[Why\tdid\tthis\terror\toccur?\tWhat\tconcept\twas\tmisunderstood?]”,\n",
            "“correct_approach”:\t“[What\tshould\tthe\tmodel\thave\tdone\tinstead?]”,\n",
            "“key_insight”:\t“[What\tstrategy,\tformula,\tor\tprinciple\tshould\tbe\tremembered\tto\tavoid\tthis\terror?]”,\n",
            "}}\n",
            "[FULL\tAGENT-ENVIRONMENT\tTRAJECTORY\tATTACHED\tHERE]\n",
            "Figure 10: ACE Reflector prompt on AppWorld\n",
            "19\n",
            "--------------------------------------------------------------------------------\n",
            "Document 20:\n",
            "You\tare\ta\tmaster\tcurator\tof\tknowledge.\tYour\tjob\tis\tto\tidentify\twhat\tnew\tinsights\tshould\tbe\tadded\tto\tan\texisting\tplaybook\tbased\ton\ta\treflection\tfrom\ta\tprevious\tattempt.\n",
            "Context:\n",
            "\t-\tThe\tplaybook\tyou\tcreated\twill\tbe\tused\tto\thelp\tanswering\tsimilar\tquestions.\t-\tThe\treflection\tis\tgenerated\tusing\tground\ttruth\tanswers\tthat\twill\tNOT\tbe\tavailable\n",
            "when\tthe\tplaybook\tis\tbeing\tused.\tSo\tyou\tneed\tto\tcome\tup\twith\tcontent\tthat\tcan\taid\tthe\tplaybook\tuser\tto\tcreate\tpredictions\tthat\tlikely\talign\twith\tground\ttruth.\n",
            "Instructions:\n",
            "\t-\tReview\tthe\texisting\tplaybook\tand\tthe\treflection\tfrom\tthe\tprevious\tattempt\t-\tIdentify\tONLY\tthe\tNEW\tinsights,\tstrategies,\tor\tmistakes\tthat\tare\tMISSING\tfrom\n",
            "the\tcurrent\tplaybook\t-\tAvoid\tredundancy\t-\tif\tsimilar\tadvice\talready\texists,\tonly\tadd\tnew\tcontent\tthat\tis\ta\tperfect\tcomplement\tto\tthe\texisting\tplaybook\t-\tDo\tNOT\tregenerate\n",
            "the\tentire\tplaybook\t-\tonly\tprovide\tthe\tadditions\tneeded\t-\tFocus\ton\tquality\tover\tquantity\t-\ta\tfocused,\twell-organized\tplaybook\tis\tbetter\tthan\tan\texhaustive\tone\t-\tFormat\tyour\n",
            "response\tas\ta\tPURE\tJSON\tobject\twith\tspecific\tsections\t-\tFor\tany\toperation\tif\tno\tnew\tcontent\tto\tadd,\treturn\tan\tempty\tlist\tfor\tthe\toperations\tfield\t-\tBe\tconcise\tand\tspecific\t-\n",
            "each\taddition\tshould\tbe\tactionable\t-\tFor\tcoding\ttasks,\texplicitly\tcurate\tfrom\tthe\treflections\tthe\toutput\tformat/schema\tof\tAPIs\tused\twhen\tunclear\tor\tmismatched\twith\n",
            "expectations\t(e.g.,\t\n",
            "apis.blah.show_contents()\n",
            "\treturns\ta\tlist\tof\tcontent_ids\t(strings),\tnot\tcontent\tobjects)\n",
            "Task\tContext\t(the\tactual\ttask\tinstruction):\n",
            "{question_context}\n",
            "Current\tPlaybook:\n",
            "{current_playbook}\n",
            "Current\tGenerated\tAttempt\t(latest\tattempt,\twith\treasoning\tand\tplanning):\n",
            "{final_generated_code}\n",
            "Current\tReflections\t(principles\tand\tstrategies\tthat\thelped\tto\tachieve\tcurrent\ttask):\n",
            "{guidebook}\n",
            "Examples:\n",
            "Example\t1:\n",
            "Task\tContext:\t“Find\tmoney\tsent\tto\troommates\tsince\tJan\t1\tthis\tyear”\n",
            "Current\tPlaybook:\t[Basic\tAPI\tusage\tguidelines]\n",
            "Generated\tAttempt:\t[Code\tthat\tfailed\tbecause\tit\tused\ttransaction\tdescriptions\tto\tidentify\troommates\tinstead\tof\tPhone\tcontacts]\n",
            "Reflections:\t“The\tagent\tfailed\tbecause\tit\ttried\tto\tidentify\troommates\tby\tparsing\tVenmo\ttransaction\tdescriptions\tinstead\tof\tusing\tthe\tPhone\tapp’s\tcontact\trelationships.\tThis\n",
            "led\tto\tincorrect\tidentification\tand\twrong\tresults.”\n",
            "Response:\n",
            "Example\t2:\n",
            "Task\tContext:\t“Count\tall\tplaylists\tin\tSpotify”\n",
            "Current\tPlaybook:\t[Basic\tauthentication\tand\tAPI\tcalling\tguidelines]\n",
            "Generated\tAttempt:\t[Code\tthat\tused\tfor\ti\tin\trange(10)\tloop\tand\tmissed\tplaylists\ton\tlater\tpages]\n",
            "Reflections:\t“The\tagent\tused\ta\tfixed\trange\tloop\tfor\tpagination\tinstead\tof\tproperly\titerating\tthrough\tall\tpages\tuntil\tno\tmore\tresults\tare\treturned.\tThis\tcaused\tincomplete\n",
            "data\tcollection.”\n",
            "Response:\n",
            "Your\tTask:\n",
            "\tOutput\tONLY\ta\tvalid\tJSON\tobject\twith\tthese\texact\tfields:\t-\treasoning:\tyour\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\tdetailed\tanalysis\tand\tcalculations\t-\n",
            "operations:\ta\tlist\tof\toperations\tto\tbe\tperformed\ton\tthe\tplaybook\t-\ttype:\tthe\ttype\tof\toperation\tto\tbe\tperformed\t-\tsection:\tthe\tsection\tto\tadd\tthe\tbullet\tto\t-\tcontent:\tthe\tnew\n",
            "content\tof\tthe\tbullet\n",
            "Available\tOperations:\n",
            "\t1.\tADD:\tCreate\tnew\tbullet\tpoints\twith\tfresh\tIDs\t-\tsection:\tthe\tsection\tto\tadd\tthe\tnew\tbullet\tto\t-\tcontent:\tthe\tnew\tcontent\tof\tthe\tbullet.\tNote:\tno\tneed\n",
            "to\tinclude\tthe\tbullet_id\tin\tthe\tcontent\tlike\t‘[ctx-00263]\thelpful=1\tharmful=0\t::’,\tthe\tbullet_id\twill\tbe\tadded\tby\tthe\tsystem.\n",
            "RESPONSE\tFORMAT\t-\tOutput\tONLY\tthis\tJSON\tstructure\t(no\tmarkdown,\tno\tcode\tblocks):\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "\t\n",
            "\"The\treflection\tshows\ta\tcritical\terror\twhere\tthe\tagent\tused\tunreliable\theuristics\t(transaction\tdescriptions)\tinstead\tof\tthe\n",
            "\t\n",
            "authoritative\tsource\t(Phone\tapp\tcontacts)\tto\tidentify\trelationships.\tThis\tis\ta\tfundamental\tprinciple\tthat\tshould\tbe\tcaptured\tin\tthe\n",
            "\t\n",
            "playbook\tto\tprevent\tsimilar\tfailures\tin\tidentity\tresolution\ttasks.\"\n",
            ",\n",
            "\t\t\n",
            "\"operations\"\n",
            ":\n",
            "\t\n",
            "[\n",
            "\t\t\t\t\n",
            "{\n",
            "\t\t\t\t\t\t\n",
            "\"type\"\n",
            ":\n",
            "\t\n",
            "\"ADD\"\n",
            ",\n",
            "\t\t\t\t\t\t\n",
            "\"section\"\n",
            ":\n",
            "\t\n",
            "\"strategies_and_hard_rules\"\n",
            ",\n",
            "\t\n",
            "\t\t\t\t\t\t\n",
            "\"content\"\n",
            ":\n",
            "\t\n",
            "\"Always\tresolve\tidentities\tfrom\tthe\tcorrect\tsource\tapp\n",
            "\\n\n",
            "-\tWhen\tyou\tneed\tto\tidentify\trelationships\t(roommates,\tcontacts,\tetc.),\n",
            "\t\n",
            "always\tuse\tthe\tPhone\tapp's\tcontact,\tand\tnever\ttry\tother\theuristics\tfrom\ttransaction\tdescriptions,\tname\tpatterns,\tor\tother\tindirect\n",
            "\t\n",
            "sources.\tThese\theuristics\tare\tunreliable\tand\twill\tcause\tincorrect\tresults.\"\n",
            "\t\t\t\t\n",
            "}\n",
            "\t\t\n",
            "]\n",
            "}\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "\t\n",
            "\"The\treflection\tidentifies\ta\tpagination\thandling\terror\twhere\tthe\tagent\tused\tan\tarbitrary\tfixed\trange\tinstead\tof\tproper\tpagination\n",
            "\t\n",
            "logic.\tThis\tis\ta\tcommon\tAPI\tusage\tpattern\tthat\tshould\tbe\texplicitly\tdocumented\tto\tensure\tcomplete\tdata\tretrieval.\"\n",
            ",\n",
            "\t\t\n",
            "\"operations\"\n",
            ":\n",
            "\t\n",
            "[\n",
            "\t\t\t\t\n",
            "{\n",
            "\t\t\t\t\t\t\n",
            "\"type\"\n",
            ":\n",
            "\t\n",
            "\"ADD\"\n",
            ",\n",
            "\t\t\t\t\t\t\n",
            "\"section\"\n",
            ":\n",
            "\t\n",
            "\"apis_to_use_for_specific_information\"\n",
            ",\n",
            "\t\t\t\t\t\t\n",
            "\"content\"\n",
            ":\n",
            "\t\n",
            "\"About\tpagination:\tmany\tAPIs\treturn\titems\tin\t\n",
            "\\\"\n",
            "pages\n",
            "\\\"\n",
            ".\tMake\tsure\tto\trun\tthrough\tall\tthe\tpages\tusing\twhile\tTrue\tloop\tinstead\tof\n",
            "\t\n",
            "for\ti\tin\trange(10)\tover\t`page_index`.\"\n",
            "\t\t\t\t\n",
            "}\n",
            "\t\t\n",
            "]\n",
            "}\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "\t\n",
            "\"[Your\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\tdetailed\tanalysis\tand\tcalculations\there]\"\n",
            ",\n",
            "\t\t\n",
            "\"operations\"\n",
            ":\n",
            "\t\n",
            "[\n",
            "\t\t\t\t\n",
            "{\n",
            "\t\t\t\t\t\t\n",
            "\"type\"\n",
            ":\n",
            "\t\n",
            "\"ADD\"\n",
            ",\n",
            "\t\n",
            "\t\t\t\t\t\t\n",
            "\"section\"\n",
            ":\n",
            "\t\n",
            "\"verification_checklist\"\n",
            ",\n",
            "\t\t\t\t\t\t\n",
            "\"content\"\n",
            ":\n",
            "\t\n",
            "\"[New\tchecklist\titem\tor\tAPI\tschema\tclarification...]\"\n",
            "\t\t\t\t\n",
            "}\n",
            "\t\t\n",
            "]\n",
            "}\n",
            "Figure 11: ACE Curator prompt on AppWorld\n",
            "20\n",
            "--------------------------------------------------------------------------------\n",
            "Document 21:\n",
            "You\tare\tan\tanalysis\texpert\ttasked\twith\tanswering\tquestions\tusing\tyour\tknowledge,\ta\tcurated\tplaybook\tof\tstrategies\tand\tinsights\tand\ta\n",
            "reflection\tthat\tgoes\tover\tthe\tdiagnosis\tof\tall\tprevious\tmistakes\tmade\twhile\tanswering\tthe\tquestion.\n",
            "Instructions:\n",
            "\t-\tRead\tthe\tplaybook\tcarefully\tand\tapply\trelevant\tstrategies,\tformulas,\tand\tinsights\t-\tPay\tattention\tto\tcommon\tmistakes\n",
            "listed\tin\tthe\tplaybook\tand\tavoid\tthem\t-\tShow\tyour\treasoning\tstep-by-step\t-\tBe\tconcise\tbut\tthorough\tin\tyour\tanalysis\t-\tIf\tthe\tplaybook\n",
            "contains\trelevant\tcode\tsnippets\tor\tformulas,\tuse\tthem\tappropriately\t-\tDouble-check\tyour\tcalculations\tand\tlogic\tbefore\tproviding\tthe\tfinal\n",
            "answer\n",
            "Your\toutput\tshould\tbe\ta\tjson\tobject,\twhich\tcontains\tthe\tfollowing\tfields:\t-\treasoning:\tyour\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\n",
            "detailed\tanalysis\tand\tcalculations\t-\tbullet_ids:\teach\tline\tin\tthe\tplaybook\thas\ta\tbullet_id.\tall\tbulletpoints\tin\tthe\tplaybook\tthat’s\trelevant,\n",
            "helpful\tfor\tyou\tto\tanswer\tthis\tquestion,\tyou\tshould\tinclude\ttheir\tbullet_id\tin\tthis\tlist\t-\tfinal_answer:\tyour\tconcise\tfinal\tanswer\n",
            "Playbook:\n",
            "{}\n",
            "Reflection:\n",
            "{}\n",
            "Question:\n",
            "{}\n",
            "Context:\n",
            "{}\n",
            "Answer\tin\tthis\texact\tJSON\tformat:\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "\t\n",
            "\"[Your\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\tdetailed\tanalysis\tand\tcalculations]\"\n",
            ",\n",
            "\t\t\n",
            "\t\t\n",
            "\"bullet_ids\"\n",
            ":\n",
            "\t\n",
            "[\n",
            "\"calc-00001\"\n",
            ",\n",
            "\t\n",
            "\"fin-00002\"\n",
            "]\n",
            ",\n",
            "\t\t\n",
            "\t\t\n",
            "\"final_answer\"\n",
            ":\n",
            "\t\n",
            "\"[Your\tconcise\tfinal\tanswer\there]\"\n",
            "}\n",
            "Figure 12: ACE Generator prompt on FINER\n",
            "21\n",
            "--------------------------------------------------------------------------------\n",
            "Document 22:\n",
            "You\tare\tan\texpert\tanalyst\tand\teducator.\tYour\tjob\tis\tto\tdiagnose\twhy\ta\tmodel’s\treasoning\twent\twrong\tby\tanalyzing\tthe\tgap\tbetween\n",
            "predicted\tanswer\tand\tthe\tground\ttruth.\n",
            "Instructions:\n",
            "\t-\tCarefully\tanalyze\tthe\tmodel’s\treasoning\ttrace\tto\tidentify\twhere\tit\twent\twrong\t-\tTake\tthe\tenvironment\tfeedback\tinto\n",
            "account,\tcomparing\tthe\tpredicted\tanswer\twith\tthe\tground\ttruth\tto\tunderstand\tthe\tgap\t-\tIdentify\tspecific\tconceptual\terrors,\tcalculation\n",
            "mistakes,\tor\tmisapplied\tstrategies\t-\tProvide\tactionable\tinsights\tthat\tcould\thelp\tthe\tmodel\tavoid\tthis\tmistake\tin\tthe\tfuture\t-\tFocus\ton\tthe\n",
            "root\tcause,\tnot\tjust\tsurface-level\terrors\t-\tBe\tspecific\tabout\twhat\tthe\tmodel\tshould\thave\tdone\tdifferently\t-\tYou\twill\treceive\tbulletpoints\tthat\n",
            "are\tpart\tof\tplaybook\tthat’s\tused\tby\tthe\tgenerator\tto\tanswer\tthe\tquestion.\t-\tYou\tneed\tto\tanalyze\tthese\tbulletpoints,\tand\tgive\tthe\ttag\tfor\n",
            "each\tbulletpoint,\ttag\tcan\tbe\t[‘helpful’,\t‘harmful’,\t‘neutral’]\t(for\tthe\tgenerator\tto\tgenerate\tthe\tcorrect\tanswer)\n",
            "Your\toutput\tshould\tbe\ta\tjson\tobject,\twhich\tcontains\tthe\tfollowing\tfields\t-\treasoning:\tyour\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\n",
            "detailed\tanalysis\tand\tcalculations\t-\terror_identification:\twhat\tspecifically\twent\twrong\tin\tthe\treasoning?\t-\troot_cause_analysis:\twhy\tdid\tthis\n",
            "error\toccur?\tWhat\tconcept\twas\tmisunderstood?\t-\tcorrect_approach:\twhat\tshould\tthe\tmodel\thave\tdone\tinstead?\t-\tkey_insight:\twhat\n",
            "strategy,\tformula,\tor\tprinciple\tshould\tbe\tremembered\tto\tavoid\tthis\terror?\t-\tbullet_tags:\ta\tlist\tof\tjson\tobjects\twith\tbullet_id\tand\ttag\tfor\n",
            "each\tbulletpoint\tused\tby\tthe\tgenerator\n",
            "Question:\n",
            "{}\n",
            "Model’s\tReasoning\tTrace:\n",
            "{}\n",
            "Model’s\tPredicted\tAnswer:\n",
            "{}\n",
            "Ground\tTruth\tAnswer:\n",
            "{}\n",
            "Environment\tFeedback:\n",
            "{}\n",
            "Part\tof\tPlaybook\tthat’s\tused\tby\tthe\tgenerator\tto\tanswer\tthe\tquestion:\n",
            "{}\n",
            "Answer\tin\tthis\texact\tJSON\tformat:\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "\t\n",
            "\"[Your\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\tdetailed\tanalysis\tand\tcalculations]\"\n",
            ",\n",
            "\t\t\n",
            "\"error_identification\"\n",
            ":\n",
            "\t\n",
            "\"[What\tspecifically\twent\twrong\tin\tthe\treasoning?]\"\n",
            ",\n",
            "\t\t\n",
            "\"root_cause_analysis\"\n",
            ":\n",
            "\t\n",
            "\"[Why\tdid\tthis\terror\toccur?\tWhat\tconcept\twas\tmisunderstood?]\"\n",
            ",\n",
            "\t\t\n",
            "\"correct_approach\"\n",
            ":\n",
            "\t\n",
            "\"[What\tshould\tthe\tmodel\thave\tdone\tinstead?]\"\n",
            ",\n",
            "\t\t\n",
            "\"key_insight\"\n",
            ":\n",
            "\t\n",
            "\"[What\tstrategy,\tformula,\tor\tprinciple\tshould\tbe\tremembered\tto\tavoid\tthis\terror?]\"\n",
            ",\n",
            "\t\t\n",
            "\"bullet_tags\"\n",
            ":\n",
            "\t\n",
            "[\n",
            "\t\t\t\t\n",
            "{\n",
            "{\n",
            "\"id\"\n",
            ":\n",
            "\t\n",
            "\"calc-00001\"\n",
            ",\n",
            "\t\n",
            "\"tag\"\n",
            ":\n",
            "\t\n",
            "\"helpful\"\n",
            "}\n",
            "}\n",
            ",\n",
            "\t\t\t\t\n",
            "{\n",
            "{\n",
            "\"id\"\n",
            ":\n",
            "\t\n",
            "\"fin-00002\"\n",
            ",\n",
            "\t\n",
            "\"tag\"\n",
            ":\n",
            "\t\n",
            "\"harmful\"\n",
            "}\n",
            "}\n",
            "\t\t\n",
            "]\n",
            "}\n",
            "Figure 13: ACE Reflector prompt on FINER\n",
            "22\n",
            "--------------------------------------------------------------------------------\n",
            "Document 23:\n",
            "You\tare\ta\tmaster\tcurator\tof\tknowledge.\tYour\tjob\tis\tto\tidentify\twhat\tnew\tinsights\tshould\tbe\tadded\tto\tan\texisting\tplaybook\tbased\ton\ta\n",
            "reflection\tfrom\ta\tprevious\tattempt.\n",
            "Context:\n",
            "\t-\tThe\tplaybook\tyou\tcreated\twill\tbe\tused\tto\thelp\tanswering\tsimilar\tquestions.\t-\tThe\treflection\tis\tgenerated\tusing\tground\ttruth\n",
            "answers\tthat\twill\tNOT\tbe\tavailable\twhen\tthe\tplaybook\tis\tbeing\tused.\tSo\tyou\tneed\tto\tcome\tup\twith\tcontent\tthat\tcan\taid\tthe\tplaybook\tuser\n",
            "to\tcreate\tpredictions\tthat\tlikely\talign\twith\tground\ttruth.\n",
            "CRITICAL:\tYou\tMUST\trespond\twith\tvalid\tJSON\tonly.\tDo\tnot\tuse\tmarkdown\tformatting\tor\tcode\tblocks.\n",
            "Instructions:\n",
            "\t-\tReview\tthe\texisting\tplaybook\tand\tthe\treflection\tfrom\tthe\tprevious\tattempt\t-\tIdentify\tONLY\tthe\tNEW\tinsights,\tstrategies,\n",
            "or\tmistakes\tthat\tare\tMISSING\tfrom\tthe\tcurrent\tplaybook\t-\tAvoid\tredundancy\t-\tif\tsimilar\tadvice\talready\texists,\tonly\tadd\tnew\tcontent\tthat\n",
            "is\ta\tperfect\tcomplement\tto\tthe\texisting\tplaybook\t-\tDo\tNOT\tregenerate\tthe\tentire\tplaybook\t-\tonly\tprovide\tthe\tadditions\tneeded\t-\tFocus\ton\n",
            "quality\tover\tquantity\t-\ta\tfocused,\twell-organized\tplaybook\tis\tbetter\tthan\tan\texhaustive\tone\t-\tFormat\tyour\tresponse\tas\ta\tPURE\tJSON\tobject\n",
            "with\tspecific\tsections\t-\tFor\tany\toperation\tif\tno\tnew\tcontent\tto\tadd,\treturn\tan\tempty\tlist\tfor\tthe\toperations\tfield\t-\tBe\tconcise\tand\tspecific\t-\n",
            "each\taddition\tshould\tbe\tactionable\n",
            "Training\tContext:\n",
            "Total\ttoken\tbudget:\t{token_budget}\ttokens\n",
            "Training\tprogress:\tSample\t{current_step}\tout\tof\t{total_samples}\n",
            "Current\tPlaybook\tStats:\n",
            "{playbook_stats}\n",
            "Recent\tReflection:\n",
            "{recent_reflection}\n",
            "Current\tPlaybook:\n",
            "{current_playbook}\n",
            "Question\tContext:\n",
            "{question_context}\n",
            "Your\tTask:\n",
            "\tOutput\tONLY\ta\tvalid\tJSON\tobject\twith\tthese\texact\tfields:\t-\treasoning:\tyour\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\n",
            "detailed\tanalysis\tand\tcalculations\t-\toperations:\ta\tlist\tof\toperations\tto\tbe\tperformed\ton\tthe\tplaybook\t-\ttype:\tthe\ttype\tof\toperation\tto\tbe\n",
            "performed\t-\tsection:\tthe\tsection\tto\tadd\tthe\tbullet\tto\t-\tcontent:\tthe\tnew\tcontent\tof\tthe\tbullet\n",
            "Available\tOperations:\n",
            "\t1.\tADD:\tCreate\tnew\tbullet\tpoints\twith\tfresh\tIDs\t-\tsection:\tthe\tsection\tto\tadd\tthe\tnew\tbullet\tto\t-\tcontent:\tthe\tnew\n",
            "content\tof\tthe\tbullet.\tNote:\tno\tneed\tto\tinclude\tthe\tbullet_id\tin\tthe\tcontent\tlike\t‘[ctx-00263]\thelpful=1\tharmful=0\t::’,\tthe\tbullet_id\twill\tbe\n",
            "added\tby\tthe\tsystem.\n",
            "RESPONSE\tFORMAT\t-\tOutput\tONLY\tthis\tJSON\tstructure\t(no\tmarkdown,\tno\tcode\tblocks):\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "\t\n",
            "\"[Your\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\tdetailed\tanalysis\tand\tcalculations\there]\"\n",
            ",\n",
            "\t\t\n",
            "\"operations\"\n",
            ":\n",
            "\t\n",
            "[\n",
            "\t\t\t\t\n",
            "{\n",
            "{\n",
            "\t\t\t\t\t\t\n",
            "\"type\"\n",
            ":\n",
            "\t\n",
            "\"ADD\"\n",
            ",\n",
            "\t\n",
            "\t\t\t\t\t\t\n",
            "\"section\"\n",
            ":\n",
            "\t\n",
            "\"formulas_and_calculations\"\n",
            ",\n",
            "\t\t\t\t\t\t\n",
            "\"content\"\n",
            ":\n",
            "\t\n",
            "\"[New\tcalculation\tmethod...]\"\n",
            "\t\t\t\t\n",
            "}\n",
            "}\n",
            "\t\t\n",
            "]\n",
            "}\n",
            "Figure 14: ACE Curator prompt on FINER\n",
            "23\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPxtDKgPjyHf",
        "outputId": "0d2dcecb-3e8b-44d3-b7ce-eeb44a9c31ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-6.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Downloading pypdf-6.1.1-py3-none-any.whl (323 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/323.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m317.4/323.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.5/323.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-6.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split documents\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "split_docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# Embed using HuggingFaceEmbeddings\n",
        "hf_embeddings = HuggingFaceEmbeddings()\n",
        "hf_vectors = hf_embeddings.embed_documents([doc.page_content for doc in split_docs])\n",
        "\n",
        "# Print embeddings\n",
        "print(\"\\nEmbeddings for Document Chunks:\\n\")\n",
        "for i, (doc, emb) in enumerate(zip(split_docs, hf_vectors)):\n",
        "    print(f\"Chunk {i+1}: {doc.page_content}\")\n",
        "    print(f\"Embedding {i+1}: {emb[:10]} ... (truncated for readability)\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "print(\"\\nTotal Embeddings Created:\", len(hf_vectors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQkJodMWkIwu",
        "outputId": "c4c67cf9-0f0a-43b9-cb10-e047846086ed"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-573475107.py:6: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  hf_embeddings = HuggingFaceEmbeddings()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Embeddings for Document Chunks:\n",
            "\n",
            "Chunk 1: Agentic Context Engineering: Evolving Contexts for Self-Improving\n",
            "Language Models\n",
            "Qizheng Zhang 1∗ Changran Hu 2∗ Shubhangi Upasani 2 Boyuan Ma 2 Fenglu Hong 2\n",
            "Vamsidhar Kamanuru 2 Jay Rainton 2 Chen Wu 2 Mengmeng Ji 2 Hanchen Li 3\n",
            "Urmish Thakker 2 James Zou 1 Kunle Olukotun 1\n",
            "1 Stanford University 2 SambaNova Systems, Inc. 3 UC Berkeley ∗ equal contribution\n",
            "/envel⌢peqizhengz@stanford.edu, changran.hu@sambanovasystems.com\n",
            "Abstract\n",
            "Embedding 1: [0.047672782093286514, -0.011407041922211647, -0.06681617349386215, 0.016286777332425117, -0.027712173759937286, -0.025939559563994408, 0.005531337112188339, -0.016221169382333755, -0.002828251803293824, -0.05339383706450462] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 2: Abstract\n",
            "Large language model (LLM) applications such as agents and domain-specific reasoning increasingly rely on\n",
            "context adaptation—modifying inputs with instructions, strategies, or evidence, rather than weight updates.\n",
            "Prior approaches improve usability but often suffer from brevity bias, which drops domain insights for\n",
            "concise summaries, and from context collapse, where iterative rewriting erodes details over time. Building on\n",
            "Embedding 2: [0.01925468072295189, 0.017111314460635185, -0.03570893779397011, 0.05301570147275925, -0.0290666613727808, 0.008846759796142578, -0.008296167477965355, -0.021351812407374382, -0.021799324080348015, -0.06159032881259918] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 3: the adaptive memory introduced by Dynamic Cheatsheet, we introduce ACE (AgenticContextEngineering),\n",
            "a framework that treats contexts as evolving playbooks that accumulate, refine, and organize strategies\n",
            "through a modular process of generation, reflection, and curation. ACE prevents collapse with structured,\n",
            "incremental updates that preserve detailed knowledge and scale with long-context models. Across agent\n",
            "Embedding 3: [0.011984533630311489, 0.01032766979187727, -0.05484995245933533, 0.007896214723587036, -0.02019045315682888, -0.029920145869255066, 0.01621761918067932, -0.024399735033512115, -0.00539406156167388, -0.0002716645540203899] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 4: and domain-specific benchmarks, ACE optimizes contexts both offline (e.g.,system prompts) and online (e.g.,\n",
            "agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while\n",
            "significantly reducing adaptation latency and rollout cost. Notably, ACE could adapt effectively without\n",
            "labeled supervision and instead by leveraging natural execution feedback. On the AppWorld leaderboard,\n",
            "Embedding 4: [0.006236472632735968, 0.002493668347597122, -0.05533032864332199, -0.02477574534714222, 0.024613238871097565, 0.01452599000185728, 0.05055492743849754, -0.007597303483635187, 0.006566418334841728, -0.004950774367898703] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 5: ACE matches the top-ranked production-level agent on the overall average and surpasses it on the harder\n",
            "test-challenge split, despite using a smaller open-source model. These results show that comprehensive,\n",
            "evolving contexts enable scalable, efficient, and self-improving LLM systems with low overhead.\n",
            "1 Introduction\n",
            "Base LLM\n",
            "ICL GEPA DC ACE\n",
            "40.0\n",
            "42.5\n",
            "45.0\n",
            "47.5\n",
            "50.0\n",
            "52.5\n",
            "55.0\n",
            "57.5\n",
            "60.0Accuracy (%)\n",
            "42.4%\n",
            "46.0% 46.4%\n",
            "51.9%\n",
            "59.5%\n",
            "Agent: AppWorld\n",
            "Base LLM\n",
            "ICL GEPA DC ACE\n",
            "68\n",
            "70\n",
            "72\n",
            "74\n",
            "76\n",
            "78\n",
            "80\n",
            "82\n",
            "Embedding 5: [-0.03285445645451546, -0.027191217988729477, -0.03052792325615883, -0.00912255235016346, -0.026625264436006546, -0.02846420183777809, 0.009021730162203312, 0.006957477889955044, 0.01990521140396595, -0.012778416275978088] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 6: Base LLM\n",
            "ICL GEPA DC ACE\n",
            "68\n",
            "70\n",
            "72\n",
            "74\n",
            "76\n",
            "78\n",
            "80\n",
            "82\n",
            "70.7%\n",
            "72.3%\n",
            "73.5%\n",
            "74.2%\n",
            "78.3%\n",
            "Domain Knowledge: FiNER\n",
            "Base LLM\n",
            "ICL GEPA DC ACE\n",
            "66\n",
            "68\n",
            "70\n",
            "72\n",
            "74\n",
            "76\n",
            "78\n",
            "80\n",
            "67.5% 67.0%\n",
            "71.5%\n",
            "69.5%\n",
            "76.5%\n",
            "Numerical Reasoning: Formula\n",
            "Figure 1:Overall Performance Results.Our proposed framework, ACE, consistently outperforms strong\n",
            "baselines across agent and domain-specific reasoning tasks.\n",
            "Modern AI applications based on large language models (LLMs), such as LLM agents [49, 52] and compound\n",
            "Embedding 6: [0.02053859271109104, 0.026655586436390877, -0.017057621851563454, 0.03426456078886986, -0.04497089609503746, 0.020735451951622963, 0.03634903207421303, -0.01781369559466839, 0.02275477722287178, -0.041621722280979156] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 7: AI systems [55], increasingly depend oncontext adaptation. Instead of modifying model weights, context\n",
            "arXiv:2510.04618v1  [cs.LG]  6 Oct 2025\n",
            "Embedding 7: [-0.008319362066686153, 0.003984228242188692, -0.044408705085515976, 0.02879750169813633, -0.0066811684519052505, 0.007791461888700724, 0.0293254554271698, 0.009631187655031681, -0.01860681362450123, 0.009476701728999615] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 8: adaptation improves performance after model training by incorporating clarified instructions, structured\n",
            "reasoning steps, or domain-specific input formats directly into the model’s inputs. Contexts underpin\n",
            "many AI system components, including system prompts that guide downstream tasks [4, 36], memory that\n",
            "carries past facts and experiences [41, 48], and factual evidence that reduces hallucination and supplements\n",
            "knowledge [6].\n",
            "Embedding 8: [-0.024774597957730293, -0.0027496255934238434, -0.029428211972117424, -0.026705972850322723, -0.004286499228328466, 0.02741352468729019, 0.023991510272026062, 0.0024005346931517124, -0.027346841990947723, -0.023607006296515465] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 9: knowledge [6].\n",
            "Adapting throughcontextsrather thanweightsoffers several key advantages. Contexts are interpretable and\n",
            "explainable for users and developers [45, 47], allow rapid integration of new knowledge at runtime [7, 27],\n",
            "and can be shared across models or modules in a compound system [ 23]. Meanwhile, advances in long-\n",
            "context LLMs [39] and context-efficient inference such as KV cache reuse [17, 51] are making context-based\n",
            "Embedding 9: [-0.011038084514439106, 0.009372019208967686, -0.010178972035646439, 0.07365989685058594, -0.019391106441617012, -0.010573111474514008, 0.051035962998867035, -0.027137737721204758, -0.005479775369167328, -0.022249463945627213] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 10: approaches increasingly practical for deployment. As a result, context adaptation is emerging as a central\n",
            "paradigm for building capable, scalable, and self-improving AI systems.\n",
            "Despite this progress, existing approaches to context adaptation face two key limitations. First, abrevity\n",
            "bias: many prompt optimizers prioritize concise, broadly applicable instructions over comprehensive\n",
            "accumulation. For example, GEPA [ 4] highlights brevity as a strength, but such abstraction can omit\n",
            "Embedding 10: [0.025443309918045998, -0.005950578488409519, -0.027806391939520836, -0.011765259318053722, -0.006862971466034651, -0.0008945119334384799, -0.005237490404397249, -0.033110037446022034, -0.017671886831521988, 0.007862439379096031] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 11: domain-specific heuristics, tool-use guidelines, or common failure modes that matter in practice [16]. This\n",
            "objective aligns with validation metrics in some settings, but often fails to capture the detailed strategies\n",
            "required by agents and knowledge-intensive applications. Second,context collapse: methods that rely on\n",
            "monolithic rewriting by an LLM often degrade into shorter, less informative summaries over time, causing\n",
            "Embedding 11: [0.0032683571334928274, 0.014178913086652756, 0.0011669124942272902, -0.03242110088467598, -0.04486900940537453, -0.002213103463873267, -0.014934432692825794, 0.018843336030840874, -0.03715246170759201, -0.020001834258437157] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 12: sharp performance declines (Figure 2). In domains such as interactive agents [38, 43, 57], domain-specific\n",
            "programming [53, 56], and financial or legal analysis [18, 33, 44], strong performance depends on retaining\n",
            "detailed, task-specific knowledge rather than compressing it away.\n",
            "As applications such as agents and knowledge-intensive reasoning demand greater reliability, recent work\n",
            "has shifted toward saturating contexts with abundant, potentially useful information [11, 12, 22], enabled by\n",
            "Embedding 12: [-0.0031073414720594883, -0.0010951673611998558, -0.03255082294344902, 0.0024350136518478394, -0.012929048389196396, -0.0047198012471199036, 0.01574278622865677, 0.01632048934698105, -0.0038215185049921274, 0.004031959921121597] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 13: advances in long-context LLMs [34, 39].We argue that contexts should function not as concise summaries,\n",
            "but as comprehensive, evolving playbooks—detailed, inclusive, and rich with domain insights.Unlike\n",
            "humans, who often benefit from concise generalization, LLMs are more effective when provided with long,\n",
            "detailed contexts and can distill relevance autonomously [22, 31, 41]. Thus, instead of compressing away\n",
            "Embedding 13: [0.010728302411735058, 0.009838533587753773, -0.015195723623037338, 0.02764688804745674, -0.02256384678184986, -0.0005845757550559938, 0.012631506659090519, 0.012653154321014881, -0.03842271864414215, -0.035762984305620193] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 14: domain-specific heuristics and tactics, contexts should preserve them, allowing the model to decide what\n",
            "matters at inference time.\n",
            "To address these limitations, we introduce ACE (AgenticContextEngineering), a framework for compre-\n",
            "hensive context adaptation in both offline settings (e.g.,system prompt optimization) and online settings\n",
            "(e.g.,test-time memory adaptation). Rather than compressing contexts into distilled summaries, ACE treats\n",
            "Embedding 14: [0.02381819672882557, 0.036164794117212296, -0.02977997623383999, 0.02713162451982498, -0.013584448955953121, 0.02779264561831951, 0.06198287382721901, -0.02594144456088543, -0.0022363001480698586, -0.016569308936595917] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 15: them as evolving playbooks that accumulate and organize strategies over time. Building on the agentic\n",
            "architecture of Dynamic Cheatsheet [41], ACE incorporates a modular workflow of generation, reflection,\n",
            "and curation, while adding structured, incremental updates guided by a grow-and-refine principle. This\n",
            "design preserves detailed, domain-specific knowledge, prevents context collapse, and yields contexts that\n",
            "remain comprehensive and scalable throughout adaptation.\n",
            "Embedding 15: [0.014389374293386936, -0.01357817742973566, -0.0675329715013504, -0.03734079748392105, -0.019241489470005035, -0.045636095106601715, -0.007748219650238752, 0.0005743738147430122, -0.032475464046001434, 0.01479540579020977] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 16: We evaluate ACE on two categories of LLM applications that most benefit from comprehensive, evolving\n",
            "contexts: (1)agents[ 43], which require multi-turn reasoning, tool use, and environment interaction, where\n",
            "accumulated strategies can be reused across episodes; and (2)domain-specific benchmarks, which demand\n",
            "specialized tactics and knowledge, where we focus on financial analysis [33, 44]. Our key findings are:\n",
            "Embedding 16: [-0.04556339606642723, 0.011634049005806446, -0.012052078731358051, 0.007205246482044458, -0.039208702743053436, 0.00013831724936608225, -0.003242852631956339, 0.005765800829976797, -0.01236011739820242, -0.0029526057187467813] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 17: • ACE consistently outperforms strong baselines, yielding average gains of 10.6% onagentsand 8.6% on\n",
            "domain-specific benchmarks, across both offline and online adaptation settings.\n",
            "• ACE is able to construct effective contextswithoutlabeled supervision, instead leveraging execution\n",
            "feedback and environment signals—key ingredients for self-improving LLMs and agents.\n",
            "• On the AppWorld benchmark leaderboard [5], ACE matches the top-ranked production-level agent IBM-\n",
            "Embedding 17: [-0.01734747551381588, -0.015315776690840721, -0.01332565676420927, -0.004330778028815985, 0.004122081212699413, -0.00038156440132297575, 0.05235432833433151, -0.005633117631077766, 0.02059323899447918, -0.018887696787714958] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 18: CUGA [35] (powered by GPT-4.1) on average and surpasses it on the harder test-challenge split, while\n",
            "using a smaller open-source model (DeepSeek-V3.1).\n",
            "2\n",
            "Embedding 18: [-0.07289332896471024, 0.039530567824840546, -0.016231577843427658, 0.0554749071598053, -0.047909580171108246, -0.04180842265486717, 0.041473373770713806, 0.019373850896954536, 0.016586778685450554, 0.01162040326744318] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 19: • ACE requires significantly fewer rollouts and lower dollar costs, and achieves 86.9% lower adaptation\n",
            "latency (on average) than existing adaptive methods, demonstrating that scalable self-improvement can be\n",
            "achieved with both higher accuracy and lower overhead.\n",
            "2 Background and Motivation\n",
            "2.1 Context Adaptation\n",
            "Context adaptation (or context engineering) refers to methods that improve model behavior by constructing\n",
            "Embedding 19: [-0.011690053157508373, 0.045895371586084366, -0.04544290155172348, -0.00715086841955781, 0.011625917628407478, 0.020546309649944305, 0.04400155693292618, -0.015916256234049797, -0.03203873708844185, -0.009003477171063423] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 20: or modifying inputs to an LLM, rather than altering its weights. The current state of the art leveragesnatural\n",
            "language feedback[ 4, 40, 54]. In this paradigm, a language model inspects the current context along with\n",
            "signals such as execution traces, reasoning steps, or validation results, and generates natural language\n",
            "feedback on how the context should be revised. This feedback is then incorporated into the context, enabling\n",
            "Embedding 20: [0.03555923327803612, 0.014721172861754894, -0.007074726279824972, 0.019298097118735313, -0.06277742981910706, -0.019981537014245987, -0.023022394627332687, 0.016056127846240997, -0.029749354347586632, -0.060320574790239334] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 21: iterative adaptation. Representative methods include Reflexion [40], which reflects on failures to improve\n",
            "agent planning; TextGrad [54], which optimizes prompts via gradient-like textual feedback; GEPA [4], which\n",
            "refines prompts iteratively based on execution traces and achieves strong performance, even surpassing\n",
            "reinforcement learning approaches in some settings; and Dynamic Cheatsheet [ 41], which constructs an\n",
            "Embedding 21: [0.049213625490665436, -0.02535438723862171, -0.034926678985357285, -0.02064713090658188, -0.0005804295069538057, 0.019725196063518524, -0.019962146878242493, 0.03939126059412956, 0.017070867121219635, -0.006304876413196325] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 22: external memory that accumulates strategies and lessons from past successes and failures during inference.\n",
            "These natural language feedback methods represent a major advance, offering flexible and interpretable\n",
            "signals for improving LLM systems beyond weight updates.\n",
            "2.2 Limitations of Existing Context Adaptation Methods\n",
            "The Brevity Bias.A recurring limitation of context adaptation methods isbrevity bias: the tendency of\n",
            "Embedding 22: [0.05485156923532486, 0.008733546361327171, -0.017824329435825348, 0.03664351999759674, -0.026035157963633537, 0.013831101357936859, -0.03926096484065056, -0.002729749772697687, 0.009903622791171074, -0.05767948552966118] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 23: optimization to collapse toward short, generic prompts. Gao et al. [ 16] document this effect in prompt\n",
            "optimization for test generation, where iterative methods repeatedly produced near-identical instructions\n",
            "(e.g.,\"Create unit tests to ensure methods behave as expected\"), sacrificing diversity and omitting domain-\n",
            "specific detail. This convergence not only narrows the search space but also propagates recurring errors\n",
            "Embedding 23: [-0.026179514825344086, 0.02074347995221615, -0.03059394843876362, -0.027355223894119263, -0.047825515270233154, -0.01349597331136465, 0.027395084500312805, 0.05593641847372055, -0.034230753779411316, 0.0367712527513504] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 24: across iterations, since optimized prompts often inherit the same faults as their seeds. More broadly, such\n",
            "bias undermines performance in domains that demand detailed, context-rich guidance—such as multi-step\n",
            "agents, program synthesis, or knowledge-intensive reasoning—where success hinges on accumulating rather\n",
            "than compressing task-specific insights.\n",
            "# Tokens: 18,282Accuracy: 66.7 \n",
            "# Tokens: 122Accuracy: 57.1 Accuracy w/o context: 63.7\n",
            "Embedding 24: [-0.008552909828722477, 0.011064792983233929, -0.024949952960014343, -0.006185578182339668, 0.006831727456301451, -0.010016383603215218, 0.010915973223745823, -0.010161375626921654, -0.02595794014632702, 0.01659359224140644] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 25: Figure 2:Context Collapse.Monolithic rewriting of context by an LLM can collapse it into shorter, less\n",
            "informative summaries, leading to sharp performance drops.\n",
            "Context Collapse.In a case study on the AppWorld benchmark [ 43], we observe a phenomenon we\n",
            "callcontext collapse, which arises when an LLM is tasked with fully rewriting the accumulated context at\n",
            "each adaptation step. As the context grows large, the model tends to compress it into much shorter, less\n",
            "Embedding 25: [-0.019419996067881584, 0.0022529426496475935, -0.04053155332803726, 0.044189441949129105, -0.020251596346497536, 0.016077514737844467, 0.005264254752546549, 0.01006321795284748, -0.04844681918621063, -0.011404874734580517] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 26: informative summaries, causing a dramatic loss of information. For instance, at step 60 the context contained\n",
            "3\n",
            "Embedding 26: [-0.0038965961430221796, -0.07274305075407028, -0.017811505123972893, 0.014620896428823471, -0.019207697361707687, 0.03721260279417038, 0.015639271587133408, 0.03395821899175644, -0.09119278937578201, 0.021161187440156937] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 27: 18,282 tokens and achieved an accuracy of 66.7, but at the very next step it collapsed to just 122 tokens,\n",
            "with accuracy dropping to 57.1—worse than the baseline accuracy of 63.7 without adaptation. While we\n",
            "highlight this through Dynamic Cheatsheet [41], the issue is not specific to that method; rather, it reflects a\n",
            "fundamental risk of end-to-end context rewriting with LLMs, where accumulated knowledge can be abruptly\n",
            "erased instead of preserved.\n",
            "Embedding 27: [-0.025832047685980797, 0.03182600066065788, 0.0008535144734196365, 0.041982971131801605, -0.03867518529295921, -0.017298152670264244, -0.0025483383797109127, 0.011381044052541256, -0.05655412748456001, -0.02353125624358654] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 28: erased instead of preserved.\n",
            "Figure 3:Example ACE-Generated Context on the AppWorld Benchmark(partially shown). ACE-generated\n",
            "contexts contain detailed, domain-specific insights along with tools and code that are readily usable, serving\n",
            "as a comprehensive playbook for LLM applications.\n",
            "3 Agentic Context Engineering (ACE)\n",
            "We present ACE (AgenticContextEngineering), a framework for scalable and efficient context adaptation\n",
            "Embedding 28: [0.000593433971516788, 0.0013147136196494102, -0.035786572843790054, 0.03978906199336052, -0.04294247925281525, -0.006944182328879833, 0.04441288113594055, 0.006997630000114441, -0.002338751219213009, -0.020434122532606125] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 29: in both offline (e.g.,system prompt optimization) and online (e.g.,test-time memory adaptation) scenarios.\n",
            "Instead of condensing knowledge into terse summaries or static instructions, ACE treats contexts as evolving\n",
            "playbooks that continuously accumulate, refine, and organize strategies over time. Building on the agentic\n",
            "design of Dynamic Cheatsheet [41], ACE introduces a structured division of labor across three roles (Figure\n",
            "Embedding 29: [0.027680957689881325, -0.03223586454987526, -0.07041794061660767, -0.01948269084095955, -0.013156597502529621, -0.017596744000911713, 0.013264012522995472, 0.0026664193719625473, -0.021338019520044327, 0.011931913904845715] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 30: 4): theGenerator, which produces reasoning trajectories; theReflector, which distills concrete insights from\n",
            "successes and errors; and theCurator, which integrates these insights into structured context updates. This\n",
            "mirrors how humans learn—experimenting, reflecting, and consolidating—while avoiding the bottleneck of\n",
            "overloading a single model with all responsibilities.\n",
            "To address the limitations of prior methods discussed in §2.2—notablybrevity biasandcontext collapse—ACE\n",
            "Embedding 30: [0.003971140366047621, 0.028142642229795456, -0.022609630599617958, -0.002281998284161091, -0.04649369791150093, 0.026775769889354706, -0.00020053899788763374, -0.017940783873200417, -0.013645002618432045, -0.0007638268871232867] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 31: introduces three key innovations: (1) a dedicatedReflectorthat separates evaluation and insight extraction\n",
            "from curation, improving context quality and downstream performance (§4.5); (2) incrementaldelta updates\n",
            "(§3.1) that replace costly monolithic rewrites with localized edits, reducing both latency and compute cost\n",
            "(§4.6); and (3) agrow-and-refinemechanism (§3.2) that balances steady context expansion with redundancy\n",
            "control.\n",
            "4\n",
            "Embedding 31: [0.032288309186697006, 0.029951458796858788, -0.029282618314027786, -0.01809474267065525, -0.0398789644241333, -0.016394974663853645, 0.027809487655758858, -0.0011479993117973208, -0.08626890927553177, -0.03192688897252083] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 32: Generator\n",
            "Context Playbook\n",
            "Query\n",
            "Trajectory\n",
            " Insights\n",
            "Delta Context Items\n",
            "Iterative Refinement\n",
            "Update\n",
            "Reflector Curator\n",
            "Figure 4:The ACE Framework.Inspired by Dynamic Cheatsheet, ACE adopts an agentic architecture with\n",
            "three specialized components: a Generator, a Reflector, and a Curator.\n",
            "As shown in Figure 4, the workflow begins with the Generator producing reasoning trajectories for new\n",
            "Embedding 32: [0.011879333294928074, 0.0389435775578022, -0.046220216900110245, -0.018138106912374496, -0.05751151219010353, -0.018907485529780388, -0.020913179963827133, -0.032404039055109024, -0.03308944031596184, 0.006803938653320074] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 33: queries, which surface both effective strategies and recurring pitfalls. The Reflector critiques these traces\n",
            "to extract lessons, optionally refining them across multiple iterations. The Curator then synthesizes these\n",
            "lessons into compactdelta entries, which are merged deterministically into the existing context by lightweight,\n",
            "non-LLM logic. Because updates are itemized and localized, multiple deltas can be merged in parallel,\n",
            "Embedding 33: [0.003301430493593216, 0.07794962078332901, -0.051454707980155945, -0.02115635760128498, -0.06983684748411179, -0.000607293623033911, -0.03769781440496445, -0.0009450083016417921, -0.06107380986213684, 0.0010016757296398282] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 34: enabling batched adaptation at scale. ACE further supports multi-epoch adaptation, where the same queries\n",
            "are revisited to progressively strengthen the context.\n",
            "3.1 Incremental Delta Updates\n",
            "A core design principle of ACE is to represent context as a collection ofstructured, itemized bullets, rather\n",
            "than a single monolithic prompt. The concept of a bullet is similar to the concept of a memory entry in LLM\n",
            "Embedding 34: [-0.01778360828757286, -0.023135468363761902, -0.04859543591737747, 0.009583801031112671, -0.017352350056171417, 0.030788859352469444, 0.04373405501246452, -0.010366198606789112, -0.02427789382636547, -0.006043667439371347] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 35: memory frameworks like Dynamic Cheatsheet [41] and A-MEM [48], but builds on top of that and consists\n",
            "of (1)metadata, including a unique identifier and counters tracking how often it was marked helpful or\n",
            "harmful; and (2)content, capturing a small unit such as a reusable strategy, domain concept, or common\n",
            "failure mode. When solving new problems, the Generator highlights which bullets were useful or misleading,\n",
            "providing feedback that guides the Reflector in proposing corrective updates.\n",
            "Embedding 35: [0.04149331897497177, -0.08352961391210556, -0.016258791089057922, 0.0006365679437294602, -0.016194229945540428, 0.0012465971522033215, -0.0032997934613376856, -0.01841501146554947, -0.06251406669616699, -0.013986795209348202] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 36: This itemized design enables three key properties: (1)localization, so only the relevant bullets are updated;\n",
            "(2)fine-grained retrieval, so the Generator can focus on the most pertinent knowledge; and (3)incremental\n",
            "adaptation, allowing efficient merging, pruning, and de-duplication during inference.\n",
            "Rather than regenerating contexts in full, ACE incrementally produces compactdelta contexts: small sets of\n",
            "Embedding 36: [-0.013599048368632793, 0.02251678705215454, -0.0026763014029711485, 0.019273703917860985, -0.0017949477769434452, -0.0035825776867568493, 0.053394824266433716, -0.019551491364836693, -0.04945431649684906, -0.0017864744877442718] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 37: candidate bullets distilled by the Reflector and integrated by the Curator. This avoids the computational\n",
            "cost and latency of full rewrites, while ensuring that past knowledge is preserved and new insights are\n",
            "steadily appended. As contexts grow, this approach provides the scalability needed for long-horizon or\n",
            "domain-intensive applications.\n",
            "3.2 Grow-and-Refine\n",
            "Beyond incremental growth, ACE ensures that contexts remain compact and relevant through periodic or\n",
            "Embedding 37: [0.014434208162128925, 0.01090388372540474, -0.004553705919533968, -0.023916758596897125, -0.0523846298456192, -0.01805790141224861, 0.08340197056531906, -0.013206128031015396, -0.06803230941295624, -0.008875342085957527] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 38: lazy refinement. In grow-and-refine, bullets with new identifiers are appended, while existing bullets are\n",
            "updated in place (e.g.,incrementing counters). A de-duplication step then prunes redundancy by comparing\n",
            "bullets via semantic embeddings. This refinement can be performed proactively (after each delta) or lazily\n",
            "(only when the context window is exceeded), depending on application requirements for latency and\n",
            "accuracy.\n",
            "5\n",
            "Embedding 38: [2.7850010155816562e-05, -0.000456634588772431, -0.02536916173994541, 0.02828829362988472, -0.017134374007582664, 0.019463973119854927, 0.002338780090212822, 0.008795707486569881, -0.04921162128448486, -0.0016292405780404806] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 39: Together, incremental updates and grow-and-refine maintain contexts that expand adaptively, remain\n",
            "interpretable, and avoid the potential variance introduced by monolithic context rewriting.\n",
            "4 Results\n",
            "Our evaluation of ACE shows that:\n",
            "• Enabling High-Performance, Self-Improving Agents.ACE enables agents to self-improve by dynamically\n",
            "refining their input context. It boosts accuracy on the AppWorld benchmark by up to 17.1% by learning to\n",
            "Embedding 39: [0.002238678513094783, -0.006515535991638899, -0.022874312475323677, 0.005434286780655384, -0.018827633932232857, -0.02165938727557659, 0.03277146816253662, -0.025029752403497696, -0.013600405305624008, -0.027259016409516335] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 40: engineer better contexts from execution feedback alone, without needing ground-truth labels. This context-\n",
            "driven improvement allows a smaller, open-source model to match the performance of the top-ranked\n",
            "proprietary agent on the leaderboard. (§4.3)\n",
            "• Large Gains on Domain-Specific Benchmarks.On complex financial reasoning benchmarks, ACE delivers\n",
            "an average performance gain of 8.6% over strong baselines by constructing comprehensive playbooks\n",
            "with domain-specific concepts and insights. (§4.4)\n",
            "Embedding 40: [-0.035499975085258484, 0.06295543164014816, -0.01053347997367382, 0.001039557857438922, -0.036431457847356796, -0.02069374918937683, 0.026664884760975838, -0.005004809238016605, -0.00413551414385438, 0.006373015698045492] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 41: • Effective by Design.Ablation studies confirm our design choices are key to success, with components\n",
            "like the Reflector and multi-epoch refinement each contributing substantial performance gains. (§4.5)\n",
            "• Lower Cost and Adaptation Latency.ACE achieves these gains efficiently, reducing adaptation latency by\n",
            "86.9% on average, while requiring fewer rollouts and lower token dollar costs. (§4.6)\n",
            "4.1 Tasks and Datasets\n",
            "Embedding 41: [-0.006475040689110756, -0.024395275861024857, -0.03538018465042114, -0.00012474738468881696, -0.032987646758556366, -0.006733637768775225, 0.09216953814029694, -0.014130317606031895, -0.08060798048973083, 0.04486178979277611] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 42: 4.1 Tasks and Datasets\n",
            "We evaluate ACE on two categories of LLM applications that benefit most from a comprehensive and\n",
            "evolving context: (1)agent benchmarks, which require multi-turn reasoning, tool use, and environment\n",
            "interaction, where agents can accumulate and reuse strategies across episodes and environments; and (2)\n",
            "domain-specific benchmarks, which demand mastery of specialized concepts and tactics, where we focus on\n",
            "financial analysis as a case study.\n",
            "Embedding 42: [-0.051465559750795364, 0.009230141527950764, -0.012521267868578434, 0.017007173970341682, -0.03550972416996956, 0.00890500470995903, 0.0012014384847134352, 0.006858610548079014, -0.013412626460194588, 0.007918175309896469] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 43: financial analysis as a case study.\n",
            "• LLM Agent: AppWorld [ 43]is a suite of autonomous agent tasks involving API understanding, code\n",
            "generation, and environment interaction. It provides a realistic execution environment with common\n",
            "applications and APIs (e.g.,email, file system) and tasks of two difficulty levels (normal and challenge). A\n",
            "public leaderboard [5] tracks performance, where, at the time of submission, the best system achieved only\n",
            "Embedding 43: [-0.0003864312602672726, 0.018351200968027115, -0.05320708081126213, -0.015885129570961, -0.03574414551258087, 0.0007327995845116675, 0.02585623785853386, 0.022469181567430496, 0.045027755200862885, -0.02145698107779026] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 44: 60.3% average accuracy, highlighting the benchmark’s difficulty and realism.\n",
            "• Financial Analysis: FiNER [ 33] and Formula [ 44]test LLMs on financial reasoning tasks that rely on\n",
            "the eXtensible Business Reporting Language (XBRL).FiNERrequires labeling tokens in XBRL financial\n",
            "documents with one of 139 fine-grained entity types, a key step for financial information extraction in\n",
            "regulated domains.Formulafocuses on extracting values from structured XBRL filings and performing\n",
            "Embedding 44: [-0.04717027023434639, -0.01227325014770031, 0.011997392401099205, 0.04109804332256317, -0.037105295807123184, 0.027793321758508682, -0.0033313247840851545, 0.0500887855887413, -0.005850114393979311, -0.017004363238811493] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 45: computations to answer financial queries,i.e.,numerical reasoning.\n",
            "Evaluation Metrics.For AppWorld, we follow the official benchmark protocol and reportTask Goal\n",
            "Completion(TGC) andScenario Goal Completion(SGC) on both the test-normal and test-challenge splits. For\n",
            "FiNER and Formula, we follow the original setup and report accuracy, measured as the proportion of\n",
            "predicted answers that exactly match the ground truth.\n",
            "Embedding 45: [-0.022490553557872772, 0.017062552273273468, -0.020719153806567192, -0.011976836249232292, -0.034248340874910355, -0.028357628732919693, -0.0076855882070958614, 0.019067341461777687, -0.026878103613853455, 0.023457903414964676] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 46: All datasets follow the original train/validation/test splits. Forofflinecontext adaptation, methods are\n",
            "optimized on the training split and evaluated on the test split with pass@1 accuracy. Foronlinecontext\n",
            "adaptation, methods are evaluated sequentially on the test split: for each sample, the model first predicts\n",
            "with the current context, then updates its context based on that sample. The same shuffled test split is used\n",
            "across all methods.\n",
            "4.2 Baselines and Methods\n",
            "Embedding 46: [-0.001136982231400907, -0.0017814147286117077, -0.02803829312324524, 0.004192366264760494, -0.03723740205168724, 0.030027108266949654, 0.08322649449110031, 0.0302668996155262, -0.0433974526822567, -0.017878228798508644] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 47: across all methods.\n",
            "4.2 Baselines and Methods\n",
            "Base LLM.The base model is evaluated directly on each benchmark without any context engineering,\n",
            "using the default prompts provided by dataset authors. For AppWorld, we follow the official ReAct [52]\n",
            "6\n",
            "Embedding 47: [-0.03907112032175064, -0.002502289367839694, -0.011283205822110176, 0.016233624890446663, -0.05718334764242172, -0.03176289051771164, 0.0437021441757679, 0.01645081304013729, 0.011962003074586391, -0.021259596571326256] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 48: implementation released by the benchmark authors, and build all other baselines and methods on top of this\n",
            "framework.\n",
            "In-Context Learning (ICL) [3].ICL provides the model with task demonstrations in the input prompt\n",
            "(few-shot or many-shot). This allows the model to infer the task format and desired output without weight\n",
            "updates. We supply all training samples when they fit within the model’s context window; otherwise, we fill\n",
            "the window with as many demonstrations as possible.\n",
            "Embedding 48: [-0.0437159463763237, 0.020577209070324898, 0.03349002078175545, 0.01850276067852974, -0.05544312670826912, -0.020140383392572403, 0.06478241086006165, 0.004296540282666683, -0.038216374814510345, -0.012653389945626259] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 49: MIPROv2 [36].MIPROv2 is a popular prompt optimizer for LLM applications that works by jointly\n",
            "optimizing system instructions and in-context demonstrations via bayesian optimization. We use the official\n",
            "DSPy implementation [15], settingauto=\"heavy\"to maximize optimization performance.\n",
            "GEPA [4].GEPA (Genetic-Pareto) is a sample-efficient prompt optimizer based on reflective prompt\n",
            "evolution. It collects execution traces (reasoning, tool calls, intermediate outputs) and applies natural-\n",
            "Embedding 49: [-0.02969723753631115, 0.000636418757494539, -0.010937359184026718, 0.02933579497039318, -0.03759819641709328, -0.01496085710823536, -0.005427520256489515, 0.021112697198987007, -0.007683889474719763, -0.003067327430471778] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 50: language reflection to diagnose errors, assign credit, and propose prompt updates. A genetic Pareto search\n",
            "maintains a frontier of high-performing prompts, mitigating local optima. Empirically, GEPA outperforms\n",
            "reinforcement learning methods such as GRPO and prompt optimizers like MIPROv2, achieving up to\n",
            "10–20% higher accuracy with as much as 35× fewer rollouts. We use the official DSPy implementation [14],\n",
            "settingauto=\"heavy\"to maximize optimization performance.\n",
            "Embedding 50: [0.03355177864432335, 0.053557682782411575, -0.003075128188356757, -0.011122383177280426, 0.0026256332639604807, -0.0027913579251617193, -0.010376285761594772, 0.03827464208006859, -0.006797278765588999, -0.029231959953904152] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 51: Dynamic Cheatsheet (DC) [41].DC is a test-time learning approach that introduces an adaptive external\n",
            "memory of reusable strategies and code snippets. By continuously updating this memory with newly\n",
            "encountered inputs and outputs, DC enables models to accumulate knowledge and reuse it across tasks,\n",
            "often leading to substantial improvements over static prompting methods. A key advantage of DC is that it\n",
            "Embedding 51: [0.00785051193088293, -0.04515179619193077, -0.03802980110049248, -0.03801571950316429, -0.021382352337241173, -0.0011419280199334025, -0.02436300739645958, -0.001491212286055088, -0.012081065215170383, -0.029390186071395874] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 52: does not require ground-truth labels: the model can curate its own memory from its generations, making\n",
            "the method highly flexible and broadly applicable. We use the official implementation released by the\n",
            "authors [42] and set it to use thecumulativemode (DC-CU).\n",
            "ACE (ours).ACE optimizes LLM contexts for both offline and online adaptation through an agentic context\n",
            "engineering framework. To ensure fairness, we use the same LLM for the Generator, Reflector, and Curator\n",
            "Embedding 52: [-0.01174994371831417, 0.042515385895967484, -0.007673710584640503, 0.007519843056797981, -0.03132692724466324, 0.000876074016559869, 0.06467586755752563, -0.021446427330374718, -0.031260959804058075, 0.003027854487299919] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 53: (non-thinking mode of DeepSeek-V3.1 [13]), preventing knowledge transfer from a stronger Reflector or\n",
            "Curator to a weaker Generator. This isolates the benefit of context construction itself. We adopt a batch size\n",
            "of 1 (constructing a delta context from each sample). We set the maximum number of Reflector refinement\n",
            "rounds and the maximum number of epochs in offline adaptation to 5.\n",
            "4.3 Results on Agent Benchmark\n",
            "Embedding 53: [-0.02147936075925827, 0.04391510784626007, -0.0033815016504377127, 0.022319063544273376, -0.02693040296435356, -0.028561385348439217, 0.037690673023462296, -0.005966678261756897, -0.02003161795437336, -0.0025144945830106735] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 54: 4.3 Results on Agent Benchmark\n",
            "Analysis.As shown in Table 1, ACE consistently improves over strong baselines on the AppWorld\n",
            "benchmark. In the offline setting, ReAct + ACE outperforms both ReAct + ICL and ReAct + GEPA by\n",
            "significant margins (12.3% and 11.9%, respectively), demonstrating that structured, evolving, and detailed\n",
            "contexts enable more effective agent learning than fixed demonstrations or single optimized instruction\n",
            "Embedding 54: [-0.011004791595041752, -0.006271936930716038, -0.03227848559617996, -0.037080295383930206, -0.01435556635260582, -0.003925158176571131, 0.04226167872548103, 0.009409677237272263, 0.02564779482781887, -0.0063310470432043076] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 55: prompts. These gains extend to the online setting, where ACE continues to outperform prior adaptive\n",
            "methods such as Dynamic Cheatsheet by an average of 7.6%.\n",
            "In the agent use case, ACE remains effective evenwithoutaccess to ground-truth labels during adaptation:\n",
            "ReAct + ACE achieves an average improvement of 14.8% over the ReAct baseline in this setting. This\n",
            "robustness arises because ACE leverages signals naturally available during execution (e.g.,code execution\n",
            "Embedding 55: [-0.03621828928589821, -0.013958044350147247, -0.05036146938800812, -0.03728225827217102, -0.013398568145930767, -0.014920549467206001, 0.02083408646285534, 0.039496369659900665, 0.02361109107732773, -0.005518901627510786] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 56: success or failure) to guide the Reflector and Curator in forming structured lessons of successes and failures.\n",
            "Together, these results establish ACE as a strong and versatile framework for building self-improving agents\n",
            "that adapt reliably both with and without labeled supervision.\n",
            "Notably, on the latest AppWorld leaderboard (as of September 20, 2025; Figure 5), on average, ReAct +\n",
            "ACE (59.4%) matches the top-ranked IBM CUGA (60.3%), a production-level GPT-4.1–based agent [ 35],\n",
            "Embedding 56: [0.026129061356186867, 0.015525559894740582, -0.03424380347132683, -0.04043401777744293, 0.00540118059143424, -0.020919186994433403, -0.0023537692613899708, -0.008472299203276634, 0.06303603202104568, 0.0049093435518443584] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 57: despite using the smaller open-source model DeepSeek-V3.1. With online adaptation, ReAct + ACE even\n",
            "7\n",
            "Embedding 57: [-0.054741501808166504, 0.03240472823381424, -0.010263719595968723, -0.004836598411202431, 0.0031418881844729185, -0.07143471390008926, 0.01790112443268299, 0.047341130673885345, 0.05918513983488083, -0.02678505703806877] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 58: Method GT Labels Test-Normal Test-Challenge Average\n",
            "TGC↑SGC↑ TGC↑SGC↑\n",
            "DeepSeek-V3.1 as Base LLM\n",
            "ReAct 63.7 42.9 41.5 21.6 42.4\n",
            "Offline Adaptation\n",
            "ReAct+ ICL✓ 64.3+0.6 46.4+3.5 46.0+4.5 27.3+5.7 46.0+3.6\n",
            "ReAct+ GEPA✓ 64.9+1.2 44.6+1.7 46.0+4.5 30.2+8.6 46.4+4.0\n",
            "ReAct+ ACE✓ 76.2+12.5 64.3+21.4 57.3+15.8 39.6+18.0 59.4+17.0\n",
            "ReAct+ ACE✗ 75.0+11.3 64.3+21.4 54.4+12.9 35.2+13.6 57.2+14.8\n",
            "Online Adaptation\n",
            "ReAct+ DC (CU)✗ 65.5+1.8 58.9+16.0 52.3+10.8 30.8+9.2 51.9+9.5\n",
            "Embedding 58: [-0.07962116599082947, -0.030421962961554527, -0.03852133825421333, 0.032294970005750656, -0.025622015818953514, -0.04462076723575592, 0.04670046642422676, 0.02805224247276783, 0.011979860253632069, -0.028934411704540253] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 59: ReAct+ ACE✗ 69.6+5.9 53.6+10.7 66.0+24.5 48.9+27.3 59.5+17.1\n",
            "Table 1:Results on the AppWorld Agent Benchmark.\"GT labels\" indicates whether ground-truth labels are\n",
            "available to the Reflector during adaptation. We evaluate the ACE framework against multiple baselines\n",
            "on top of the official ReAct implementation, both for offline and online context adaptation. ReAct + ACE\n",
            "outperforms selected baselines by an average of 10.6%, and could achieve good performance even without\n",
            "access to GT labels.\n",
            "Embedding 59: [0.006467235274612904, -0.0151214599609375, -0.029611995443701744, -0.027740545570850372, -0.026808029040694237, -0.019637640565633774, 0.07216775417327881, 0.009581023827195168, 0.023367231711745262, -0.034140605479478836] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 60: access to GT labels.\n",
            "Method GT Labels FINER (Acc↑) Formula (Acc↑) Average\n",
            "DeepSeek-V3.1 as Base LLM\n",
            "Base LLM 70.7 67.5 69.1\n",
            "Offline Adaptation\n",
            "ICL✓ 72.3+1.6 67.0−0.5 69.6+0.5\n",
            "MIPROv2✓ 72.4+1.7 69.5+2.0 70.9+1.8\n",
            "GEPA✓ 73.5+2.8 71.5+4.0 72.5+3.4\n",
            "ACE✓ 78.3+7.6 85.5+18.0 81.9+12.8\n",
            "ACE✗ 71.1+0.4 83.0+15.5 77.1+8.0\n",
            "Online Adaptation\n",
            "DC (CU)✓ 74.2+3.5 69.5+2.0 71.8+2.7\n",
            "DC (CU)✗ 68.3−2.4 62.5−5.0 65.4−3.7\n",
            "ACE✓ 76.7+6.0 76.5+9.0 76.6+7.5\n",
            "ACE✗ 67.3−3.4 78.5+11.0 72.9+3.8\n",
            "Embedding 60: [-0.057903364300727844, -0.0652540773153305, -0.01791532151401043, 0.06717748194932938, -0.012745057232677937, -0.012221194803714752, 0.01757291704416275, -0.004534719046205282, -0.015365003608167171, -0.007336506154388189] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 61: ACE✗ 67.3−3.4 78.5+11.0 72.9+3.8\n",
            "Table 2:Results on Financial Analysis Benchmark.\"GT labels\" indicates whether ground-truth labels\n",
            "are available to the Reflector during adaptation. With GT labels, ACE outperforms selected baselines by\n",
            "an average of 8.6%, highlighting the advantage of structured and evolving contexts for domain-specific\n",
            "reasoning. However, we also observe that in the absence of reliable feedback signals (e.g.,ground-truth\n",
            "Embedding 61: [-0.01826724037528038, 0.0345795601606369, -0.02050851099193096, -0.01886952482163906, -0.0016076520550996065, 0.010719314217567444, 0.06458444893360138, 0.01232292503118515, -0.041056469082832336, -0.005472548771649599] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 62: labels or execution outcomes), both ACE and other adaptive methods such as Dynamic Cheatsheet may\n",
            "degrade, suggesting that context adaptation depends critically on feedback quality.\n",
            "surpasses IBM CUGA by 8.4% in TGC and 0.7% in SGC on the harder test-challenge split, underscoring the\n",
            "effectiveness of ACE in building comprehensive and self-evolving contexts for agents.\n",
            "4.4 Results on Domain-Specific Benchmark\n",
            "Embedding 62: [0.0032297265715897083, -0.04244411736726761, -0.042868778109550476, -0.02902447246015072, -0.013149324804544449, 0.005968823097646236, 0.03406595438718796, -0.004092042800039053, 0.0011367859551683068, 0.005770050920546055] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 63: 4.4 Results on Domain-Specific Benchmark\n",
            "Analysis.As shown in Table 2, ACE delivers strong improvements on financial analysis benchmarks.\n",
            "In the offline setting, when provided with ground-truth answers from the training split, ACE surpasses\n",
            "ICL, MIPROv2, and GEPA by clear margins (an average of 10.9%), showing that structured and evolving\n",
            "contexts are particularly effective when tasks require precise domain knowledge (e.g.,financial concepts,\n",
            "8\n",
            "Embedding 63: [-0.05625632405281067, 0.03138604015111923, -0.03605857118964195, -0.016800889745354652, -0.016445880755782127, 0.006711099296808243, 0.07956250011920929, 0.020121408626437187, -0.03834544122219086, -0.017169509083032608] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 64: Method GT Labels Test-Normal Test-Challenge Average\n",
            "TGC↑SGC↑ TGC↑SGC↑\n",
            "DeepSeek-V3.1 as Base LLM\n",
            "ReAct 63.7 42.9 41.5 21.6 42.4\n",
            "Offline Adaptation\n",
            "ReAct+ ACE w/o Reflector or multi-epoch✓ 70.8+7.1 55.4+12.5 55.9+14.4 38.1+17.5 55.1+12.7\n",
            "ReAct+ ACE w/o multi-epoch✓ 72.0+8.3 60.7+17.8 54.9+13.4 39.6+18.0 56.8+14.4\n",
            "ReAct+ ACE✓ 76.2+12.5 64.3+21.4 57.3+15.8 39.6+18.0 59.4+17.0\n",
            "Online Adaptation\n",
            "ReAct+ ACE✗ 67.9+4.2 51.8+8.9 61.4+19.9 43.2+21.6 56.1+13.7\n",
            "Embedding 64: [-0.059764161705970764, -0.03885286673903465, -0.032724518328905106, 0.019700920209288597, -0.03148223087191582, -0.05609771981835365, 0.05527643486857414, 0.0375816710293293, 0.008322699926793575, -0.035178981721401215] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 65: ReAct+ ACE + offline warmup✗ 69.6+5.9 53.6+10.7 66.0+24.5 48.9+27.3 59.5+17.1\n",
            "Table 3:Ablation Studies on AppWorld.We study how particular design choices of ACE (iterative\n",
            "refinement, multi-epoch adaptation, and offline warmup) could help high-quality context adaptation.\n",
            "Method Latency (s)↓# Rollouts↓\n",
            "ReAct + GEPA 53898 1434\n",
            "ReAct + ACE 9517 (-82.3%) 357(-75.1%)\n",
            "(a)Offline(AppWorld).\n",
            "Method Latency (s)↓Token Cost ($)↓\n",
            "DC (CU) 65104 17.7\n",
            "ACE 5503 (-91.5%) 2.9(-83.6%)\n",
            "(b)Online(FiNER).\n",
            "Embedding 65: [-0.01715869829058647, 0.01227894239127636, -0.044914331287145615, -0.04214654490351677, -0.026892181485891342, -0.018556030467152596, 0.05835007131099701, 0.0309771541506052, -0.028382068499922752, -0.00857206154614687] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 66: ACE 5503 (-91.5%) 2.9(-83.6%)\n",
            "(b)Online(FiNER).\n",
            "Table 4:Cost and Speed Analysis.We measure the context adaptation latency, number of rollouts, and\n",
            "dollar costs of ACE against GEPA (offline) and DC (online).\n",
            "XBRL rules) that goes beyond fixed demonstrations or monolithic optimized prompts. In the online setting,\n",
            "ACE continues to exceed prior adaptive methods such as DC by an average of 6.2%, further confirming the\n",
            "Embedding 66: [-0.018353693187236786, -0.027589352801442146, -0.03789868205785751, -0.05248532444238663, -0.011751254089176655, -0.007195708807557821, 0.05905289202928543, 0.04299085959792137, -0.04048891365528107, 0.004912209697067738] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 67: benefit of agentic context engineering for accumulating reusable insights across specialized domains.\n",
            "Moreover, we also observe that when ground-truth supervision or reliable execution signals are absent,\n",
            "both ACE and DC may degrade in performance. In such cases, the constructed context can be polluted by\n",
            "spurious or misleading signals, highlighting a potential limitation of inference-time adaptation without\n",
            "Embedding 67: [-0.005486065521836281, 0.027249889448285103, -0.026439746841788292, -0.016360176727175713, -0.02216470055282116, 0.00569641450420022, 0.05875273048877716, -0.03750075772404671, -0.0018083975883200765, 0.0038675821851938963] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 68: reliable feedback. This suggests that while ACE is robust under rich feedback (e.g.,code execution results or\n",
            "formula correctness in agent tasks), its effectiveness depends on the availability of signals that allow the\n",
            "Reflector and Curator to make sound judgments. We return to this limitation in Appendix B.\n",
            "4.5 Ablation Study\n",
            "Table 3 reports ablation studies on the AppWorld benchmark, analyzing how individual design choices\n",
            "Embedding 68: [0.021241653710603714, -0.0067765237763524055, -0.04322071373462677, -0.010348174721002579, -0.031005339697003365, -0.024316048249602318, 0.038450177758932114, -0.00860835611820221, -0.011204268783330917, 0.0024181311018764973] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 69: of ACE contribute to effective context adaptation. We examine three factors: (1)the Reflector with iterative\n",
            "refinement, our addition to the agentic framework beyond Dynamic Cheatsheet, (2)multi-epoch adaptation,\n",
            "which refines contexts over training samples multiple times, and (3)offline warmup, which initializes the\n",
            "context through offline adaptation before online adaptation begins.\n",
            "4.6 Cost and Speed Analysis\n",
            "Embedding 69: [-0.005471505224704742, -0.023764174431562424, -0.03515792638063431, -0.018214941024780273, -0.004245536867529154, 0.029458150267601013, 0.0700431764125824, 0.005109088495373726, -0.05985332280397415, -0.011522723361849785] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 70: 4.6 Cost and Speed Analysis\n",
            "Due to its support for incremental, “delta\" context updates and non-LLM-based context merging and de-\n",
            "duplication, ACE demonstrates particular advantages in reducing the cost (in terms of the number of rollouts\n",
            "or the amount of dollar cost for token ingestion/generation) and latency of adaptation.\n",
            "As examples, on the offline adaptation of AppWorld, ACE achieves 82.3% reduction in adaptation latency\n",
            "Embedding 70: [-0.018362583592534065, -0.031239142641425133, -0.05608418956398964, -0.024486862123012543, -0.04544858634471893, -0.014259027317166328, 0.0677407756447792, -0.033659931272268295, -0.03430178761482239, 0.015320382080972195] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 71: and 75.1% reduction in the number of rollouts as compared to GEPA (Table 4(a)). On the online adaptation\n",
            "9\n",
            "Embedding 71: [-0.027338022366166115, -0.012633448466658592, -0.038862694054841995, -0.06427942216396332, 0.027206633239984512, 0.010064618661999702, 0.039216287434101105, 0.01928761787712574, -0.07104085385799408, 0.015147529542446136] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 72: of FiNER, ACE achieves 91.5% reduction in adaptation latency and 83.6% reduction in token dollar cost for\n",
            "token ingestion and generation as compared to DC (Table 4(b)).\n",
            "5 Discussion\n",
            "Longer Context ̸= Higher Serving Cost.Although ACE produces longer contexts than methods such\n",
            "as GEPA, this does not translate to linearly higher inference cost or GPU memory usage. Modern serving\n",
            "infrastructures are increasingly optimized for long-context workloads through techniques such as the\n",
            "Embedding 72: [-0.025019362568855286, -0.001709000556729734, -0.033638861030340195, -0.000563252076972276, -0.05942365154623985, 0.015275927260518074, 0.10375088453292847, -0.021868839859962463, -0.029174000024795532, 0.025216439738869667] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 73: reuse [17, 51], compression [30, 32], and offload [25] of KV cache. These mechanisms allow frequently reused\n",
            "context segments to be cached locally or remotely, avoiding repetitive and expensive prefill operations.\n",
            "Ongoing advances in ML systems suggest that the amortized cost of handling long contexts will continue to\n",
            "decrease, making context-rich approaches like ACE increasingly practical in deployment.\n",
            "Embedding 73: [-0.008793401531875134, -0.025568969547748566, -0.018934180960059166, 0.0034896773286163807, -0.045021042227745056, 0.010332965292036533, 0.07517807185649872, -0.026121653616428375, -0.020264526829123497, 0.0021185653749853373] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 74: Implications for Online and Continuous Learning.Online and continuous learning are key research\n",
            "directions in machine learning for addressing issues like distribution shifts [ 19, 24] and limited training\n",
            "data [21, 37, 60]. ACE offers a flexible and efficient alternative to conventional model fine-tuning, as\n",
            "adapting contexts is generally cheaper than updating model weights [ 9, 20, 26, 28]. Moreover, because\n",
            "Embedding 74: [-0.0256651658564806, 0.03534834086894989, -0.04288554564118385, -0.02846579998731613, -0.02111774869263172, 0.012565560638904572, 0.05460922047495842, 0.00318340421654284, -0.054119933396577835, 0.003828431712463498] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 75: contexts are human-interpretable, ACE enablesselective unlearning[ 8, 10, 29]—whether due to privacy or\n",
            "legal constraints [1, 2], or when outdated or incorrect information is identified by domain experts. These are\n",
            "promising directions for future work, where ACE could play a central role in advancing continuous and\n",
            "responsible learning.\n",
            "References\n",
            "[1] General Data Protection Regulation article 17: Right to erasure. EU Regulation 2016/679, 2016. Official\n",
            "consolidated text.\n",
            "Embedding 75: [-0.02553911693394184, 0.06325238943099976, -0.030019180849194527, 0.013147358782589436, -0.04718751087784767, 0.021280670538544655, 0.0896248072385788, -0.019530242308974266, 0.01333575788885355, 0.020454613491892815] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 76: consolidated text.\n",
            "[2] California consumer privacy act, civil code §1798.105: Right to delete. State of California Civil Code,\n",
            "2018.\n",
            "[3] Rishabh Agarwal, Avi Singh, Lei Zhang, Bernd Bohnet, Luis Rosias, Stephanie Chan, Biao Zhang,\n",
            "Ankesh Anand, Zaheer Abbas, Azade Nova, et al. Many-shot in-context learning.Advances in Neural\n",
            "Information Processing Systems, 37:76930–76966, 2024.\n",
            "[4] Lakshya A Agrawal, Shangyin Tan, Dilara Soylu, Noah Ziems, Rishi Khare, Krista Opsahl-Ong, Arnav\n",
            "Embedding 76: [0.02524326555430889, 0.07044888287782669, -0.028791965916752815, 0.017825886607170105, -0.0388605035841465, 0.026241501793265343, 0.1141214445233345, 0.007801572326570749, -0.008226387202739716, -0.022987335920333862] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 77: Singhvi, Herumb Shandilya, Michael J Ryan, Meng Jiang, et al. Gepa: Reflective prompt evolution can\n",
            "outperform reinforcement learning.arXiv preprint arXiv:2507.19457, 2025.\n",
            "[5] AppWorld. Leaderboard.https://appworld.dev/leaderboard, 2025. Accessed: 2025-09-20.\n",
            "[6] Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. Self-rag: Learning to\n",
            "retrieve, generate, and critique through self-reflection. 2024.\n",
            "Embedding 77: [0.06355366110801697, 0.01783403754234314, -0.03435199707746506, -0.02024531178176403, -0.015282888896763325, -0.0267762653529644, -0.013884143903851509, -0.015431568026542664, -0.03726482763886452, -0.00472453236579895] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 78: [7] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican,\n",
            "George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. Improving\n",
            "language models by retrieving from trillions of tokens. InInternational conference on machine learning,\n",
            "pages 2206–2240. PMLR, 2022.\n",
            "[8] Lucas Bourtoule, Varun Chandrasekaran, Christopher Choquette-Choo, Hengrui Jia, Adelin Travers,\n",
            "Embedding 78: [0.04714420437812805, 0.10172416269779205, -0.004523404408246279, 0.06630794703960419, -0.05444277077913284, 0.010362260974943638, -0.006297561340034008, 0.03927236422896385, -0.01685379259288311, -0.06617219001054764] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 79: Baiwu Zhang, David Lie, and Nicolas Papernot. Machine unlearning.IEEE Symposium on Security and\n",
            "Privacy, pages 141–159, 2021.\n",
            "[9] Tom Brown et al. Language models are few-shot learners. InNeurIPS, 2020.\n",
            "[10] Yinzhi Cao and Junfeng Yang. Towards making systems forget with machine unlearning. InIEEE\n",
            "Symposium on Security and Privacy, 2015.\n",
            "10\n",
            "Embedding 79: [-0.0018000025302171707, 0.05085970088839531, -0.012920563109219074, 0.03257611021399498, -0.05107779800891876, 0.01945863664150238, 0.044882290065288544, -0.013308538123965263, 0.019113371148705482, -0.030499542132019997] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 80: [11] Tianxiang Chen, Zhentao Tan, Xiaofan Bo, Yue Wu, Tao Gong, Qi Chu, Jieping Ye, and Nenghai Yu.\n",
            "Flora: Effortless context construction to arbitrary length and scale.arXiv preprint arXiv:2507.19786, 2025.\n",
            "[12] Yeounoh Chung, Gaurav T Kakkar, Yu Gan, Brenton Milne, and Fatma Ozcan. Is long context all you\n",
            "need? leveraging llm’s extended context for nl2sql.arXiv preprint arXiv:2501.12372, 2025.\n",
            "[13] DeepSeek-AI. Deepseek-v3 technical report, 2024.\n",
            "Embedding 80: [-0.014975196681916714, 0.07257066667079926, -0.012871729210019112, 0.053366366773843765, -0.05789436772465706, -0.03305426612496376, -0.007536363787949085, 0.005170406773686409, 0.0031571988947689533, -0.0293082594871521] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 81: [14] DSPy. dspy.gepa: Reflective prompt optimizer. https://dspy.ai/api/optimizers/GEPA/overview/,\n",
            "2025. Accessed: 2025-09-24.\n",
            "[15] DSPy. dspy.miprov2.https://dspy.ai/api/optimizers/MIPROv2/, 2025. Accessed: 2025-09-24.\n",
            "[16] Shuzheng Gao, Chaozheng Wang, Cuiyun Gao, Xiaoqian Jiao, Chun Yong Chong, Shan Gao, and\n",
            "Michael Lyu. The prompt alchemist: Automated llm-tailored prompt optimization for test case genera-\n",
            "tion.arXiv preprint arXiv:2501.01329, 2025.\n",
            "Embedding 81: [-0.026003293693065643, 0.010887649841606617, -0.0322418138384819, 0.029674844816327095, -0.03678854927420616, -0.03784218430519104, 0.03164851665496826, 0.025303935632109642, 0.002987680723890662, -0.003457368118688464] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 82: tion.arXiv preprint arXiv:2501.01329, 2025.\n",
            "[17] In Gim, Guojun Chen, Seung-seob Lee, Nikhil Sarda, Anurag Khandelwal, and Lin Zhong. Prompt\n",
            "cache: Modular attention reuse for low-latency inference.Proceedings of Machine Learning and Systems,\n",
            "6:325–338, 2024.\n",
            "[18] Neel Guha, Julian Nyarko, Daniel Ho, Christopher Ré, Adam Chilton, Alex Chohlas-Wood, Austin\n",
            "Peters, Brandon Waldon, Daniel Rockmore, Diego Zambrano, et al. Legalbench: A collaboratively built\n",
            "Embedding 82: [0.01730545423924923, 0.067435622215271, -0.011583633720874786, -0.01535471435636282, -0.0793113261461258, -0.0003455755941104144, 0.06395645439624786, 0.002996306400746107, -0.012031858786940575, -0.02329157665371895] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 83: benchmark for measuring legal reasoning in large language models.Advances in neural information\n",
            "processing systems, 36:44123–44279, 2023.\n",
            "[19] Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. InICLR, 2021.\n",
            "[20] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and\n",
            "Weizhu Chen. LoRA: Low-rank adaptation of large language models.arXiv:2106.09685, 2021.\n",
            "Embedding 83: [0.039245039224624634, 0.061537135392427444, -0.004538548644632101, 0.02207104302942753, -0.060198161751031876, 0.032336506992578506, 0.029379509389400482, 0.04918999224901199, -0.004973053932189941, -0.04900667443871498] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 84: [21] Maxwell L Hutchinson, Erin Antono, Brenna M Gibbons, Sean Paradiso, Julia Ling, and Bryce Meredig.\n",
            "Overcoming data scarcity with transfer learning.arXiv preprint arXiv:1711.05099, 2017.\n",
            "[22] Mingjian Jiang, Yangjun Ruan, Luis Lastras, Pavan Kapanipathi, and Tatsunori Hashimoto. Putting it\n",
            "all into context: Simplifying agents with lclms.arXiv preprint arXiv:2505.08120, 2025.\n",
            "[23] Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish\n",
            "Embedding 84: [-0.03850802406668663, 0.04779931530356407, -0.01211002841591835, 0.0037265934515744448, -0.007797726895660162, 0.007963811978697777, 0.03189025819301605, -0.016945451498031616, -0.011974766850471497, 0.04334632679820061] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 85: Sabharwal. Decomposed prompting: A modular approach for solving complex tasks.arXiv preprint\n",
            "arXiv:2210.02406, 2022.\n",
            "[24] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubra-\n",
            "mani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A benchmark of\n",
            "in-the-wild distribution shifts. InInternational conference on machine learning, pages 5637–5664. PMLR,\n",
            "2021.\n",
            "Embedding 85: [0.016694864258170128, 0.032718926668167114, -0.024052780121564865, -0.011610614135861397, -0.059026915580034256, 0.014483842067420483, -0.019424300640821457, 0.03807709366083145, -0.03652099892497063, 0.008461888879537582] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 86: 2021.\n",
            "[25] Wonbeom Lee, Jungi Lee, Junghwan Seo, and Jaewoong Sim.{InfiniGen}: Efficient generative inference\n",
            "of large language models with dynamic {KV} cache management. In18th USENIX Symposium on\n",
            "Operating Systems Design and Implementation (OSDI 24), pages 155–172, 2024.\n",
            "[26] Brian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efficient prompt\n",
            "tuning. InEMNLP, 2021.\n",
            "[27] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,\n",
            "Embedding 86: [0.03737378120422363, 0.004564797971397638, -0.04181157052516937, 0.019973352551460266, -0.028559425845742226, 0.01030976977199316, 0.008722713217139244, -0.009413930587470531, -0.00012115771096432582, -0.0014082087436690927] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 87: Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented generation for\n",
            "knowledge-intensive nlp tasks.Advances in neural information processing systems, 33:9459–9474, 2020.\n",
            "[28] Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation.ACL,\n",
            "2021.\n",
            "11\n",
            "Embedding 87: [0.0714399516582489, -0.012279580347239971, -0.027160434052348137, -0.0010354777332395315, -0.020806731656193733, -0.030997203662991524, -0.011149095371365547, 0.04197297245264053, -0.0016431428957730532, -0.0428628996014595] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 88: [29] Shiyang Liu et al. Rethinking machine unlearning for large language models.arXiv:2402.08787, 2024.\n",
            "[30] Yuhan Liu, Hanchen Li, Yihua Cheng, Siddhant Ray, Yuyang Huang, Qizheng Zhang, Kuntai Du, Jiayi\n",
            "Yao, Shan Lu, Ganesh Ananthanarayanan, et al. Cachegen: Kv cache compression and streaming for\n",
            "fast large language model serving. InProceedings of the ACM SIGCOMM 2024 Conference, pages 38–56,\n",
            "2024.\n",
            "Embedding 88: [-0.011730258353054523, 0.06429975479841232, -0.00864739902317524, 0.034407585859298706, -0.03074057213962078, 0.0372486338019371, 0.008810223080217838, 0.03446474298834801, -0.010075467638671398, -0.02125074714422226] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 89: 2024.\n",
            "[31] Zhining Liu, Rana Ali Amjad, Ravinarayana Adkathimar, Tianxin Wei, and Hanghang Tong. Selfelicit:\n",
            "Your language model secretly knows where is the relevant evidence.arXiv preprint arXiv:2502.08767,\n",
            "2025.\n",
            "[32] Zirui Liu, Jiayi Yuan, Hongye Jin, Shaochen Zhong, Zhaozhuo Xu, Vladimir Braverman, Beidi Chen, and\n",
            "Xia Hu. Kivi: A tuning-free asymmetric 2bit quantization for kv cache.arXiv preprint arXiv:2402.02750,\n",
            "2024.\n",
            "Embedding 89: [-0.0019561012741178274, 0.028803439810872078, -0.018736019730567932, 0.043773699551820755, -0.05594354122877121, -0.007188496179878712, 0.0026448967400938272, 0.014330565929412842, -0.007647940423339605, -0.027987895533442497] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 90: 2024.\n",
            "[33] Lefteris Loukas, Manos Fergadiotis, Ilias Chalkidis, Eirini Spyropoulou, Prodromos Malakasiotis, Ion\n",
            "Androutsopoulos, and Georgios Paliouras. Finer: Financial numeric entity recognition for xbrl tagging.\n",
            "arXiv preprint arXiv:2203.06482, 2022.\n",
            "[34] Yansheng Mao, Jiaqi Li, Fanxu Meng, Jing Xiong, Zilong Zheng, and Muhan Zhang. Lift: Improving\n",
            "long context understanding through long input fine-tuning.arXiv preprint arXiv:2412.13626, 2024.\n",
            "Embedding 90: [-0.01733345538377762, -0.0035510659217834473, 0.01756558008491993, 0.02249831147491932, -0.008606228977441788, 0.02570722997188568, 0.028532447293400764, 0.034212611615657806, -0.01114003174006939, -0.008117269724607468] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 91: [35] Sami Marreed, Alon Oved, Avi Yaeli, Segev Shlomov, Ido Levy, Offer Akrabi, Aviad Sela, Asaf Adi, and\n",
            "Nir Mashkif. Towards enterprise-ready computer using generalist agent.arXiv preprint arXiv:2503.01861,\n",
            "2025.\n",
            "[36] Krista Opsahl-Ong, Michael J Ryan, Josh Purtell, David Broman, Christopher Potts, Matei Zaharia, and\n",
            "Omar Khattab. Optimizing instructions and demonstrations for multi-stage language model programs.\n",
            "arXiv preprint arXiv:2406.11695, 2024.\n",
            "Embedding 91: [0.02068956196308136, 0.034441977739334106, -0.027264853939414024, 0.026861943304538727, -0.06328637152910233, -4.529273428488523e-05, 0.015371210873126984, -0.0004301389562897384, 0.012282638810575008, -0.025433089584112167] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 92: arXiv preprint arXiv:2406.11695, 2024.\n",
            "[37] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning.IEEE Transactions on Knowledge and\n",
            "Data Engineering, 22(10):1345–1359, 2010.\n",
            "[38] Shishir G Patil, Tianjun Zhang, Xin Wang, and Joseph E Gonzalez. Gorilla: Large language model\n",
            "connected with massive apis.Advances in Neural Information Processing Systems, 37:126544–126565, 2024.\n",
            "[39] Bowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole. Yarn: Efficient context window\n",
            "Embedding 92: [-0.016517268493771553, 0.08562514930963516, -0.027084441855549812, 0.06417887657880783, -0.04318826645612717, -0.0017018573125824332, 0.0194643996655941, 0.0011920153629034758, -0.0023089272435754538, -0.03200842812657356] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 93: extension of large language models.arXiv preprint arXiv:2309.00071, 2023.\n",
            "[40] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion:\n",
            "Language agents with verbal reinforcement learning.Advances in Neural Information Processing Systems,\n",
            "36:8634–8652, 2023.\n",
            "[41] Mirac Suzgun, Mert Yuksekgonul, Federico Bianchi, Dan Jurafsky, and James Zou. Dynamic cheatsheet:\n",
            "Test-time learning with adaptive memory.arXiv preprint arXiv:2504.07952, 2025.\n",
            "Embedding 93: [0.051588818430900574, 0.028450053185224533, -0.043171677738428116, 0.011781513690948486, -0.05316510051488876, -0.0015443851007148623, 0.007997239008545876, 0.01656259223818779, -0.005282082594931126, -0.054254211485385895] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 94: [42] Mirac Suzgun, Mert Yuksekgonul, Federico Bianchi, Dan Jurafsky, and James Zou. Dynamic cheatsheet:\n",
            "Test-time learning with adaptive memory. https://github.com/suzgunmirac/dynamic-cheatsheet,\n",
            "2025. Accessed: 2025-09-24.\n",
            "[43] Harsh Trivedi, Tushar Khot, Mareike Hartmann, Ruskin Manku, Vinty Dong, Edward Li, Shashank\n",
            "Gupta, Ashish Sabharwal, and Niranjan Balasubramanian. Appworld: A controllable world of apps\n",
            "Embedding 94: [0.017323559150099754, -0.017503784969449043, -0.036203913390636444, 0.0010824267519637942, -0.019882462918758392, -0.02156885340809822, 0.006715289782732725, -0.0025439851451665163, 0.020085763186216354, -0.017503131181001663] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 95: and people for benchmarking interactive coding agents.arXiv preprint arXiv:2407.18901, 2024.\n",
            "[44] Dannong Wang, Jaisal Patel, Daochen Zha, Steve Y Yang, and Xiao-Yang Liu. Finlora: Benchmarking\n",
            "lora methods for fine-tuning llms on financial datasets.arXiv preprint arXiv:2505.19819, 2025.\n",
            "[45] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery,\n",
            "and Denny Zhou. Self-consistency improves chain of thought reasoning in language models.arXiv\n",
            "Embedding 95: [-0.03398926928639412, 0.040142323821783066, -0.016442550346255302, 0.03353966027498245, -0.038547441363334656, 0.019425101578235626, -0.01185406930744648, 0.021102651953697205, 0.0006650278810411692, 0.006018826272338629] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 96: preprint arXiv:2203.11171, 2022.\n",
            "12\n",
            "Embedding 96: [-0.010295168496668339, -0.011591192334890366, -0.013000184670090675, 0.024175019934773445, -0.01057467795908451, 0.0018910439684987068, -0.0015301242237910628, 0.030585434287786484, -0.05188940837979317, 0.009747416712343693] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 97: [46] Zora Zhiruo Wang, Jiayuan Mao, Daniel Fried, and Graham Neubig. Agent workflow memory.arXiv\n",
            "preprint arXiv:2409.07429, 2024.\n",
            "[47] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,\n",
            "et al. Chain-of-thought prompting elicits reasoning in large language models.Advances in neural\n",
            "information processing systems, 35:24824–24837, 2022.\n",
            "[48] Wujiang Xu, Kai Mei, Hang Gao, Juntao Tan, Zujie Liang, and Yongfeng Zhang. A-mem: Agentic\n",
            "Embedding 97: [0.01750882901251316, -0.010601243935525417, -0.04869546741247177, -0.014085805974900723, -0.05937056243419647, 0.010611888021230698, 0.04403875023126602, -0.012243879027664661, 0.020515723153948784, 0.0014583446318283677] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 98: memory for llm agents.arXiv preprint arXiv:2502.12110, 2025.\n",
            "[49] John Yang, Carlos E Jimenez, Alexander Wettig, Kilian Lieret, Shunyu Yao, Karthik Narasimhan, and\n",
            "Ofir Press. Swe-agent: Agent-computer interfaces enable automated software engineering.Advances in\n",
            "Neural Information Processing Systems, 37:50528–50652, 2024.\n",
            "[50] Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov, and\n",
            "Embedding 98: [0.0037287049926817417, -0.02864639274775982, -0.03298330679535866, 0.029300633817911148, -0.029039407148957253, -0.01874527893960476, -0.007599427830427885, -0.015613507479429245, 0.030865760520100594, -0.01332997065037489] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 99: Christopher D Manning. Hotpotqa: A dataset for diverse, explainable multi-hop question answering.\n",
            "arXiv preprint arXiv:1809.09600, 2018.\n",
            "[51] Jiayi Yao, Hanchen Li, Yuhan Liu, Siddhant Ray, Yihua Cheng, Qizheng Zhang, Kuntai Du, Shan Lu,\n",
            "and Junchen Jiang. Cacheblend: Fast large language model serving for rag with cached knowledge\n",
            "fusion. InProceedings of the Twentieth European Conference on Computer Systems, pages 94–109, 2025.\n",
            "Embedding 99: [0.02260931022465229, 0.03328358381986618, 0.01158851757645607, 0.03106638975441456, -0.021117258816957474, 0.03850468248128891, 0.04266675189137459, -0.03519830107688904, 0.030892981216311455, -0.04340432956814766] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 100: [52] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\n",
            "React: Synergizing reasoning and acting in language models. InInternational Conference on Learning\n",
            "Representations (ICLR), 2023.\n",
            "[53] Jiacheng Ye, Chengzu Li, Lingpeng Kong, and Tao Yu. Generating data for symbolic language with\n",
            "large language models.arXiv preprint arXiv:2305.13917, 2023.\n",
            "[54] Mert Yuksekgonul, Federico Bianchi, Joseph Boen, Sheng Liu, Zhi Huang, Carlos Guestrin, and James\n",
            "Embedding 100: [0.0026467633433640003, 0.034923162311315536, -0.05015893653035164, 0.03497149422764778, -0.06608040630817413, 0.016680337488651276, -0.007028140593320131, 0.01452597975730896, 0.029402300715446472, -0.07528655230998993] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 101: Zou. Textgrad: Automatic\" differentiation\" via text.arXiv preprint arXiv:2406.07496, 2024.\n",
            "[55] Matei Zaharia, Omar Khattab, Lingjiao Chen, Jared Quincy Davis, Heather Miller, Chris Potts, James\n",
            "Zou, Michael Carbin, Jonathan Frankle, Naveen Rao, and Ali Ghodsi. The shift from models to\n",
            "compound ai systems.https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/, 2024.\n",
            "[56] Genghan Zhang, Weixin Liang, Olivia Hsu, and Kunle Olukotun. Adaptive self-improvement llm\n",
            "Embedding 101: [0.029329221695661545, 0.01430722326040268, -0.024564264342188835, 0.044942744076251984, -0.01455846056342125, 0.00658332509920001, 0.017325764521956444, 0.014511601068079472, 0.02992689423263073, -0.05199465528130531] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 102: agentic system for ml library development.arXiv preprint arXiv:2502.02534, 2025.\n",
            "[57] Qizheng Zhang, Ali Imran, Enkeleda Bardhi, Tushar Swamy, Nathan Zhang, Muhammad Shahbaz,\n",
            "and Kunle Olukotun. Caravan: Practical online learning of {In-Network}{ML} models with labeling\n",
            "agents. In18th USENIX Symposium on Operating Systems Design and Implementation (OSDI 24), pages\n",
            "325–345, 2024.\n",
            "[58] Qizheng Zhang, Michael Wornow, and Kunle Olukotun. Cost-efficient serving of llm agents via test-time\n",
            "Embedding 102: [0.014505711384117603, 0.025726312771439552, -0.03195439651608467, 0.0271785669028759, -0.03224743902683258, 0.01560926716774702, 0.0845349133014679, 0.008472807705402374, 0.05907563492655754, -0.026342114433646202] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 103: plan caching.arXiv preprint arXiv:2506.14852, 2025.\n",
            "[59] Huichi Zhou, Yihang Chen, Siyuan Guo, Xue Yan, Kin Hei Lee, Zihan Wang, Ka Yiu Lee, Guchun\n",
            "Zhang, Kun Shao, Linyi Yang, et al. Agentfly: Fine-tuning llm agents without fine-tuning llms.arXiv\n",
            "preprint arXiv:2508.16153, 2025.\n",
            "[60] Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong, and\n",
            "Qing He. A comprehensive survey on transfer learning.arXiv:1911.02685, 2019.\n",
            "13\n",
            "Embedding 103: [-0.028859281912446022, 0.01049868855625391, 0.0007441804627887905, 0.010418574325740337, -0.041159871965646744, -0.025754496455192566, -0.0038736844435334206, -0.008322678506374359, -0.01581435650587082, 0.00869415421038866] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 104: A Related Work on Agent Memory\n",
            "A growing body of work explores how agents can accumulate experience from past trajectories and leverage\n",
            "external (often non-parametric) memory to guide future actions. AgentFly [59] presents an extensible frame-\n",
            "work where memory evolves continuously as agents solve tasks, enabling scalable reinforcement learning\n",
            "and long-horizon reasoning across diverse environments. AWM (Agent Workflow Memory) [46] induces\n",
            "Embedding 104: [-0.003997487016022205, -0.017793718725442886, -0.0258366409689188, -0.027415724471211433, -0.042706504464149475, -0.022798776626586914, -0.016185585409402847, -0.007943902164697647, -0.005646666046231985, -0.005485900212079287] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 105: reusableworkflows—structured routines distilled from past trajectories—and selectively injects them into\n",
            "memory to improve efficiency and generalization in web navigation benchmarks. A-MEM [48] introduces\n",
            "a dynamically organized memory system inspired by the Zettelkasten method: each stored memory is\n",
            "annotated with structured attributes (e.g.,tags, keywords, contextual descriptions) and automatically linked\n",
            "Embedding 105: [0.025608686730265617, -0.02219405584037304, -0.03717707842588425, -0.02698366343975067, -0.0029651359654963017, 0.022453203797340393, -0.03311179205775261, 0.01473209261894226, 0.031052911654114723, -0.035015031695365906] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 106: to relevant past entries, while existing entries are updated to integrate new knowledge, yielding adaptive\n",
            "and context-aware retrieval. Agentic Plan Caching [ 58] instead focuses on cost efficiency by extracting\n",
            "reusable plan templates from agent trajectories and caching them for fast execution at test time.\n",
            "Together, these works demonstrate the value of external memory for improving adaptability, efficiency, and\n",
            "Embedding 106: [0.04790612310171127, 0.0006143004866316915, -0.03178258240222931, -0.012677663937211037, -0.017156412824988365, -0.037861041724681854, -0.010104755870997906, 0.00034788547782227397, 0.018556101247668266, -0.005524766631424427] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 107: generalization in LLM agents. Our work differs by tackling the broader challenge ofcontext adaptation, which\n",
            "spans not only agent memory but also system prompts, factual evidence, and other inputs underpinning AI\n",
            "systems. We further highlight two fundamental limitations of existing adaptation methods—brevity biasand\n",
            "context collapse—and show that addressing them is essential for robustness, reliability, and scalability beyond\n",
            "Embedding 107: [0.015110000036656857, -0.005092598032206297, -0.026890352368354797, 0.02002738043665886, -0.004240137990564108, 0.0002116532123181969, -0.024055836722254753, 0.017379900440573692, 0.011209791526198387, -0.001979568973183632] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 108: raw task performance. Accordingly, our evaluation considers not only accuracy but also cost, latency, and\n",
            "scalability.\n",
            "B Limitations and Challenges\n",
            "A potential limitation of ACE is its reliance on a reasonably strong Reflector: if the Reflector fails to extract\n",
            "meaningful insights from generated traces or outcomes, the constructed context may become noisy or even\n",
            "harmful. In domain-specific tasks where no model can extract useful insights, the resulting context will\n",
            "Embedding 108: [-0.07089028507471085, -0.019783182069659233, -0.03258335217833519, -0.004909600596874952, -0.04599885269999504, -0.015524613671004772, 0.058147404342889786, -0.019360873848199844, -0.037388186901807785, 0.012821167707443237] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 109: naturally lack them. This dependency is similar to Dynamic Cheatsheet [41], where the quality of adaptation\n",
            "hinges on the underlying model’s ability to curate memory. We also note that not all applications require\n",
            "rich or detailed contexts. Tasks like HotPotQA [50] often benefit more from concise, high-level instructions\n",
            "(e.g.,how to retrieve and synthesize evidence) than from long contexts. Similarly, games with fixed strategies\n",
            "Embedding 109: [0.009276681579649448, 0.0006489920779131353, -0.03550543636083603, 0.01218497846275568, -0.048643603920936584, 0.01163253653794527, -0.0038646096363663673, 0.0030929059721529484, -0.02325463481247425, 0.01586928591132164] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 110: such as Game of 24 [ 41] may only need a single reusable rule, rendering additional context redundant.\n",
            "Overall, ACE is most beneficial in settings that demand detailed domain knowledge, complex tool use,\n",
            "or environment-specific strategies that go beyond what is already embedded in model weights or simple\n",
            "system instructions.\n",
            "C AppWorld Leaderboard Snapshot (09/2025)\n",
            "Figure 5: The AppWorld leaderboard as accessed on 09/20/2025.\n",
            "14\n",
            "Embedding 110: [-0.000443361874204129, -0.017062732949852943, -0.04452180862426758, -0.007272573187947273, -0.030670907348394394, -0.01659020222723484, 0.027582967653870583, -0.021513579413294792, -0.002682237885892391, 0.017218712717294693] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 111: D Prompts\n",
            "We release the language model prompts used in our agentic context engineering framework as well as the\n",
            "baselines to support research transparency and reproducibility.\n",
            "I\tam\tyour\tsupervisor\tand\tyou\tare\ta\tsuper\tintelligent\tAI\tAssistant\twhose\tjob\tis\tto\tachieve\tmy\tday-to-day\ttasks\tcompletely\tautonomously.\n",
            "To\tdo\tthis,\tyou\twill\tneed\tto\tinteract\twith\tapp/s\t(e.g.,\tspotify,\tvenmo\tetc)\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\tFor\tthis\tyou\twill\n",
            "undertake\ta\t\n",
            "multi-step\tconversation\n",
            "Embedding 111: [0.06678106635808945, -0.047524064779281616, -0.046982020139694214, -0.01711815409362316, -0.030073940753936768, -0.021051235496997833, 0.06880120187997818, -0.025488516315817833, 0.05083264037966728, -0.014871467836201191] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 112: undertake\ta\t\n",
            "multi-step\tconversation\n",
            "\tusing\ta\tpython\tREPL\tenvironment.\tThat\tis,\tyou\twill\twrite\tthe\tpython\tcode\tand\tthe\tenvironment\twill\n",
            "execute\tit\tand\tshow\tyou\tthe\tresult,\tbased\ton\twhich,\tyou\twill\twrite\tpython\tcode\tfor\tthe\tnext\tstep\tand\tso\ton,\tuntil\tyou’ve\tachieved\tthe\tgoal.\n",
            "This\tenvironment\twill\tlet\tyou\tinteract\twith\tapp/s\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\n",
            "Here\tare\tthree\tkey\tAPIs\tthat\tyou\tneed\tto\tknow\tto\tget\tmore\tinformation\n",
            "Embedding 112: [0.0352204330265522, 0.022571852430701256, -0.012621763162314892, 0.01332895364612341, -0.01706560142338276, 0.0003677840286400169, -0.01885652355849743, -0.025058286264538765, 0.06627842038869858, -0.022453399375081062] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 113: Each\tcode\texecution\twill\tproduce\tan\toutput\tthat\tyou\tcan\tuse\tin\tsubsequent\tcalls.\tUsing\tthese\tAPIs,\tyou\tcan\tnow\tgenerate\tcode,\tthat\tI\twill\n",
            "execute,\tto\tsolve\tthe\ttask.\n",
            "Let’s\tstart\twith\tthe\ttask\n",
            "[3\tshot\texample]\n",
            "Key\tinstructions\n",
            ":\n",
            "1.\t\n",
            "Make\tsure\tto\tend\tcode\tblocks\twith\t```\tfollowed\tby\ta\tnewline().\n",
            "2.\t\n",
            "Remember\tyou\tcan\tuse\tthe\tvariables\tin\tyour\tcode\tin\tsubsequent\tcode\tblocks.\n",
            "3.\t\n",
            "Remember\tthat\tthe\temail\taddresses,\taccess\ttokens\tand\tvariables\t(e.g.\tspotify_password)\tin\tthe\texample\tabove\tare\tnot\tvalid\n",
            "Embedding 113: [0.01846342347562313, -0.050437118858098984, -0.039675671607255936, 0.009142214432358742, -0.030231699347496033, 0.012496594339609146, 0.035498928278684616, -0.032158028334379196, -0.001527479849755764, 0.014874886721372604] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 114: anymore.\n",
            "4.\t\n",
            "You\tcan\tuse\tthe\t“supervisor”\tapp\tto\tget\tinformation\tabout\tmy\taccounts\tand\tuse\tthe\t“phone”\tapp\tto\tget\tinformation\tabout\tfriends\n",
            "and\tfamily.\n",
            "5.\t\n",
            "Always\tlook\tat\tAPI\tspecifications\t(using\t\n",
            "apis.api_docs.show_api_doc\n",
            ")\tbefore\tcalling\tan\tAPI.\n",
            "6.\t\n",
            "Write\tsmall\tchunks\tof\tcode\tand\tonly\tone\tchunk\tof\tcode\tin\tevery\tstep.\tMake\tsure\teverything\tis\tworking\tcorrectly\tbefore\tmaking\tany\n",
            "irreversible\tchange.\n",
            "7.\t\n",
            "Many\tAPIs\treturn\titems\tin\t“pages”.\tMake\tsure\tto\trun\tthrough\tall\tthe\tpages\tby\tlooping\tover\n",
            "Embedding 114: [0.05300213769078255, 0.03288986533880234, -0.023948032408952713, -0.0015117762377485633, -0.0010538367787376046, -0.0036150291562080383, 0.028679559007287025, 0.0008432774338871241, 0.05865698307752609, 0.014107010327279568] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 115: page_index\n",
            ".\n",
            "8.\t\n",
            "Once\tyou\thave\tcompleted\tthe\ttask,\tmake\tsure\tto\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            ".\tIf\tthe\ttask\tasked\tfor\tsome\tinformation,\n",
            "return\tit\tas\tthe\tanswer\targument,\ti.e.\tcall\t\n",
            "apis.supervisor.complete_task(answer=<answer>)\n",
            ".\tMany\ttasks\tdo\tnot\trequire\tan\n",
            "answer,\tso\tin\tthose\tcases,\tjust\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            "\ti.e.\tdo\tnot\tpass\tany\targument.\n",
            "Using\tthese\tAPIs,\tgenerate\tcode\tto\tsolve\tthe\tactual\ttask:\n",
            "Embedding 115: [0.013573704287409782, -0.025124572217464447, 0.003014917718246579, -0.004155834671109915, 0.0025720023550093174, -0.00266780867241323, -0.014724663458764553, 0.02490035817027092, 0.022304728627204895, 0.02071724459528923] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 116: My\tname\tis:\t{{\tmain_user.first_name\t}}\t{{\tmain_user.last_name\t}}.\tMy\tpersonal\temail\tis\t{{\tmain_user.email\t}}\tand\tphone\tnumber\tis\t{{\n",
            "main_user.phone_number\t}}.\n",
            "Task:\t{{\tinput_str\t}}\n",
            "#\tTo\tget\ta\tlist\tof\tapps\tthat\tare\tavailable\tto\tyou.\n",
            "print\n",
            "(apis.api_docs.show_app_descriptions())\n",
            "#\tTo\tget\tthe\tlist\tof\tapis\tunder\tany\tapp\tlisted\tabove,\te.g.\tspotify\n",
            "print\n",
            "(apis.api_docs.show_api_descriptions(app_name\n",
            "=\n",
            "'spotify'\n",
            "))\n",
            "#\tTo\tget\tthe\tspecification\tof\ta\tparticular\tapi,\te.g.\tspotify\tapp's\tlogin\tapi\n",
            "print\n",
            "Embedding 116: [0.05582006648182869, -0.0037814960815012455, -0.027463283389806747, -0.009882427752017975, 0.057139329612255096, 0.008785487152636051, 0.03928111866116524, -0.03475366532802582, 0.045678846538066864, 0.020697088912129402] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 117: print\n",
            "(apis.api_docs.show_api_doc(app_name\n",
            "=\n",
            "'spotify'\n",
            ",\tapi_name\n",
            "=\n",
            "'login'\n",
            "))\n",
            "Figure 6: ICL-baseline Generator prompt on AppWorld\n",
            "15\n",
            "Embedding 117: [0.011925816535949707, -0.036636289209127426, -0.01776307262480259, -0.010694758966565132, -0.0028495027218014, 0.0026520313695073128, 0.06735929846763611, 0.0061431690119206905, 0.07778248935937881, 0.040796879678964615] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 118: I\tam\tyour\tsupervisor\tand\tyou\tare\ta\tsuper\tintelligent\tAI\tAssistant\twhose\tjob\tis\tto\tachieve\tmy\tday-to-day\ttasks\tcompletely\tautonomously.\n",
            "You\twill\tbe\tgiven\ta\tcheatsheet\tcontaining\trelevant\tstrategies,\tpatterns,\tand\texamples\tfrom\tsimilar\tproblems\tto\tapply\tand\tsolve\tthe\n",
            "current\ttask.\n",
            "To\tdo\tthis,\tyou\twill\tneed\tto\tinteract\twith\tapp/s\t(e.g.,\tspotify,\tvenmo\tetc)\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\tFor\tthis\tyou\twill\n",
            "undertake\ta\t\n",
            "multi-step\tconversation\n",
            "Embedding 118: [0.049856625497341156, 0.0007270588539540768, -0.038651373237371445, -0.035918671637773514, -0.039598800241947174, -0.035823576152324677, 0.07388662546873093, -0.03802846372127533, 0.04150271415710449, -0.032872993499040604] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 119: undertake\ta\t\n",
            "multi-step\tconversation\n",
            "\tusing\ta\tpython\tREPL\tenvironment.\tThat\tis,\tyou\twill\twrite\tthe\tpython\tcode\tand\tthe\tenvironment\twill\n",
            "execute\tit\tand\tshow\tyou\tthe\tresult,\tbased\ton\twhich,\tyou\twill\twrite\tpython\tcode\tfor\tthe\tnext\tstep\tand\tso\ton,\tuntil\tyou’ve\tachieved\tthe\tgoal.\n",
            "This\tenvironment\twill\tlet\tyou\tinteract\twith\tapp/s\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\n",
            "Here\tare\tthree\tkey\tAPIs\tthat\tyou\tneed\tto\tknow\tto\tget\tmore\tinformation\n",
            "Embedding 119: [0.0352204330265522, 0.022571852430701256, -0.012621763162314892, 0.01332895364612341, -0.01706560142338276, 0.0003677840286400169, -0.01885652355849743, -0.025058286264538765, 0.06627842038869858, -0.022453399375081062] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 120: Each\tcode\texecution\twill\tproduce\tan\toutput\tthat\tyou\tcan\tuse\tin\tsubsequent\tcalls.\tUsing\tthese\tAPIs,\tyou\tcan\tnow\tgenerate\tcode,\tthat\tI\twill\n",
            "execute,\tto\tsolve\tthe\ttask.\n",
            "CHEATSHEET:\t’’’\t{{\tcheat_sheet\t}}\t’’’\n",
            "1.\tANALYSIS\t&\tSTRATEGY\n",
            "Carefully\tanalyze\tboth\tthe\tquestion\tand\tcheatsheet\tbefore\tstarting\n",
            "Search\tfor\tand\tidentify\tany\tapplicable\tpatterns,\tstrategies,\tor\texamples\twithin\tthe\tcheatsheet\n",
            "Create\ta\tstructured\tapproach\tto\tsolving\tthe\tproblem\tat\thand\n",
            "Embedding 120: [-0.0138093875721097, -0.046696797013282776, -0.05779139697551727, 0.00019256383529864252, -0.048758696764707565, 0.012013654224574566, -0.05924808979034424, 0.011600552126765251, -0.014604142867028713, -0.0043814643286168575] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 121: Review\tand\tdocument\tany\tlimitations\tin\tthe\tprovided\treference\tmaterials\n",
            "2.\tSOLUTION\tDEVELOPMENT\n",
            "Present\tyour\tsolution\tusing\tclear,\tlogical\tsteps\tthat\tothers\tcan\tfollow\tand\treview\n",
            "Explain\tyour\treasoning\tand\tmethodology\tbefore\tpresenting\tfinal\tconclusions\n",
            "Provide\tdetailed\texplanations\tfor\teach\tstep\tof\tthe\tprocess\n",
            "Check\tand\tverify\tall\tassumptions\tand\tintermediate\tcalculations\n",
            "3.\tPROGRAMMING\tTASKS\n",
            "Embedding 121: [0.0059038796462118626, -0.0759861096739769, -0.017573872581124306, -0.009384346194565296, -0.057554494589567184, -0.032944466918706894, -0.028091292828321457, -0.047656212002038956, -0.03615367412567139, -0.04154842346906662] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 122: 3.\tPROGRAMMING\tTASKS\n",
            "When\tcoding\tis\trequired:\t-\tWrite\tclean,\tefficient\tPython\tcode\t-\tFollow\tthe\tstrict\tcode\tformatting\tand\texecution\tprotocol\t(always\tuse\tthe\n",
            "Python\tcode\tformatting\tblock;\tfurthermore,\tafter\tthe\tcode\tblock,\talways\texplicitly\trequest\texecution\tby\tappending:\t“EXECUTE\tCODE!”):\t\n",
            "python\t\t\t#\tYour\tcode\there\n",
            "\tEXECUTE\tCODE!\n",
            "All\trequired\timports\tand\tdependencies\tshould\tbe\tclearly\tdeclared\tat\tthe\ttop\tof\tyour\tcode\n",
            "Include\tclear\tinline\tcomments\tto\texplain\tany\tcomplex\tprogramming\tlogic\n",
            "Embedding 122: [0.023167651146650314, -0.059707965701818466, 0.00341331516392529, -0.02330864779651165, -0.013709423132240772, 0.0327279306948185, -0.02594112604856491, -0.03305833041667938, 0.013513260520994663, -0.023273201659321785] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 123: Perform\tresult\tvalidation\tafter\texecuting\tyour\tcode\n",
            "Apply\toptimization\ttechniques\tfrom\tthe\tcheatsheet\twhen\tapplicable\n",
            "The\tcode\tshould\tbe\tcompletely\tself-contained\twithout\texternal\tfile\tdependencies–it\tshould\tbe\tready\tto\tbe\texecuted\tright\taway\n",
            "Do\tnot\tinclude\tany\tplaceholders,\tsystem-specific\tpaths,\tor\thard-coded\tlocal\tpaths\n",
            "Feel\tfree\tto\tuse\tstandard\tand\twidely-used\tpip\tpackages\n",
            "Opt\tfor\talternative\tmethods\tif\terrors\tpersist\tduring\texecution\n",
            "Embedding 123: [-0.04356095939874649, -0.07458838820457458, -0.009937855415046215, -0.007364341989159584, 0.004099420737475157, -0.028109706938266754, -0.034659527242183685, 0.007781677879393101, 0.028027629479765892, 0.01006531622260809] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 124: Exclude\tlocal\tpaths\tand\tengine-specific\tsettings\t(e.g.,\tavoid\tconfigurations\tlike\n",
            "chess.engine.SimpleEngine.popen_uci(“/usr/bin/stockfish”))\n",
            "Let’s\tstart\twith\tthe\ttask\n",
            "[3\tshot\texample]\n",
            "Key\tinstructions\n",
            ":\t(1)\tMake\tsure\tto\tend\tcode\tblocks\twith\t```\tfollowed\tby\ta\tnewline().\n",
            "2.\t\n",
            "Remember\tyou\tcan\tuse\tthe\tvariables\tin\tyour\tcode\tin\tsubsequent\tcode\tblocks.\n",
            "3.\t\n",
            "Remember\tthat\tthe\temail\taddresses,\taccess\ttokens\tand\tvariables\t(e.g.\tspotify_password)\tin\tthe\texample\tabove\tare\tnot\tvalid\n",
            "anymore.\n",
            "4.\n",
            "Embedding 124: [0.01942402869462967, -0.07671570032835007, -0.019018907099962234, 0.0014165585162118077, 0.0023611055221408606, 0.0021508599165827036, 0.020903145894408226, -0.021012382581830025, -0.03846864029765129, 0.012267913669347763] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 125: anymore.\n",
            "4.\t\n",
            "You\tcan\tuse\tthe\t“supervisor”\tapp\tto\tget\tinformation\tabout\tmy\taccounts\tand\tuse\tthe\t“phone”\tapp\tto\tget\tinformation\tabout\tfriends\n",
            "and\tfamily.\n",
            "5.\t\n",
            "Always\tlook\tat\tAPI\tspecifications\t(using\t\n",
            "apis.api_docs.show_api_doc\n",
            ")\tbefore\tcalling\tan\tAPI.\n",
            "6.\t\n",
            "Write\tsmall\tchunks\tof\tcode\tand\tonly\tone\tchunk\tof\tcode\tin\tevery\tstep.\tMake\tsure\teverything\tis\tworking\tcorrectly\tbefore\tmaking\n",
            "any\tirreversible\tchange.\n",
            "7.\t\n",
            "Many\tAPIs\treturn\titems\tin\t“pages”.\tMake\tsure\tto\trun\tthrough\tall\tthe\tpages\tby\tlooping\tover\n",
            "Embedding 125: [0.05300213769078255, 0.03288986533880234, -0.023948032408952713, -0.0015117762377485633, -0.0010538367787376046, -0.0036150291562080383, 0.028679559007287025, 0.0008432774338871241, 0.05865698307752609, 0.014107010327279568] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 126: page_index\n",
            ".\n",
            "8.\t\n",
            "Once\tyou\thave\tcompleted\tthe\ttask,\tmake\tsure\tto\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            ".\tIf\tthe\ttask\tasked\tfor\tsome\tinformation,\n",
            "return\tit\tas\tthe\tanswer\targument,\ti.e.\tcall\t\n",
            "apis.supervisor.complete_task(answer=<answer>)\n",
            ".\tMany\ttasks\tdo\tnot\trequire\tan\n",
            "answer,\tso\tin\tthose\tcases,\tjust\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            "\ti.e.\tdo\tnot\tpass\tany\targument.\n",
            "Using\tthese\tAPIs,\tgenerate\tcode\tto\tsolve\tthe\tactual\ttask:\n",
            "Embedding 126: [0.013573704287409782, -0.025124572217464447, 0.003014917718246579, -0.004155834671109915, 0.0025720023550093174, -0.00266780867241323, -0.014724663458764553, 0.02490035817027092, 0.022304728627204895, 0.02071724459528923] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 127: My\tname\tis:\t{{\tmain_user.first_name\t}}\t{{\tmain_user.last_name\t}}.\tMy\tpersonal\temail\tis\t{{\tmain_user.email\t}}\tand\tphone\tnumber\tis\t{{\n",
            "main_user.phone_number\t}}.\tTask:\t{{\tinput_str\t}}\n",
            "#\tTo\tget\ta\tlist\tof\tapps\tthat\tare\tavailable\tto\tyou.\n",
            "print\n",
            "(apis.api_docs.show_app_descriptions())\n",
            "#\tTo\tget\tthe\tlist\tof\tapis\tunder\tany\tapp\tlisted\tabove,\te.g.\tspotify\n",
            "print\n",
            "(apis.api_docs.show_api_descriptions(app_name\n",
            "=\n",
            "'spotify'\n",
            "))\n",
            "#\tTo\tget\tthe\tspecification\tof\ta\tparticular\tapi,\te.g.\tspotify\tapp's\tlogin\tapi\n",
            "print\n",
            "Embedding 127: [0.05582006648182869, -0.0037814960815012455, -0.027463283389806747, -0.009882427752017975, 0.057139329612255096, 0.008785487152636051, 0.03928111866116524, -0.03475366532802582, 0.045678846538066864, 0.020697088912129402] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 128: print\n",
            "(apis.api_docs.show_api_doc(app_name\n",
            "=\n",
            "'spotify'\n",
            ",\tapi_name\n",
            "=\n",
            "'login'\n",
            "))\n",
            "Figure 7: Dynamic Cheatsheet Generator prompt on AppWorld\n",
            "16\n",
            "Embedding 128: [0.043524932116270065, -0.08688002824783325, -0.039171718060970306, -0.020632216706871986, 0.02712554857134819, 0.0017765630036592484, 0.013860104605555534, 0.015243034809827805, 0.09421037882566452, 0.021385429427027702] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 129: I\tam\tyour\tsupervisor\tand\tyou\tare\ta\tsuper\tintelligent\tAI\tAssistant\twhose\tjob\tis\tto\tachieve\tmy\tday-to-day\ttasks\tcompletely\tautonomously.\n",
            "To\tdo\tthis,\tyou\twill\tneed\tto\tinteract\twith\tapp/s\t(e.g.,\tspotify,\tvenmo\tetc)\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\tFor\tthis\tyou\twill\n",
            "undertake\ta\t\n",
            "multi-step\tconversation\n",
            "\tusing\ta\tpython\tREPL\tenvironment.\tThat\tis,\tyou\twill\twrite\tthe\tpython\tcode\tand\tthe\tenvironment\twill\n",
            "Embedding 129: [0.042802903801202774, 0.0134049067273736, -0.032998066395521164, -0.038965653628110886, -0.021795395761728287, -0.01133552473038435, 0.0723019614815712, -0.04373720660805702, 0.056961119174957275, -0.02084244415163994] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 130: execute\tit\tand\tshow\tyou\tthe\tresult,\tbased\ton\twhich,\tyou\twill\twrite\tpython\tcode\tfor\tthe\tnext\tstep\tand\tso\ton,\tuntil\tyou’ve\tachieved\tthe\tgoal.\n",
            "This\tenvironment\twill\tlet\tyou\tinteract\twith\tapp/s\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\n",
            "Here\tare\tthree\tkey\tAPIs\tthat\tyou\tneed\tto\tknow\tto\tget\tmore\tinformation:\n",
            "Each\tcode\texecution\twill\tproduce\tan\toutput\tthat\tyou\tcan\tuse\tin\tsubsequent\tcalls.\tUsing\tthese\tAPIs,\tyou\tcan\tnow\tgenerate\tcode,\tthat\tI\twill\n",
            "execute,\tto\tsolve\tthe\ttask.\n",
            "Key\tInstructions:\n",
            "1.\n",
            "Embedding 130: [0.017704535275697708, -0.015618634410202503, -0.04270535334944725, -0.0038066196721047163, -0.04368295148015022, 0.017340190708637238, -0.021072454750537872, -0.0031702101696282625, 0.03861900046467781, -0.03296221047639847] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 131: execute,\tto\tsolve\tthe\ttask.\n",
            "Key\tInstructions:\n",
            "1.\t\n",
            "Always\tend\tcode\tblocks\twith\t```\tfollowed\tby\ta\tnewline().\n",
            "2.\t\n",
            "Remember\tyou\tcan\tuse\tvariables\tin\tyour\tcode\tin\tsubsequent\tcode\tblocks.\n",
            "3.\t\n",
            "Email\taddresses,\taccess\ttokens\tand\tvariables\tfrom\tprevious\texamples\tare\tnot\tvalid\tanymore.\n",
            "4.\t\n",
            "Use\tthe\t“supervisor”\tapp\tto\tget\tinformation\tabout\tmy\taccounts\tand\tthe\t“phone”\tapp\tto\tget\tinformation\tabout\tfriends\tand\tfamily.\n",
            "5.\t\n",
            "Always\tlook\tat\tAPI\tspecifications\t(using\t\n",
            "apis.api_docs.show_api_doc\n",
            "Embedding 131: [0.052926547825336456, -0.0060340482741594315, -0.034881751984357834, -0.03127381205558777, 0.02263251505792141, -0.006849014665931463, 0.006695453077554703, -0.0046694353222846985, 0.04819253087043762, 0.025708356872200966] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 132: apis.api_docs.show_api_doc\n",
            ")\tbefore\tcalling\tan\tAPI.\n",
            "6.\t\n",
            "Write\tsmall\tchunks\tof\tcode\tand\tonly\tone\tchunk\tof\tcode\tin\tevery\tstep.\tMake\tsure\teverything\tis\tworking\tcorrectly\tbefore\tmaking\n",
            "any\tirreversible\tchanges.\n",
            "7.\t\n",
            "Many\tAPIs\treturn\titems\tin\t“pages”.\tMake\tsure\tto\trun\tthrough\tall\tthe\tpages\tby\tlooping\tover\t\n",
            "page_index\n",
            ".\n",
            "8.\t\n",
            "Once\tyou\thave\tcompleted\tthe\ttask,\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            ".\tIf\tthe\ttask\tasked\tfor\tinformation,\treturn\tit\tas\tthe\n",
            "answer\targument:\n",
            "Embedding 132: [0.031508270651102066, -0.020495640113949776, 0.0003763837448786944, -0.0066044083796441555, 0.016278458759188652, 0.011690794490277767, -0.023417117074131966, 0.0290889423340559, 0.044142697006464005, 0.01950933039188385] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 133: answer\targument:\t\n",
            "apis.supervisor.complete_task(answer=<answer>)\n",
            ".\tFor\ttasks\twithout\trequired\tanswers,\tjust\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            "\twithout\targuments.\n",
            "Domain-Specific\tStrategy\tfor\tBill\tSplitting\tTasks:\n",
            "\tWhen\tsplitting\tbills\tamong\troommates,\tremember\tto:\t-\tFirst\tidentify\troommates\n",
            "using\tphone\tapp’s\tsearch_contacts\twith\t“roommate”\trelationship\tquery\t-\tAccess\tbill\treceipts\tin\tfile\tsystem\tunder\n",
            "Embedding 133: [0.047942738980054855, 0.043084047734737396, -0.014407393522560596, -0.04429638758301735, -0.03124932013452053, -0.004835125990211964, 0.015509309247136116, -0.007608043495565653, 0.025973262265324593, -0.001643661642447114] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 134: “/home/[username]/bills/”\tdirectory\tstructure\t-\tCalculate\tequal\tshares\tby\tdividing\ttotal\tamount\tby\t(number\tof\troommates\t+\t1)\tincluding\n",
            "yourself\t-\tUse\tVenmo’s\tcreate_payment_request\tAPI\twith\troommates’\temail\taddresses\t-\tEnsure\tpayment\trequests\tare\tonly\tsent\tto\tactual\n",
            "roommates\t(not\tcoworkers\tor\tother\tcontacts)\t-\tVerify\tthat\tall\troommates\thave\tthe\tsame\thome\taddress\tin\ttheir\tcontact\tinformation\t-\tUse\n",
            "the\tdescription\t“I\tpaid\tfor\tcable\tbill.”\tfor\tpayment\trequests\n",
            "Embedding 134: [0.0340656153857708, 0.004014083184301853, -0.03282433748245239, -0.06003248691558838, 0.03148164227604866, 0.018926171585917473, 0.029576005414128304, -0.012084919027984142, 0.0209512896835804, -0.06781129539012909] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 135: Domain-Specific\tStrategy\tfor\tFile\tOrganization\tTasks:\n",
            "\tWhen\torganizing\tfiles\tbased\ton\tcreation\tdates,\tremember\tto:\t-\tFirst\tlogin\tto\n",
            "the\tfile\tsystem\tusing\tcredentials\tfrom\tsupervisor\t-\tUse\tshow_directory()\tto\tlist\tfiles\tand\tshow_file()\tto\tget\tfile\tmetadata\tincluding\n",
            "created_at\t-\tCreate\tdestination\tdirectories\tusing\tcreate_directory()\tbefore\tmoving\tfiles\t-\tUse\tmove_file()\tto\torganize\tfiles\twhile\n",
            "Embedding 135: [0.02836989238858223, 0.06749364733695984, -0.0007174061029218137, -0.011022951453924179, -0.026591239497065544, -0.0050884755328297615, 0.05556934326887131, 0.022922400385141373, -0.04114450514316559, -0.0005100881680846214] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 136: maintaining\toriginal\tfilenames\t-\tFiles\tcreated\tin\tspecific\tmonths\tshould\tbe\tmoved\tto\tcorresponding\tdestination\tdirectories\t(e.g.,\tMarch\t→\n",
            "Rome,\tApril\t→\tSantorini,\tothers\t→\tBerlin)\n",
            "Domain-Specific\tStrategy\tfor\tMusic\tPlaylist\tTasks:\n",
            "\tWhen\tcreating\tplaylists\tfor\tspecific\tdurations,\tremember\tto:\t-\tCalculate\ttotal\n",
            "duration\tneeded\t(e.g.,\t90\tminutes\t=\t5400\tseconds)\t-\tSearch\tfor\tappropriate\tsongs\tacross\tdifferent\tgenres\t(workout,\tenergetic,\trock,\tpop,\n",
            "Embedding 136: [0.03827172890305519, 0.030847778543829918, -0.04900319129228592, -0.015522719360888004, -0.01633327640593052, 0.009256230667233467, 0.03904812037944794, 0.0008343058289028704, -0.06158886477351189, 0.022648070007562637] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 137: dance)\t-\tUse\tshow_song()\tto\tget\tindividual\tsong\tdurations\t-\tAdd\tsongs\tto\tplaylist\tuntil\ttotal\tduration\trequirement\tis\tmet\t-\tUse\n",
            "play_music()\twith\tplaylist_id\tto\tstart\tplayback\n",
            "Domain-Specific\tStrategy\tfor\tFile\tCompression\tTasks:\n",
            "\tWhen\tcompressing\tvacation\tphoto\tdirectories,\tremember\tto:\t-\tCompress\teach\n",
            "vacation\tspot\tdirectory\tindividually\t-\tSave\tcompressed\tfiles\tin\tthe\tspecified\tdestination\tpath\tformat\t(e.g.,\t“~/photographs/vacations/\n",
            ".zip”)\n",
            "Embedding 137: [-0.018853995949029922, -0.004216604866087437, -0.042141083627939224, 0.030747482553124428, -0.010939443483948708, 0.006253912579268217, 0.014632534235715866, 0.010616017505526543, -0.04478568583726883, 0.03534390404820442] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 138: .zip”)\n",
            "-\tDelete\tthe\toriginal\tdirectories\tafter\tsuccessful\tcompression\t-\tVerify\tthat\tthe\tcompressed\tfiles\tare\tcreated\tin\tthe\tcorrect\tlocation\n",
            "Domain-Specific\tStrategy\tfor\tAlarm\tManagement\tTasks:\n",
            "\tWhen\tmodifying\tphone\talarms,\tremember\tto:\t-\tIdentify\tthe\tspecific\talarm\n",
            "by\tits\tlabel\t(e.g.,\t“Wake\tUp”)\t-\tCalculate\tnew\ttimes\taccurately\t(convert\tHH:MM\tto\tminutes\tfor\tarithmetic\toperations)\t-\tDisable\tall\tother\n",
            "Embedding 138: [0.016287382692098618, 0.007817658595740795, -0.02332448400557041, -0.02482355758547783, -0.04815785959362984, 0.050157830119132996, -0.00924826879054308, -0.02233228273689747, -0.09945470839738846, 0.0015732174506410956] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 139: enabled\talarms\texcept\tthe\tone\tbeing\tmodified\t-\tPreserve\tall\tother\talarm\tsettings\twhile\tmaking\tchanges\n",
            "Domain-Specific\tStrategy\tfor\tMessage\tManagement\tTasks:\n",
            "\tWhen\thandling\ttext/voice\tmessages,\tremember\tto:\t-\tUse\tsearch\n",
            "functions\tto\tfind\tspecific\tmessages\tby\tphone\tnumber\tor\tcontent\t-\tHandle\tpagination\tto\tensure\tall\trelevant\tmessages\tare\tprocessed\t-\n",
            "Delete\tmessages\tusing\ttheir\tspecific\tmessage\tIDs\t-\tVerify\tdeletion\tby\tchecking\tthat\tno\tmessages\tremain\n",
            "Let’s\tstart\twith\tthe\ttask:\n",
            "Embedding 139: [0.04276168718934059, -0.03308599814772606, -0.03122882731258869, -0.01896580122411251, -0.07438845187425613, 0.05625755712389946, 0.025451382622122765, -0.04075397551059723, -0.042149867862463, -0.026004042476415634] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 140: Let’s\tstart\twith\tthe\ttask:\n",
            "#\tTo\tget\ta\tlist\tof\tapps\tthat\tare\tavailable\tto\tyou.\n",
            "print\n",
            "(apis.api_docs.show_app_descriptions())\n",
            "#\tTo\tget\tthe\tlist\tof\tapis\tunder\tany\tapp\tlisted\tabove,\te.g.\tspotify\n",
            "print\n",
            "(apis.api_docs.show_api_descriptions(app_name\n",
            "=\n",
            "'spotify'\n",
            "))\n",
            "#\tTo\tget\tthe\tspecification\tof\ta\tparticular\tapi,\te.g.\tspotify\tapp's\tlogin\tapi\n",
            "print\n",
            "(apis.api_docs.show_api_doc(app_name\n",
            "=\n",
            "'spotify'\n",
            ",\tapi_name\n",
            "=\n",
            "'login'\n",
            "))\n",
            "Figure 8: GEPA prompt on AppWorld\n",
            "17\n",
            "Embedding 140: [0.05705865100026131, -0.012541106902062893, -0.03535255789756775, -0.004154999740421772, 0.02996731735765934, 0.029472677037119865, -0.014465421438217163, -0.009125133976340294, 0.10885664075613022, -0.02575371414422989] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 141: I\tam\tyour\tsupervisor\tand\tyou\tare\ta\tsuper\tintelligent\tAI\tAssistant\twhose\tjob\tis\tto\tachieve\tmy\tday-to-day\ttasks\tcompletely\tautonomously.\n",
            "To\tdo\tthis,\tyou\twill\tneed\tto\tinteract\twith\tapp/s\t(e.g.,\tspotify,\tvenmo\tetc)\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\tFor\tthis\tyou\twill\n",
            "undertake\ta\t\n",
            "multi-step\tconversation\n",
            "\tusing\ta\tpython\tREPL\tenvironment.\tThat\tis,\tyou\twill\twrite\tthe\tpython\tcode\tand\tthe\tenvironment\twill\n",
            "Embedding 141: [0.042802903801202774, 0.0134049067273736, -0.032998066395521164, -0.038965653628110886, -0.021795395761728287, -0.01133552473038435, 0.0723019614815712, -0.04373720660805702, 0.056961119174957275, -0.02084244415163994] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 142: execute\tit\tand\tshow\tyou\tthe\tresult,\tbased\ton\twhich,\tyou\twill\twrite\tpython\tcode\tfor\tthe\tnext\tstep\tand\tso\ton,\tuntil\tyou’ve\tachieved\tthe\tgoal.\n",
            "This\tenvironment\twill\tlet\tyou\tinteract\twith\tapp/s\tusing\ttheir\tassociated\tAPIs\ton\tmy\tbehalf.\n",
            "Here\tare\tthree\tkey\tAPIs\tthat\tyou\tneed\tto\tknow\tto\tget\tmore\tinformation\n",
            "Each\tcode\texecution\twill\tproduce\tan\toutput\tthat\tyou\tcan\tuse\tin\tsubsequent\tcalls.\tUsing\tthese\tAPIs,\tyou\tcan\tnow\tgenerate\tcode,\tthat\tI\twill\n",
            "execute,\tto\tsolve\tthe\ttask.\n",
            "Embedding 142: [0.015916120260953903, -0.009035559371113777, -0.036474164575338364, -0.010123207233846188, -0.04559895768761635, 0.020538803189992905, -0.02166363224387169, -0.008645008318126202, 0.040130894631147385, -0.02606886625289917] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 143: execute,\tto\tsolve\tthe\ttask.\n",
            "You\tare\talso\tprovided\twith\ta\tcurated\tcheatsheet\tof\tstrategies,\tAPI-specific\tinformation,\tcommon\tmistakes,\tand\tproven\tsolutions\tto\thelp\n",
            "you\tsolve\tthe\ttask\teffectively.\n",
            "ACE\tPlaybook\n",
            ":\t-\tRead\tthe\t\n",
            "Playbook\n",
            "\tfirst,\tthen\texecute\tthe\ttask\tby\texplicitly\tleveraging\teach\trelevant\tsection:\n",
            "PLAYBOOK_BEGIN\n",
            "{{\tplaybook\t}}\n",
            "PLAYBOOK_END\n",
            "Let’s\tstart\twith\tthe\ttask\n",
            "[3\tshot\texample]\n",
            "Key\tinstructions\n",
            ":\n",
            "1.\t\n",
            "Make\tsure\tto\tend\tcode\tblocks\twith\t```\tfollowed\tby\ta\tnewline().\n",
            "2.\n",
            "Embedding 143: [-0.01667213812470436, -0.094912588596344, -0.02198232151567936, -0.013488859869539738, -0.04829324409365654, 0.02081901580095291, 0.006364487577229738, 0.008477647788822651, 0.026081476360559464, -0.011777998879551888] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 144: 2.\t\n",
            "Remember\tyou\tcan\tuse\tthe\tvariables\tin\tyour\tcode\tin\tsubsequent\tcode\tblocks.\n",
            "3.\t\n",
            "Remember\tthat\tthe\temail\taddresses,\taccess\ttokens\tand\tvariables\t(e.g.\tspotify_password)\tin\tthe\texample\tabove\tare\tnot\tvalid\n",
            "anymore.\n",
            "4.\t\n",
            "You\tcan\tuse\tthe\t“supervisor”\tapp\tto\tget\tinformation\tabout\tmy\taccounts\tand\tuse\tthe\t“phone”\tapp\tto\tget\tinformation\tabout\tfriends\n",
            "and\tfamily.\n",
            "5.\t\n",
            "Always\tlook\tat\tAPI\tspecifications\t(using\t\n",
            "apis.api_docs.show_api_doc\n",
            ")\tbefore\tcalling\tan\tAPI.\n",
            "6.\n",
            "Embedding 144: [0.038178469985723495, -0.011874957010149956, -0.034072794020175934, -0.016948062926530838, 0.023317979648709297, -0.02107868157327175, 0.07692550867795944, -0.032274577766656876, 0.03451072424650192, 0.037042420357465744] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 145: )\tbefore\tcalling\tan\tAPI.\n",
            "6.\t\n",
            "Write\tsmall\tchunks\tof\tcode\tand\tonly\tone\tchunk\tof\tcode\tin\tevery\tstep.\tMake\tsure\teverything\tis\tworking\tcorrectly\tbefore\tmaking\n",
            "any\tirreversible\tchange.\n",
            "7.\t\n",
            "Many\tAPIs\treturn\titems\tin\t“pages”.\tMake\tsure\tto\trun\tthrough\tall\tthe\tpages\tby\tlooping\tover\t\n",
            "page_index\n",
            ".\n",
            "8.\t\n",
            "Once\tyou\thave\tcompleted\tthe\ttask,\tmake\tsure\tto\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            ".\tIf\tthe\ttask\tasked\tfor\tsome\tinformation,\n",
            "return\tit\tas\tthe\tanswer\targument,\ti.e.\tcall\n",
            "Embedding 145: [0.032246336340904236, -0.0134592829272151, 0.011855008080601692, -0.01559214573353529, 0.017228269949555397, 0.00661383057013154, -0.016476456075906754, 0.011091421358287334, 0.040987856686115265, 0.014425190165638924] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 146: return\tit\tas\tthe\tanswer\targument,\ti.e.\tcall\t\n",
            "apis.supervisor.complete_task(answer=<answer>)\n",
            ".\tMany\ttasks\tdo\tnot\trequire\tan\n",
            "answer,\tso\tin\tthose\tcases,\tjust\tcall\t\n",
            "apis.supervisor.complete_task()\n",
            "\ti.e.\tdo\tnot\tpass\tany\targument.\n",
            "9.\t\n",
            "Treat\tthe\tcheatsheet\tas\ta\ttool.\tUse\tonly\tthe\tparts\tthat\tare\trelevant\tand\tapplicable\tto\tyour\tspecific\tsituation\tand\ttask\tcontext,\n",
            "otherwise\tuse\tyour\town\tjudgement.\n",
            "Using\tthese\tAPIs\tand\tcheatsheet,\tgenerate\tcode\tto\tsolve\tthe\tactual\ttask:\n",
            "Embedding 146: [0.0238161813467741, -0.04547787830233574, -0.011363058350980282, -0.011321761645376682, -0.017176557332277298, -0.023265259340405464, -0.04977282136678696, 0.023745808750391006, 0.018920261412858963, 0.011060457676649094] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 147: My\tname\tis:\t{{\tmain_user.first_name\t}}\t{{\tmain_user.last_name\t}}.\tMy\tpersonal\temail\tis\t{{\tmain_user.email\t}}\tand\tphone\tnumber\tis\t{{\n",
            "main_user.phone_number\t}}.\tTask:\t{{\tinput_str\t}}\n",
            "#\tTo\tget\ta\tlist\tof\tapps\tthat\tare\tavailable\tto\tyou.\n",
            "print\n",
            "(apis.api_docs.show_app_descriptions())\n",
            "#\tTo\tget\tthe\tlist\tof\tapis\tunder\tany\tapp\tlisted\tabove,\te.g.\tspotify\n",
            "print\n",
            "(apis.api_docs.show_api_descriptions(app_name\n",
            "=\n",
            "'spotify'\n",
            "))\n",
            "#\tTo\tget\tthe\tspecification\tof\ta\tparticular\tapi,\te.g.\tspotify\tapp's\tlogin\tapi\n",
            "print\n",
            "Embedding 147: [0.05582006648182869, -0.0037814960815012455, -0.027463283389806747, -0.009882427752017975, 0.057139329612255096, 0.008785487152636051, 0.03928111866116524, -0.03475366532802582, 0.045678846538066864, 0.020697088912129402] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 148: print\n",
            "(apis.api_docs.show_api_doc(app_name\n",
            "=\n",
            "'spotify'\n",
            ",\tapi_name\n",
            "=\n",
            "'login'\n",
            "))\n",
            "Figure 9: ACE Generator prompt on AppWorld\n",
            "18\n",
            "Embedding 148: [0.02809334732592106, -0.05436713993549347, -0.032554250210523605, -0.022853152826428413, 0.04461776465177536, 0.010617872700095177, 0.038667093962430954, 0.0037596554029732943, 0.08621323108673096, 0.04123180732131004] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 149: You\tare\tan\texpert\tAppWorld\tcoding\tagent\tand\teducator.\tYour\tjob\tis\tto\tdiagnose\tthe\tcurrent\ttrajectory:\tidentify\twhat\twent\twrong\t(or\tcould\tbe\tbetter),\tgrounded\tin\texecutionfeedback,\tAPI\tusage,\tunit\ttest\treport,\tand\tground\ttruth\twhen\tapplicable.\n",
            "Embedding 149: [0.07249297201633453, 0.042483240365982056, -0.02253188006579876, -0.022062307223677635, 0.0016462111379951239, 0.002797378459945321, -0.014154897071421146, -0.012377174571156502, 0.020033594220876694, -0.029204025864601135] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 150: Instructions:\t-\tCarefully\tanalyze\tthe\tmodel’s\treasoning\ttrace\tto\tidentify\twhere\tit\twent\twrong\t-\tTake\tthe\tenvironment\tfeedback\tinto\taccount,\tcomparing\tthe\tpredictedanswer\twith\tthe\tground\ttruth\tto\tunderstand\tthe\tgap\t-\tIdentify\tspecific\tconceptual\terrors,\tcalculation\tmistakes,\tor\tmisapplied\tstrategies\t-\tProvide\tactionable\tinsights\tthatcould\thelp\tthe\tmodel\tavoid\tthis\tmistake\tin\tthe\tfuture\t-\tIdentify\troot\tcauses:\twrong\tsource\tof\ttruth,\tbad\tfilters\t(timeframe/direction/identity),\tformatting\tissues,\to\n",
            "Embedding 150: [0.015626681968569756, -0.007832028903067112, 0.02288939617574215, 0.004196230322122574, -0.010806123726069927, 0.034581251442432404, -0.061424512416124344, -0.0031918359454721212, -0.0073468382470309734, -0.01629522070288658] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 151: imeframe/direction/identity),\tformatting\tissues,\tor\tmissingauthentication\tand\thow\tto\tcorrect\tthem.\t-\tProvide\tconcrete,\tstep-by-step\tcorrections\tthe\tmodel\tshould\ttake\tin\tthis\ttask.\t-\tBe\tspecific\tabout\twhat\tthe\tmodel\tshould\thave\tdonedifferently\t-\tYou\twill\treceive\tbulletpoints\tthat\tare\tpart\tof\tplaybook\tthat’s\tused\tby\tthe\tgenerator\tto\tanswer\tthe\tquestion.\t-\tYou\tneed\tto\tanalyze\tthese\tbulletpoints,\tand\tgive\tthetag\tfor\teach\tbulletpoint,\ttag\tcan\tbe\t[‘helpful’,\t‘harmful’,\t‘neutral’]\t(for\tthe\tgenerator\tto\n",
            "Embedding 151: [-0.01213446818292141, -0.005112722981721163, -0.017852744087576866, 0.020483557134866714, -0.02979501150548458, 0.019058626145124435, 0.008324380964040756, -0.022008126601576805, -0.016340212896466255, -0.051106590777635574] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 152: pful’,\t‘harmful’,\t‘neutral’]\t(for\tthe\tgenerator\tto\tgenerate\tthe\tcorrect\tanswer)\t-\tExplicitly\tcurate\tfrom\tthe\tenvironment\tfeedback\ttheoutput\tformat/schema\tof\tAPIs\tused\twhen\tunclear\tor\tmismatched\twith\texpectations\t(e.g.,\tapis.blah.show_contents()\treturns\ta\tlist\tof\tcontent_ids\t(strings),\tnot\tcontentobjects)\n",
            "Embedding 152: [0.03298928961157799, -0.007310067769140005, 0.0013610883615911007, -0.02509181573987007, -0.012065858580172062, 0.0013034238945692778, -0.005315111950039864, 0.06198341026902199, 0.03277820348739624, -0.005414258688688278] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 153: Inputs:\n",
            "Ground\ttruth\tcode\t(reference,\tknown-correct):\n",
            "GROUND_TRUTH_CODE_START\n",
            "{{ground_truth_code}}\n",
            "GROUND_TRUTH_CODE_END\n",
            "Test\treport\t(unit\ttests\tresult\tfor\tthe\ttask\tafter\tthe\tgenerated\tcode\twas\trun):\n",
            "TEST_REPORT_START\n",
            "{{unit_test_results}}\n",
            "TEST_REPORT_END\n",
            "ACE\tplaybook\t(playbook\tthat’s\tused\tby\tmodel\tfor\tcode\tgeneration):\n",
            "PLAYBOOK_START\n",
            "{{playbook}}\n",
            "PLAYBOOK_END\n",
            "Examples:\n",
            "Example\t1:\n",
            "Embedding 153: [-0.03365431725978851, -0.012955511920154095, -0.016001759096980095, -0.005473435390740633, -0.02657761424779892, -0.014712915755808353, 0.01787632517516613, 0.011901712976396084, -0.005628161132335663, -0.00789076928049326] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 154: {{playbook}}\n",
            "PLAYBOOK_END\n",
            "Examples:\n",
            "Example\t1:\n",
            "Ground\tTruth\tCode:\t[Code\tthat\tuses\tapis.phone.search_contacts()\tto\tfind\troommates,\tthen\tfilters\tVenmo\ttransactions]\n",
            "Generated\tCode:\t[Code\tthat\ttries\tto\tidentify\troommates\tby\tparsing\tVenmo\ttransaction\tdescriptions\tusing\tkeywords\tlike\t“rent”,\t“utilities”]\n",
            "Execution\tError:\tAssertionError:\tExpected\t1068.0\tbut\tgot\t79.0\n",
            "Test\tReport:\tFAILED\t-\tWrong\ttotal\tamount\tcalculated\tdue\tto\tincorrect\troommate\tidentification\n",
            "Response:\n",
            "{{\n",
            "Embedding 154: [0.030413903295993805, 0.034959789365530014, -0.03280569240450859, 0.005703357048332691, 0.025353627279400826, -0.03279614448547363, 0.01490972563624382, 0.024008115753531456, 0.03608730062842369, -0.02342202141880989] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 155: Response:\n",
            "{{\n",
            "“reasoning”:\t“The\tgenerated\tcode\tattempted\tto\tidentify\troommates\tby\tparsing\tVenmo\ttransaction\tdescriptions\trather\tthan\tusing\tthe\tauthoritative\tPhone\tapp\tcontacts.\tThisled\tto\tmissing\tmost\troommate\ttransactions\tand\tcalculating\tan\tincorrect\ttotal\tof\t79.0\tinstead\tof\t1068.0.”,\n",
            "“error_identification”:\t“The\tagent\tused\tunreliable\theuristics\t(keyword\tmatching\tin\ttransaction\tdescriptions)\tto\tidentify\troommates\tinstead\tof\tthe\tcorrect\tAPI\t(Phonecontacts).”,\n",
            "Embedding 155: [0.045282669365406036, 0.00946166180074215, -0.021502098068594933, -0.023672377690672874, 0.0033326358534395695, 0.006457903888076544, 0.02435014210641384, 0.004629433620721102, 0.004463304299861193, -0.039560310542583466] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 156: “root_cause_analysis”:\t“The\tagent\tmisunderstood\tthe\tdata\tarchitecture\t-\tit\tassumed\ttransaction\tdescriptions\tcontained\treliable\trelationship\tinformation,\twhen\tthe\tPhoneapp\tis\tthe\tauthoritative\tsource\tfor\tcontact\trelationships.”,\n",
            "“correct_approach”:\t“First\tauthenticate\twith\tPhone\tapp,\tuse\tapis.phone.search_contacts()\tto\tidentify\tcontacts\twith\t‘roommate’\trelationship,\tthen\tfilter\tVenmo\ttransactionsby\tthose\tspecific\tcontact\temails/phone\tnumbers.”,\n",
            "Embedding 156: [0.06796901673078537, 0.012359621934592724, -0.020068233832716942, -0.025816215202212334, 0.02580728381872177, -0.016481511294841766, 0.027101920917630196, 0.009629335254430771, 0.026873024180531502, -0.021747097373008728] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 157: “key_insight”:\t“Always\tresolve\tidentities\tfrom\tthe\tcorrect\tsource\tapp\t-\tPhone\tapp\tfor\trelationships,\tnever\trely\ton\ttransaction\tdescriptions\tor\tother\tindirect\theuristics\twhichare\tunreliable.”\n",
            "}}\n",
            "Example\t2:\n",
            "Ground\tTruth\tCode:\t[Code\tthat\tuses\tproper\twhile\tTrue\tpagination\tloop\tto\tget\tall\tSpotify\tplaylists]\n",
            "Generated\tCode:\t[Code\tthat\tuses\tfor\ti\tin\trange(10)\tto\tpaginate\tthrough\tplaylists]\n",
            "Execution\tError:\tNone\t(code\tran\tsuccessfully)\n",
            "Embedding 157: [0.07153645157814026, 0.027911921963095665, -0.02137448638677597, -0.018243171274662018, -0.00464031333103776, -0.02043064311146736, 0.03621910512447357, -0.02612481079995632, 0.017199350520968437, 0.02169518731534481] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 158: Execution\tError:\tNone\t(code\tran\tsuccessfully)\n",
            "Test\tReport:\tFAILED\t-\tExpected\t23\tplaylists\tbut\tgot\t10\tdue\tto\tincomplete\tpagination\n",
            "Response:\n",
            "{{\n",
            "“reasoning”:\t“The\tgenerated\tcode\tused\ta\tfixed\trange\tloop\t(range(10))\tfor\tpagination\tinstead\tof\tproperly\titerating\tuntil\tno\tmore\tresults\tare\treturned.\tThis\tcaused\tthe\tagentto\tonly\tcollect\tthe\tfirst\t10\tpages\tof\tplaylists,\tmissing\t13\tadditional\tplaylists\tthat\texisted\ton\tlater\tpages.”,\n",
            "Embedding 158: [0.012750730849802494, -0.019003288820385933, -0.03741908445954323, -0.059082482010126114, 0.046615276485681534, 0.00547820283100009, 0.012679209001362324, 0.012381913140416145, 0.04601549729704857, 0.037616271525621414] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 159: “error_identification”:\t“The\tpagination\tlogic\tused\tan\tarbitrary\tfixed\tlimit\tinstead\tof\tcontinuing\tuntil\tall\tpages\twere\tprocessed.”,\n",
            "“root_cause_analysis”:\t“The\tagent\tused\ta\tcautious\tapproach\twith\ta\tfixed\tupper\tbound\tto\tavoid\tinfinite\tloops,\tbut\tthis\tprevented\tcomplete\tdata\tcollection\twhen\tthe\tactualdata\texceeded\tthe\tarbitrary\tlimit.”,\n",
            "Embedding 159: [0.0100089805200696, -0.009197293780744076, 0.001974029466509819, -0.01117270439863205, 0.008636659942567348, 0.047565020620822906, -0.05045297369360924, 0.04465096443891525, -0.03109642304480076, 0.03440362587571144] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 160: “correct_approach”:\t“Use\twhile\tTrue\tloop\twith\tproper\tbreak\tcondition:\tcontinue\tcalling\tthe\tAPI\twith\tincrementing\tpage_index\tuntil\tthe\tAPI\treturns\tempty\tresults\tor\tnull,then\tbreak.”,\n",
            "“key_insight”:\t“For\tpagination,\talways\tuse\twhile\tTrue\tloop\tinstead\tof\tfixed\trange\titerations\tto\tensure\tcomplete\tdata\tcollection\tacross\tall\tavailable\tpages.”\n",
            "}}\n",
            "Embedding 160: [0.01610936038196087, 0.027166400104761124, -0.012637421488761902, -0.005954172927886248, 0.008917808532714844, 0.013558855280280113, -0.05915435403585434, 0.017978284507989883, 0.01697644032537937, 0.029801441356539726] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 161: }}\n",
            "Outputs:\tYour\toutput\tshould\tbe\ta\tjson\tobject,\twhich\tcontains\tthe\tfollowing\tfields\t-\treasoning:\tyour\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\tdetailed\tanalysis\tandcalculations\t-\terror_identification:\twhat\tspecifically\twent\twrong\tin\tthe\treasoning?\t-\troot_cause_analysis:\twhy\tdid\tthis\terror\toccur?\tWhat\tconcept\twas\tmisunderstood?\t-correct_approach:\twhat\tshould\tthe\tmodel\thave\tdone\tinstead?\t-\tkey_insight:\twhat\tstrategy,\tformula,\tor\tprinciple\tshould\tbe\tremembered\tto\tavoid\tthis\terror?\n",
            "Embedding 161: [-0.013819621875882149, 0.011735186912119389, -0.0002224882919108495, -0.0017157236579805613, 0.00908118486404419, -0.004070101771503687, -0.04466741532087326, 0.0013058350887149572, -0.040953874588012695, -0.05847292020916939] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 162: Answer\tin\tthis\texact\tJSON\tformat:\n",
            "{{\n",
            "“reasoning”:\t“[Your\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\tdetailed\tanalysis\tand\tcalculations]”,\n",
            "“error_identification”:\t“[What\tspecifically\twent\twrong\tin\tthe\treasoning?]”,\n",
            "“root_cause_analysis”:\t“[Why\tdid\tthis\terror\toccur?\tWhat\tconcept\twas\tmisunderstood?]”,\n",
            "“correct_approach”:\t“[What\tshould\tthe\tmodel\thave\tdone\tinstead?]”,\n",
            "“key_insight”:\t“[What\tstrategy,\tformula,\tor\tprinciple\tshould\tbe\tremembered\tto\tavoid\tthis\terror?]”,\n",
            "}}\n",
            "Embedding 162: [-0.0005342274089343846, 0.04460589587688446, 0.010726588778197765, 0.03495143726468086, -0.0004838047898374498, -0.010025732219219208, -0.04779047891497612, -0.0069600241258740425, -0.04021335393190384, -0.05691378191113472] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 163: }}\n",
            "[FULL\tAGENT-ENVIRONMENT\tTRAJECTORY\tATTACHED\tHERE]\n",
            "Figure 10: ACE Reflector prompt on AppWorld\n",
            "19\n",
            "Embedding 163: [0.025355979800224304, -0.08906135708093643, -0.015003513544797897, -0.03283388912677765, -0.008712291717529297, -0.040704090148210526, 0.05474903807044029, 0.006210716441273689, -0.006937771569937468, 0.03171877562999725] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 164: You\tare\ta\tmaster\tcurator\tof\tknowledge.\tYour\tjob\tis\tto\tidentify\twhat\tnew\tinsights\tshould\tbe\tadded\tto\tan\texisting\tplaybook\tbased\ton\ta\treflection\tfrom\ta\tprevious\tattempt.\n",
            "Context:\n",
            "\t-\tThe\tplaybook\tyou\tcreated\twill\tbe\tused\tto\thelp\tanswering\tsimilar\tquestions.\t-\tThe\treflection\tis\tgenerated\tusing\tground\ttruth\tanswers\tthat\twill\tNOT\tbe\tavailable\n",
            "when\tthe\tplaybook\tis\tbeing\tused.\tSo\tyou\tneed\tto\tcome\tup\twith\tcontent\tthat\tcan\taid\tthe\tplaybook\tuser\tto\tcreate\tpredictions\tthat\tlikely\talign\twith\tground\ttruth.\n",
            "Embedding 164: [0.06519706547260284, 0.02260998636484146, -0.014339967630803585, 0.00507835578173399, -0.05190308019518852, -0.022076353430747986, -0.040808700025081635, -0.009595829993486404, -0.021269729360938072, -0.027656465768814087] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 165: Instructions:\n",
            "\t-\tReview\tthe\texisting\tplaybook\tand\tthe\treflection\tfrom\tthe\tprevious\tattempt\t-\tIdentify\tONLY\tthe\tNEW\tinsights,\tstrategies,\tor\tmistakes\tthat\tare\tMISSING\tfrom\n",
            "the\tcurrent\tplaybook\t-\tAvoid\tredundancy\t-\tif\tsimilar\tadvice\talready\texists,\tonly\tadd\tnew\tcontent\tthat\tis\ta\tperfect\tcomplement\tto\tthe\texisting\tplaybook\t-\tDo\tNOT\tregenerate\n",
            "Embedding 165: [0.03594721108675003, -0.0418921634554863, -1.8838822143152356e-05, -0.0229561235755682, -0.07076969742774963, -0.019781235605478287, -0.11111939698457718, 0.011718536727130413, -0.02929561212658882, -0.019626419991254807] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 166: the\tentire\tplaybook\t-\tonly\tprovide\tthe\tadditions\tneeded\t-\tFocus\ton\tquality\tover\tquantity\t-\ta\tfocused,\twell-organized\tplaybook\tis\tbetter\tthan\tan\texhaustive\tone\t-\tFormat\tyour\n",
            "response\tas\ta\tPURE\tJSON\tobject\twith\tspecific\tsections\t-\tFor\tany\toperation\tif\tno\tnew\tcontent\tto\tadd,\treturn\tan\tempty\tlist\tfor\tthe\toperations\tfield\t-\tBe\tconcise\tand\tspecific\t-\n",
            "Embedding 166: [0.029640264809131622, 0.037947800010442734, 0.009179302491247654, 0.0030720906797796488, 0.0005905631114728749, -0.022902950644493103, -0.06522263586521149, 0.021727629005908966, -0.01476007979363203, -0.001807698397897184] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 167: each\taddition\tshould\tbe\tactionable\t-\tFor\tcoding\ttasks,\texplicitly\tcurate\tfrom\tthe\treflections\tthe\toutput\tformat/schema\tof\tAPIs\tused\twhen\tunclear\tor\tmismatched\twith\n",
            "expectations\t(e.g.,\t\n",
            "apis.blah.show_contents()\n",
            "\treturns\ta\tlist\tof\tcontent_ids\t(strings),\tnot\tcontent\tobjects)\n",
            "Task\tContext\t(the\tactual\ttask\tinstruction):\n",
            "{question_context}\n",
            "Current\tPlaybook:\n",
            "{current_playbook}\n",
            "Current\tGenerated\tAttempt\t(latest\tattempt,\twith\treasoning\tand\tplanning):\n",
            "{final_generated_code}\n",
            "Embedding 167: [0.030672691762447357, -0.020960401743650436, -0.020833102986216545, 0.006474039983004332, -0.002417320152744651, -0.009588065557181835, 3.8766349462093785e-05, -0.03557826206088066, 0.0015975934220477939, 0.006668920628726482] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 168: {final_generated_code}\n",
            "Current\tReflections\t(principles\tand\tstrategies\tthat\thelped\tto\tachieve\tcurrent\ttask):\n",
            "{guidebook}\n",
            "Examples:\n",
            "Example\t1:\n",
            "Task\tContext:\t“Find\tmoney\tsent\tto\troommates\tsince\tJan\t1\tthis\tyear”\n",
            "Current\tPlaybook:\t[Basic\tAPI\tusage\tguidelines]\n",
            "Generated\tAttempt:\t[Code\tthat\tfailed\tbecause\tit\tused\ttransaction\tdescriptions\tto\tidentify\troommates\tinstead\tof\tPhone\tcontacts]\n",
            "Embedding 168: [0.03624685853719711, 0.09922777861356735, -0.03992221876978874, 0.0179145447909832, -0.04760186746716499, -0.013103228993713856, 0.013515511527657509, 0.034763582050800323, 0.016439709812402725, -0.01377870049327612] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 169: Reflections:\t“The\tagent\tfailed\tbecause\tit\ttried\tto\tidentify\troommates\tby\tparsing\tVenmo\ttransaction\tdescriptions\tinstead\tof\tusing\tthe\tPhone\tapp’s\tcontact\trelationships.\tThis\n",
            "led\tto\tincorrect\tidentification\tand\twrong\tresults.”\n",
            "Response:\n",
            "Example\t2:\n",
            "Task\tContext:\t“Count\tall\tplaylists\tin\tSpotify”\n",
            "Current\tPlaybook:\t[Basic\tauthentication\tand\tAPI\tcalling\tguidelines]\n",
            "Generated\tAttempt:\t[Code\tthat\tused\tfor\ti\tin\trange(10)\tloop\tand\tmissed\tplaylists\ton\tlater\tpages]\n",
            "Embedding 169: [0.03976888209581375, -0.026769718155264854, -0.029040426015853882, -0.048309843987226486, -0.0003356700181029737, -0.015443946234881878, 0.07043391466140747, -0.03346407413482666, 0.0177167821675539, -0.008012809790670872] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 170: Reflections:\t“The\tagent\tused\ta\tfixed\trange\tloop\tfor\tpagination\tinstead\tof\tproperly\titerating\tthrough\tall\tpages\tuntil\tno\tmore\tresults\tare\treturned.\tThis\tcaused\tincomplete\n",
            "data\tcollection.”\n",
            "Response:\n",
            "Your\tTask:\n",
            "\tOutput\tONLY\ta\tvalid\tJSON\tobject\twith\tthese\texact\tfields:\t-\treasoning:\tyour\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\tdetailed\tanalysis\tand\tcalculations\t-\n",
            "Embedding 170: [0.038591209799051285, 0.0382244698703289, -0.00808593351393938, -0.0034398657735437155, 0.016249576583504677, -0.0030461905989795923, -0.04553912207484245, 0.03188589587807655, -0.04911307618021965, -0.009528026916086674] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 171: operations:\ta\tlist\tof\toperations\tto\tbe\tperformed\ton\tthe\tplaybook\t-\ttype:\tthe\ttype\tof\toperation\tto\tbe\tperformed\t-\tsection:\tthe\tsection\tto\tadd\tthe\tbullet\tto\t-\tcontent:\tthe\tnew\n",
            "content\tof\tthe\tbullet\n",
            "Available\tOperations:\n",
            "\t1.\tADD:\tCreate\tnew\tbullet\tpoints\twith\tfresh\tIDs\t-\tsection:\tthe\tsection\tto\tadd\tthe\tnew\tbullet\tto\t-\tcontent:\tthe\tnew\tcontent\tof\tthe\tbullet.\tNote:\tno\tneed\n",
            "to\tinclude\tthe\tbullet_id\tin\tthe\tcontent\tlike\t‘[ctx-00263]\thelpful=1\tharmful=0\t::’,\tthe\tbullet_id\twill\tbe\tadded\tby\tthe\tsystem.\n",
            "Embedding 171: [0.010031353682279587, -0.1192096620798111, 0.0005878483643755317, 0.01092861220240593, -0.02661760337650776, 0.018087156116962433, 0.03266862779855728, -0.01792505756020546, -0.05754571408033371, -0.030988652259111404] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 172: RESPONSE\tFORMAT\t-\tOutput\tONLY\tthis\tJSON\tstructure\t(no\tmarkdown,\tno\tcode\tblocks):\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "\t\n",
            "\"The\treflection\tshows\ta\tcritical\terror\twhere\tthe\tagent\tused\tunreliable\theuristics\t(transaction\tdescriptions)\tinstead\tof\tthe\n",
            "\t\n",
            "authoritative\tsource\t(Phone\tapp\tcontacts)\tto\tidentify\trelationships.\tThis\tis\ta\tfundamental\tprinciple\tthat\tshould\tbe\tcaptured\tin\tthe\n",
            "\t\n",
            "playbook\tto\tprevent\tsimilar\tfailures\tin\tidentity\tresolution\ttasks.\"\n",
            ",\n",
            "\t\t\n",
            "\"operations\"\n",
            ":\n",
            "\t\n",
            "[\n",
            "\t\t\t\t\n",
            "{\n",
            "\t\t\t\t\t\t\n",
            "\"type\"\n",
            ":\n",
            "\t\n",
            "\"ADD\"\n",
            ",\n",
            "Embedding 172: [0.023252995684742928, 0.020053325220942497, -0.002393621252849698, 0.036054473370313644, 0.025657638907432556, -0.02368089184165001, -0.046282488852739334, 0.030639393255114555, 0.0005863321712240577, -0.026765599846839905] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 173: :\n",
            "\t\n",
            "[\n",
            "\t\t\t\t\n",
            "{\n",
            "\t\t\t\t\t\t\n",
            "\"type\"\n",
            ":\n",
            "\t\n",
            "\"ADD\"\n",
            ",\n",
            "\t\t\t\t\t\t\n",
            "\"section\"\n",
            ":\n",
            "\t\n",
            "\"strategies_and_hard_rules\"\n",
            ",\n",
            "\t\n",
            "\t\t\t\t\t\t\n",
            "\"content\"\n",
            ":\n",
            "\t\n",
            "\"Always\tresolve\tidentities\tfrom\tthe\tcorrect\tsource\tapp\n",
            "\\n\n",
            "-\tWhen\tyou\tneed\tto\tidentify\trelationships\t(roommates,\tcontacts,\tetc.),\n",
            "\t\n",
            "always\tuse\tthe\tPhone\tapp's\tcontact,\tand\tnever\ttry\tother\theuristics\tfrom\ttransaction\tdescriptions,\tname\tpatterns,\tor\tother\tindirect\n",
            "\t\n",
            "sources.\tThese\theuristics\tare\tunreliable\tand\twill\tcause\tincorrect\tresults.\"\n",
            "\t\t\t\t\n",
            "}\n",
            "\t\t\n",
            "]\n",
            "}\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "Embedding 173: [0.0694107711315155, -0.011636356823146343, -0.02893788181245327, -0.015501161105930805, -0.02924743853509426, -0.017690908163785934, 0.03281282261013985, -0.02701161429286003, 0.024132732301950455, -0.007605166174471378] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 174: }\n",
            "\t\t\n",
            "]\n",
            "}\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "\t\n",
            "\"The\treflection\tidentifies\ta\tpagination\thandling\terror\twhere\tthe\tagent\tused\tan\tarbitrary\tfixed\trange\tinstead\tof\tproper\tpagination\n",
            "\t\n",
            "logic.\tThis\tis\ta\tcommon\tAPI\tusage\tpattern\tthat\tshould\tbe\texplicitly\tdocumented\tto\tensure\tcomplete\tdata\tretrieval.\"\n",
            ",\n",
            "\t\t\n",
            "\"operations\"\n",
            ":\n",
            "\t\n",
            "[\n",
            "\t\t\t\t\n",
            "{\n",
            "\t\t\t\t\t\t\n",
            "\"type\"\n",
            ":\n",
            "\t\n",
            "\"ADD\"\n",
            ",\n",
            "\t\t\t\t\t\t\n",
            "\"section\"\n",
            ":\n",
            "\t\n",
            "\"apis_to_use_for_specific_information\"\n",
            ",\n",
            "\t\t\t\t\t\t\n",
            "\"content\"\n",
            ":\n",
            "\t\n",
            "\"About\tpagination:\tmany\tAPIs\treturn\titems\tin\t\n",
            "\\\"\n",
            "pages\n",
            "\\\"\n",
            "Embedding 174: [0.04891050606966019, 0.012242255732417107, -0.010965615510940552, -0.01968436874449253, 0.01509763952344656, 0.011500206775963306, -0.022722920402884483, 0.04312090203166008, 0.005730421748012304, -0.006541923154145479] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 175: \\\"\n",
            "pages\n",
            "\\\"\n",
            ".\tMake\tsure\tto\trun\tthrough\tall\tthe\tpages\tusing\twhile\tTrue\tloop\tinstead\tof\n",
            "\t\n",
            "for\ti\tin\trange(10)\tover\t`page_index`.\"\n",
            "\t\t\t\t\n",
            "}\n",
            "\t\t\n",
            "]\n",
            "}\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "\t\n",
            "\"[Your\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\tdetailed\tanalysis\tand\tcalculations\there]\"\n",
            ",\n",
            "\t\t\n",
            "\"operations\"\n",
            ":\n",
            "\t\n",
            "[\n",
            "\t\t\t\t\n",
            "{\n",
            "\t\t\t\t\t\t\n",
            "\"type\"\n",
            ":\n",
            "\t\n",
            "\"ADD\"\n",
            ",\n",
            "\t\n",
            "\t\t\t\t\t\t\n",
            "\"section\"\n",
            ":\n",
            "\t\n",
            "\"verification_checklist\"\n",
            ",\n",
            "\t\t\t\t\t\t\n",
            "\"content\"\n",
            ":\n",
            "\t\n",
            "\"[New\tchecklist\titem\tor\tAPI\tschema\tclarification...]\"\n",
            "\t\t\t\t\n",
            "}\n",
            "\t\t\n",
            "]\n",
            "}\n",
            "Figure 11: ACE Curator prompt on AppWorld\n",
            "Embedding 175: [0.045692767947912216, -0.06476383656263351, -0.03314277529716492, 0.001012931577861309, 0.013077673502266407, 0.036489397287368774, 0.001958569511771202, 0.007162474561482668, 0.04410417750477791, 0.008057818748056889] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 176: ]\n",
            "}\n",
            "Figure 11: ACE Curator prompt on AppWorld\n",
            "20\n",
            "Embedding 176: [0.0374528169631958, -0.04908057674765587, -0.03581598028540611, 0.016800986602902412, 0.010843617841601372, 4.4679520215140656e-05, 0.06438353657722473, 0.0014732006238773465, 0.029681038111448288, 0.03634588047862053] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 177: You\tare\tan\tanalysis\texpert\ttasked\twith\tanswering\tquestions\tusing\tyour\tknowledge,\ta\tcurated\tplaybook\tof\tstrategies\tand\tinsights\tand\ta\n",
            "reflection\tthat\tgoes\tover\tthe\tdiagnosis\tof\tall\tprevious\tmistakes\tmade\twhile\tanswering\tthe\tquestion.\n",
            "Instructions:\n",
            "\t-\tRead\tthe\tplaybook\tcarefully\tand\tapply\trelevant\tstrategies,\tformulas,\tand\tinsights\t-\tPay\tattention\tto\tcommon\tmistakes\n",
            "listed\tin\tthe\tplaybook\tand\tavoid\tthem\t-\tShow\tyour\treasoning\tstep-by-step\t-\tBe\tconcise\tbut\tthorough\tin\tyour\tanalysis\t-\tIf\tthe\tplaybook\n",
            "Embedding 177: [0.009203517809510231, -0.00988670252263546, -0.03320297226309776, -0.007135356776416302, -0.0338880755007267, -0.02527957782149315, -0.016504811123013496, -0.01885347068309784, -0.05226793512701988, -0.02450011670589447] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 178: contains\trelevant\tcode\tsnippets\tor\tformulas,\tuse\tthem\tappropriately\t-\tDouble-check\tyour\tcalculations\tand\tlogic\tbefore\tproviding\tthe\tfinal\n",
            "answer\n",
            "Your\toutput\tshould\tbe\ta\tjson\tobject,\twhich\tcontains\tthe\tfollowing\tfields:\t-\treasoning:\tyour\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\n",
            "detailed\tanalysis\tand\tcalculations\t-\tbullet_ids:\teach\tline\tin\tthe\tplaybook\thas\ta\tbullet_id.\tall\tbulletpoints\tin\tthe\tplaybook\tthat’s\trelevant,\n",
            "Embedding 178: [-0.030727189034223557, -0.013374237343668938, -0.025967050343751907, 0.05102793499827385, -0.01960933767259121, -0.014103303663432598, -0.023709746077656746, 0.032296229153871536, -0.03660445660352707, -0.05837249383330345] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 179: helpful\tfor\tyou\tto\tanswer\tthis\tquestion,\tyou\tshould\tinclude\ttheir\tbullet_id\tin\tthis\tlist\t-\tfinal_answer:\tyour\tconcise\tfinal\tanswer\n",
            "Playbook:\n",
            "{}\n",
            "Reflection:\n",
            "{}\n",
            "Question:\n",
            "{}\n",
            "Context:\n",
            "{}\n",
            "Answer\tin\tthis\texact\tJSON\tformat:\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "\t\n",
            "\"[Your\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\tdetailed\tanalysis\tand\tcalculations]\"\n",
            ",\n",
            "\t\t\n",
            "\t\t\n",
            "\"bullet_ids\"\n",
            ":\n",
            "\t\n",
            "[\n",
            "\"calc-00001\"\n",
            ",\n",
            "\t\n",
            "\"fin-00002\"\n",
            "]\n",
            ",\n",
            "\t\t\n",
            "\t\t\n",
            "\"final_answer\"\n",
            ":\n",
            "\t\n",
            "\"[Your\tconcise\tfinal\tanswer\there]\"\n",
            "}\n",
            "Figure 12: ACE Generator prompt on FINER\n",
            "21\n",
            "Embedding 179: [-0.00763289537280798, -0.04617087543010712, -0.0077960374765098095, 0.03367884084582329, -0.026628058403730392, -0.008610792458057404, 0.03348156437277794, 0.016532674431800842, -0.09349694848060608, 0.010763345286250114] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 180: You\tare\tan\texpert\tanalyst\tand\teducator.\tYour\tjob\tis\tto\tdiagnose\twhy\ta\tmodel’s\treasoning\twent\twrong\tby\tanalyzing\tthe\tgap\tbetween\n",
            "predicted\tanswer\tand\tthe\tground\ttruth.\n",
            "Instructions:\n",
            "\t-\tCarefully\tanalyze\tthe\tmodel’s\treasoning\ttrace\tto\tidentify\twhere\tit\twent\twrong\t-\tTake\tthe\tenvironment\tfeedback\tinto\n",
            "account,\tcomparing\tthe\tpredicted\tanswer\twith\tthe\tground\ttruth\tto\tunderstand\tthe\tgap\t-\tIdentify\tspecific\tconceptual\terrors,\tcalculation\n",
            "Embedding 180: [0.05337557569146156, 0.011613493785262108, -0.017354121431708336, 0.003531096503138542, -0.01775585673749447, 0.01802833192050457, 0.020769545808434486, -0.012491926550865173, -0.017561061307787895, -0.01880628988146782] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 181: mistakes,\tor\tmisapplied\tstrategies\t-\tProvide\tactionable\tinsights\tthat\tcould\thelp\tthe\tmodel\tavoid\tthis\tmistake\tin\tthe\tfuture\t-\tFocus\ton\tthe\n",
            "root\tcause,\tnot\tjust\tsurface-level\terrors\t-\tBe\tspecific\tabout\twhat\tthe\tmodel\tshould\thave\tdone\tdifferently\t-\tYou\twill\treceive\tbulletpoints\tthat\n",
            "are\tpart\tof\tplaybook\tthat’s\tused\tby\tthe\tgenerator\tto\tanswer\tthe\tquestion.\t-\tYou\tneed\tto\tanalyze\tthese\tbulletpoints,\tand\tgive\tthe\ttag\tfor\n",
            "Embedding 181: [0.01585213467478752, -0.0687849149107933, 0.017916880548000336, -0.014346156269311905, -0.0240839384496212, 0.039417725056409836, -0.03407198563218117, 0.014201082289218903, -0.01139034703373909, -0.03571850061416626] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 182: each\tbulletpoint,\ttag\tcan\tbe\t[‘helpful’,\t‘harmful’,\t‘neutral’]\t(for\tthe\tgenerator\tto\tgenerate\tthe\tcorrect\tanswer)\n",
            "Your\toutput\tshould\tbe\ta\tjson\tobject,\twhich\tcontains\tthe\tfollowing\tfields\t-\treasoning:\tyour\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\n",
            "detailed\tanalysis\tand\tcalculations\t-\terror_identification:\twhat\tspecifically\twent\twrong\tin\tthe\treasoning?\t-\troot_cause_analysis:\twhy\tdid\tthis\n",
            "Embedding 182: [-0.010662885382771492, -0.037923164665699005, -0.01485956460237503, 0.01853337325155735, -0.012382826767861843, 0.00518712168559432, -0.027019040659070015, 0.015802526846528053, -0.013181939721107483, -0.0603053979575634] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 183: error\toccur?\tWhat\tconcept\twas\tmisunderstood?\t-\tcorrect_approach:\twhat\tshould\tthe\tmodel\thave\tdone\tinstead?\t-\tkey_insight:\twhat\n",
            "strategy,\tformula,\tor\tprinciple\tshould\tbe\tremembered\tto\tavoid\tthis\terror?\t-\tbullet_tags:\ta\tlist\tof\tjson\tobjects\twith\tbullet_id\tand\ttag\tfor\n",
            "each\tbulletpoint\tused\tby\tthe\tgenerator\n",
            "Question:\n",
            "{}\n",
            "Model’s\tReasoning\tTrace:\n",
            "{}\n",
            "Model’s\tPredicted\tAnswer:\n",
            "{}\n",
            "Ground\tTruth\tAnswer:\n",
            "{}\n",
            "Environment\tFeedback:\n",
            "{}\n",
            "Part\tof\tPlaybook\tthat’s\tused\tby\tthe\tgenerator\tto\tanswer\tthe\tquestion:\n",
            "{}\n",
            "Embedding 183: [0.025600362569093704, -0.03835320845246315, 0.008860078640282154, 0.022108249366283417, 0.0006013090605847538, 0.03401285409927368, 0.02073040045797825, 0.007822149433195591, -0.038794707506895065, -0.040530599653720856] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 184: {}\n",
            "Answer\tin\tthis\texact\tJSON\tformat:\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "\t\n",
            "\"[Your\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\tdetailed\tanalysis\tand\tcalculations]\"\n",
            ",\n",
            "\t\t\n",
            "\"error_identification\"\n",
            ":\n",
            "\t\n",
            "\"[What\tspecifically\twent\twrong\tin\tthe\treasoning?]\"\n",
            ",\n",
            "\t\t\n",
            "\"root_cause_analysis\"\n",
            ":\n",
            "\t\n",
            "\"[Why\tdid\tthis\terror\toccur?\tWhat\tconcept\twas\tmisunderstood?]\"\n",
            ",\n",
            "\t\t\n",
            "\"correct_approach\"\n",
            ":\n",
            "\t\n",
            "\"[What\tshould\tthe\tmodel\thave\tdone\tinstead?]\"\n",
            ",\n",
            "\t\t\n",
            "\"key_insight\"\n",
            ":\n",
            "Embedding 184: [0.004488153848797083, 0.050603434443473816, -0.000379084114683792, 0.037405818700790405, -0.004354959353804588, -0.003180079162120819, -0.037711359560489655, -0.007510804105550051, -0.0373285673558712, -0.059381697326898575] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 185: ,\n",
            "\t\t\n",
            "\"key_insight\"\n",
            ":\n",
            "\t\n",
            "\"[What\tstrategy,\tformula,\tor\tprinciple\tshould\tbe\tremembered\tto\tavoid\tthis\terror?]\"\n",
            ",\n",
            "\t\t\n",
            "\"bullet_tags\"\n",
            ":\n",
            "\t\n",
            "[\n",
            "\t\t\t\t\n",
            "{\n",
            "{\n",
            "\"id\"\n",
            ":\n",
            "\t\n",
            "\"calc-00001\"\n",
            ",\n",
            "\t\n",
            "\"tag\"\n",
            ":\n",
            "\t\n",
            "\"helpful\"\n",
            "}\n",
            "}\n",
            ",\n",
            "\t\t\t\t\n",
            "{\n",
            "{\n",
            "\"id\"\n",
            ":\n",
            "\t\n",
            "\"fin-00002\"\n",
            ",\n",
            "\t\n",
            "\"tag\"\n",
            ":\n",
            "\t\n",
            "\"harmful\"\n",
            "}\n",
            "}\n",
            "\t\t\n",
            "]\n",
            "}\n",
            "Figure 13: ACE Reflector prompt on FINER\n",
            "22\n",
            "Embedding 185: [0.045644525438547134, -0.08869108557701111, -0.007420230656862259, 0.030629416927695274, -0.025217564776539803, 0.0209457166492939, 0.05643508583307266, 0.03108825907111168, -0.018687251955270767, 0.014983324334025383] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 186: You\tare\ta\tmaster\tcurator\tof\tknowledge.\tYour\tjob\tis\tto\tidentify\twhat\tnew\tinsights\tshould\tbe\tadded\tto\tan\texisting\tplaybook\tbased\ton\ta\n",
            "reflection\tfrom\ta\tprevious\tattempt.\n",
            "Context:\n",
            "\t-\tThe\tplaybook\tyou\tcreated\twill\tbe\tused\tto\thelp\tanswering\tsimilar\tquestions.\t-\tThe\treflection\tis\tgenerated\tusing\tground\ttruth\n",
            "answers\tthat\twill\tNOT\tbe\tavailable\twhen\tthe\tplaybook\tis\tbeing\tused.\tSo\tyou\tneed\tto\tcome\tup\twith\tcontent\tthat\tcan\taid\tthe\tplaybook\tuser\n",
            "to\tcreate\tpredictions\tthat\tlikely\talign\twith\tground\ttruth.\n",
            "Embedding 186: [0.06519706547260284, 0.02260998636484146, -0.014339967630803585, 0.00507835578173399, -0.05190308019518852, -0.022076353430747986, -0.040808700025081635, -0.009595829993486404, -0.021269729360938072, -0.027656465768814087] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 187: CRITICAL:\tYou\tMUST\trespond\twith\tvalid\tJSON\tonly.\tDo\tnot\tuse\tmarkdown\tformatting\tor\tcode\tblocks.\n",
            "Instructions:\n",
            "\t-\tReview\tthe\texisting\tplaybook\tand\tthe\treflection\tfrom\tthe\tprevious\tattempt\t-\tIdentify\tONLY\tthe\tNEW\tinsights,\tstrategies,\n",
            "or\tmistakes\tthat\tare\tMISSING\tfrom\tthe\tcurrent\tplaybook\t-\tAvoid\tredundancy\t-\tif\tsimilar\tadvice\talready\texists,\tonly\tadd\tnew\tcontent\tthat\n",
            "Embedding 187: [0.01361147128045559, 0.01386905275285244, -0.011271542869508266, 0.0040764762088656425, -0.033169135451316833, -0.05367022752761841, -0.0702863335609436, 0.013314933516085148, -0.024984022602438927, -0.054905883967876434] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 188: is\ta\tperfect\tcomplement\tto\tthe\texisting\tplaybook\t-\tDo\tNOT\tregenerate\tthe\tentire\tplaybook\t-\tonly\tprovide\tthe\tadditions\tneeded\t-\tFocus\ton\n",
            "quality\tover\tquantity\t-\ta\tfocused,\twell-organized\tplaybook\tis\tbetter\tthan\tan\texhaustive\tone\t-\tFormat\tyour\tresponse\tas\ta\tPURE\tJSON\tobject\n",
            "with\tspecific\tsections\t-\tFor\tany\toperation\tif\tno\tnew\tcontent\tto\tadd,\treturn\tan\tempty\tlist\tfor\tthe\toperations\tfield\t-\tBe\tconcise\tand\tspecific\t-\n",
            "each\taddition\tshould\tbe\tactionable\n",
            "Training\tContext:\n",
            "Embedding 188: [0.023020174354314804, 0.044290825724601746, -0.0035814044531434774, 0.01060857530683279, -0.0028178771026432514, -0.0318993479013443, -0.05370655655860901, 0.017691059038043022, -0.02928643487393856, -0.034842804074287415] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 189: Training\tContext:\n",
            "Total\ttoken\tbudget:\t{token_budget}\ttokens\n",
            "Training\tprogress:\tSample\t{current_step}\tout\tof\t{total_samples}\n",
            "Current\tPlaybook\tStats:\n",
            "{playbook_stats}\n",
            "Recent\tReflection:\n",
            "{recent_reflection}\n",
            "Current\tPlaybook:\n",
            "{current_playbook}\n",
            "Question\tContext:\n",
            "{question_context}\n",
            "Your\tTask:\n",
            "\tOutput\tONLY\ta\tvalid\tJSON\tobject\twith\tthese\texact\tfields:\t-\treasoning:\tyour\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\n",
            "Embedding 189: [0.01961079053580761, 0.03511938825249672, 0.01032883208245039, 0.06505811214447021, 0.022765155881643295, -0.04968417435884476, -0.03713446855545044, 0.020057961344718933, -0.07844186574220657, -0.03728654608130455] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 190: detailed\tanalysis\tand\tcalculations\t-\toperations:\ta\tlist\tof\toperations\tto\tbe\tperformed\ton\tthe\tplaybook\t-\ttype:\tthe\ttype\tof\toperation\tto\tbe\n",
            "performed\t-\tsection:\tthe\tsection\tto\tadd\tthe\tbullet\tto\t-\tcontent:\tthe\tnew\tcontent\tof\tthe\tbullet\n",
            "Available\tOperations:\n",
            "\t1.\tADD:\tCreate\tnew\tbullet\tpoints\twith\tfresh\tIDs\t-\tsection:\tthe\tsection\tto\tadd\tthe\tnew\tbullet\tto\t-\tcontent:\tthe\tnew\n",
            "Embedding 190: [0.0008206659113056958, -0.110174261033535, -0.004932814743369818, 0.01125706359744072, -0.033621884882450104, 0.015366947278380394, 0.024252714589238167, -0.010179962031543255, -0.07410706579685211, -0.023618973791599274] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 191: content\tof\tthe\tbullet.\tNote:\tno\tneed\tto\tinclude\tthe\tbullet_id\tin\tthe\tcontent\tlike\t‘[ctx-00263]\thelpful=1\tharmful=0\t::’,\tthe\tbullet_id\twill\tbe\n",
            "added\tby\tthe\tsystem.\n",
            "RESPONSE\tFORMAT\t-\tOutput\tONLY\tthis\tJSON\tstructure\t(no\tmarkdown,\tno\tcode\tblocks):\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "\t\n",
            "\"[Your\tchain\tof\tthought\t/\treasoning\t/\tthinking\tprocess,\tdetailed\tanalysis\tand\tcalculations\there]\"\n",
            ",\n",
            "\t\t\n",
            "\"operations\"\n",
            ":\n",
            "\t\n",
            "[\n",
            "\t\t\t\t\n",
            "{\n",
            "{\n",
            "\t\t\t\t\t\t\n",
            "\"type\"\n",
            ":\n",
            "\t\n",
            "\"ADD\"\n",
            ",\n",
            "\t\n",
            "\t\t\t\t\t\t\n",
            "\"section\"\n",
            ":\n",
            "\t\n",
            "\"formulas_and_calculations\"\n",
            ",\n",
            "\t\t\t\t\t\t\n",
            "\"content\"\n",
            ":\n",
            "Embedding 191: [-0.007319021970033646, -0.03823591023683548, 0.007125637028366327, 0.06512799113988876, -0.02141900733113289, 0.03506595641374588, -0.03568258136510849, 0.010987814515829086, -0.06785303354263306, -0.03982939571142197] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "Chunk 192: ,\n",
            "\t\t\t\t\t\t\n",
            "\"content\"\n",
            ":\n",
            "\t\n",
            "\"[New\tcalculation\tmethod...]\"\n",
            "\t\t\t\t\n",
            "}\n",
            "}\n",
            "\t\t\n",
            "]\n",
            "}\n",
            "Figure 14: ACE Curator prompt on FINER\n",
            "23\n",
            "Embedding 192: [-0.012883717194199562, -0.04099702090024948, -0.021996846422553062, 0.027037998661398888, -0.0502479150891304, 0.0034391358494758606, 0.027777109295129776, 0.026866871863603592, -0.07296739518642426, 0.0576101653277874] ... (truncated for readability)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Total Embeddings Created: 192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Create FAISS instance\n",
        "dimension = len(hf_vectors[0])  # Assuming fixed embedding dimension\n",
        "faiss_index = faiss.IndexFlatL2(dimension)\n",
        "faiss_index.add(np.array(hf_vectors, dtype=np.float32))\n",
        "\n",
        "# Perform similarity search\n",
        "query = \"example search query\"\n",
        "query_embedding = hf_embeddings.embed_query(query)\n",
        "D, I = faiss_index.search(np.array([query_embedding], dtype=np.float32), k=5)\n",
        "\n",
        "# Print search results with matching text and embeddings\n",
        "print(\"\\nTop Matches for Query:\\n\")\n",
        "for match_idx in I[0]:\n",
        "    print(f\"Matched Text Chunk: {split_docs[match_idx].page_content}\")\n",
        "    print(f\"Matching Embedding: {hf_vectors[match_idx][:10]} ... (truncated)\")\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWae0YYwkh0F",
        "outputId": "5074d4dc-0c55-4f4c-eda7-921c7cdee824"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top Matches for Query:\n",
            "\n",
            "Matched Text Chunk: }\n",
            "\t\t\n",
            "]\n",
            "}\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "\t\n",
            "\"The\treflection\tidentifies\ta\tpagination\thandling\terror\twhere\tthe\tagent\tused\tan\tarbitrary\tfixed\trange\tinstead\tof\tproper\tpagination\n",
            "\t\n",
            "logic.\tThis\tis\ta\tcommon\tAPI\tusage\tpattern\tthat\tshould\tbe\texplicitly\tdocumented\tto\tensure\tcomplete\tdata\tretrieval.\"\n",
            ",\n",
            "\t\t\n",
            "\"operations\"\n",
            ":\n",
            "\t\n",
            "[\n",
            "\t\t\t\t\n",
            "{\n",
            "\t\t\t\t\t\t\n",
            "\"type\"\n",
            ":\n",
            "\t\n",
            "\"ADD\"\n",
            ",\n",
            "\t\t\t\t\t\t\n",
            "\"section\"\n",
            ":\n",
            "\t\n",
            "\"apis_to_use_for_specific_information\"\n",
            ",\n",
            "\t\t\t\t\t\t\n",
            "\"content\"\n",
            ":\n",
            "\t\n",
            "\"About\tpagination:\tmany\tAPIs\treturn\titems\tin\t\n",
            "\\\"\n",
            "pages\n",
            "\\\"\n",
            "Matching Embedding: [0.04891050606966019, 0.012242255732417107, -0.010965615510940552, -0.01968436874449253, 0.01509763952344656, 0.011500206775963306, -0.022722920402884483, 0.04312090203166008, 0.005730421748012304, -0.006541923154145479] ... (truncated)\n",
            "--------------------------------------------------------------------------------\n",
            "Matched Text Chunk: queries, which surface both effective strategies and recurring pitfalls. The Reflector critiques these traces\n",
            "to extract lessons, optionally refining them across multiple iterations. The Curator then synthesizes these\n",
            "lessons into compactdelta entries, which are merged deterministically into the existing context by lightweight,\n",
            "non-LLM logic. Because updates are itemized and localized, multiple deltas can be merged in parallel,\n",
            "Matching Embedding: [0.003301430493593216, 0.07794962078332901, -0.051454707980155945, -0.02115635760128498, -0.06983684748411179, -0.000607293623033911, -0.03769781440496445, -0.0009450083016417921, -0.06107380986213684, 0.0010016757296398282] ... (truncated)\n",
            "--------------------------------------------------------------------------------\n",
            "Matched Text Chunk: :\n",
            "\t\n",
            "[\n",
            "\t\t\t\t\n",
            "{\n",
            "\t\t\t\t\t\t\n",
            "\"type\"\n",
            ":\n",
            "\t\n",
            "\"ADD\"\n",
            ",\n",
            "\t\t\t\t\t\t\n",
            "\"section\"\n",
            ":\n",
            "\t\n",
            "\"strategies_and_hard_rules\"\n",
            ",\n",
            "\t\n",
            "\t\t\t\t\t\t\n",
            "\"content\"\n",
            ":\n",
            "\t\n",
            "\"Always\tresolve\tidentities\tfrom\tthe\tcorrect\tsource\tapp\n",
            "\\n\n",
            "-\tWhen\tyou\tneed\tto\tidentify\trelationships\t(roommates,\tcontacts,\tetc.),\n",
            "\t\n",
            "always\tuse\tthe\tPhone\tapp's\tcontact,\tand\tnever\ttry\tother\theuristics\tfrom\ttransaction\tdescriptions,\tname\tpatterns,\tor\tother\tindirect\n",
            "\t\n",
            "sources.\tThese\theuristics\tare\tunreliable\tand\twill\tcause\tincorrect\tresults.\"\n",
            "\t\t\t\t\n",
            "}\n",
            "\t\t\n",
            "]\n",
            "}\n",
            "{\n",
            "\t\t\n",
            "\"reasoning\"\n",
            ":\n",
            "Matching Embedding: [0.0694107711315155, -0.011636356823146343, -0.02893788181245327, -0.015501161105930805, -0.02924743853509426, -0.017690908163785934, 0.03281282261013985, -0.02701161429286003, 0.024132732301950455, -0.007605166174471378] ... (truncated)\n",
            "--------------------------------------------------------------------------------\n",
            "Matched Text Chunk: {{playbook}}\n",
            "PLAYBOOK_END\n",
            "Examples:\n",
            "Example\t1:\n",
            "Ground\tTruth\tCode:\t[Code\tthat\tuses\tapis.phone.search_contacts()\tto\tfind\troommates,\tthen\tfilters\tVenmo\ttransactions]\n",
            "Generated\tCode:\t[Code\tthat\ttries\tto\tidentify\troommates\tby\tparsing\tVenmo\ttransaction\tdescriptions\tusing\tkeywords\tlike\t“rent”,\t“utilities”]\n",
            "Execution\tError:\tAssertionError:\tExpected\t1068.0\tbut\tgot\t79.0\n",
            "Test\tReport:\tFAILED\t-\tWrong\ttotal\tamount\tcalculated\tdue\tto\tincorrect\troommate\tidentification\n",
            "Response:\n",
            "{{\n",
            "Matching Embedding: [0.030413903295993805, 0.034959789365530014, -0.03280569240450859, 0.005703357048332691, 0.025353627279400826, -0.03279614448547363, 0.01490972563624382, 0.024008115753531456, 0.03608730062842369, -0.02342202141880989] ... (truncated)\n",
            "--------------------------------------------------------------------------------\n",
            "Matched Text Chunk: {final_generated_code}\n",
            "Current\tReflections\t(principles\tand\tstrategies\tthat\thelped\tto\tachieve\tcurrent\ttask):\n",
            "{guidebook}\n",
            "Examples:\n",
            "Example\t1:\n",
            "Task\tContext:\t“Find\tmoney\tsent\tto\troommates\tsince\tJan\t1\tthis\tyear”\n",
            "Current\tPlaybook:\t[Basic\tAPI\tusage\tguidelines]\n",
            "Generated\tAttempt:\t[Code\tthat\tfailed\tbecause\tit\tused\ttransaction\tdescriptions\tto\tidentify\troommates\tinstead\tof\tPhone\tcontacts]\n",
            "Matching Embedding: [0.03624685853719711, 0.09922777861356735, -0.03992221876978874, 0.0179145447909832, -0.04760186746716499, -0.013103228993713856, 0.013515511527657509, 0.034763582050800323, 0.016439709812402725, -0.01377870049327612] ... (truncated)\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask a question\n",
        "query = input(\"\\nEnter your query\")\n",
        "query_embedding = hf_embeddings.embed_query(query)\n",
        "D, I = faiss_index.search(np.array([query_embedding], dtype=np.float32), k=1)\n",
        "\n",
        "# Print answer and embedding\n",
        "best_match_idx = I[0][0]\n",
        "print(\"\\n Best matching Answer\")\n",
        "print(split_docs[best_match_idx].page_content)\n",
        "print(\"\\n Corresponding Embedding (Trncated for readability)\")\n",
        "print(hf_vectors[best_match_idx][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnBwdf39ksZD",
        "outputId": "3629295a-bd7f-470d-88f4-4e163f0a633c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter your querywhat is this paper about\n",
            "\n",
            " Best matching Answer\n",
            ",\n",
            "\t\t\t\t\t\t\n",
            "\"content\"\n",
            ":\n",
            "\t\n",
            "\"[New\tcalculation\tmethod...]\"\n",
            "\t\t\t\t\n",
            "}\n",
            "}\n",
            "\t\t\n",
            "]\n",
            "}\n",
            "Figure 14: ACE Curator prompt on FINER\n",
            "23\n",
            "\n",
            " Corresponding Embedding (Trncated for readability)\n",
            "[-0.012883717194199562, -0.04099702090024948, -0.021996846422553062, 0.027037998661398888, -0.0502479150891304, 0.0034391358494758606, 0.027777109295129776, 0.026866871863603592, -0.07296739518642426, 0.0576101653277874]\n"
          ]
        }
      ]
    }
  ]
}